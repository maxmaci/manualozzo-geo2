% SVN info for this file
\svnidlong
{$HeadURL$}
{$LastChangedDate$}
{$LastChangedRevision$}
{$LastChangedBy$}

\chapter{Geometria proiettiva}
\labelChapter{geoproiettiva}

\begin{introduction}
	‘‘BEEP BOOP INSERIRE CITAZIONE QUA BEEP BOOP.''
	\begin{flushright}
		\textsc{NON UN ROBOT,} UN UMANO IN CARNE ED OSSA BEEP BOOP.
	\end{flushright}
\end{introduction}

\section{Spazi proiettivi}
% mettere superfici
Abbiamo già approfondito, a livello \textit{topologico}, lo \textbf{spazio proiettivo reale} e le sue caratteristiche nel \autoref{chap:superfici}. In questo capitolo, ci dedicheremo a \textit{generalizzare} il concetto per un \textit{qualsiasi} spazio vettoriale su campo $\kamp$, utilizzando gli strumenti dell'algebra lineare. 
\begin{define}
Sia $\kamp$ un campo e $V$ uno spazio vettoriale di dimensione \textit{finita} su $\kamp$. Lo \textbf{spazio proiettivo}\index{spazio!proiettivo} associato a $V$ è l'insieme quoziente:
\begin{equation}
	\proj{V}=\frac{V\setminus\left\{0\right\}}{\sim}
\end{equation}
Dove $\sim$ è la relazione di equivalenza data su $V\setminus\left\{0\right\}$ definita dall'azione del gruppo moltiplicativo $\kamp\setminus\left\{0\right\}$:
\begin{equation}
	\forall v,\ w\in V\setminus\left\{0\right\}\ v\sim w \iff \exists \lambda\in\kamp\setminus\left\{0\right\}\ \colon v=\lambda w
\end{equation}
Lo spazio proiettivo $\proj{V}$ si dice anche il \textbf{proiettivizzato}\seeonlyindex{proiettivizzato}{spazio!proiettivo} di $V$.
\end{define}
% finire dimostrazione
\begin{demonstration}
~{}
\begin{itemize}
	\item \textsc{Riflessiva}: ...
	\item \textsc{Simmetrica}: ...
	\item \textsc{Transitiva}: ...
\end{itemize}
\end{demonstration}
\begin{define}
La \textbf{dimensione}\index{dimensione di uno spazio proiettivo} di $\proj{V}$ è:
\begin{equation}
	\dim\proj{V}=\dim V-1
\end{equation}
Se $V=\left\{0\right\}$, allora $\proj{V}=\emptyset$ e si pone $\dim\emptyset\coloneqq -1$.
\end{define}
\begin{define}
Si denota con $\funz{\pi}{V\setminus\left\{0\right\}}{\proj{V}}$ la \textbf{proiezione al quoziente}\index{proiezione!al quoziente} e con $\left[v\right]\in\proj{V}$ la \textbf{classe}\index{classe!dello spazio proiettivo} di $v\in V\setminus\left\{0\right\}$.
\end{define}
\begin{observe}
	Si ha una corrispondenza biunivoca:
	\begin{equation}
		\begin{array}{c}
			\proj{V}\leftrightarrow\left\{\text{sottospazi vettoriali }1\text{-dimensionali di }V\right\}\\
			\left[v\right]\leftrightarrow\lin{v}
		\end{array}
	\end{equation}
In altre parole, possiamo pensare a $\proj{V}$ come l'insieme delle \textbf{rette vettoriali} in $V$.
\end{observe}
\begin{define}~{}
	\begin{itemize}
		\item Se $\dim V=1$, allora $\proj{V}$ è un \textbf{punto}\index{punto!proiettivo} e $\dim\proj{V}=0$.
		\item Se $\dim \proj{V}=1$, si parla di \textbf{retta proiettiva}\index{retta!proiettiva}.
		\item Se $\dim \proj{V}=2$, si parla di \textbf{piano proiettivo}\index{piano!proiettivo}.
		\item Se $\kamp=\realset$ o $\kamp=\complexset$, si parla rispettivamente di \textbf{spazio proiettivo reale}\index{spazio!proiettivo!reale} o di \textbf{spazio proiettivo complesso}\index{spazio!proiettivo!complesso}.
	\end{itemize}
\end{define}
Gli esempi più frequenti di spazi proiettivi si ottengono considerando $V=\kamp^{n+1}$.
\begin{define}
	Lo \textbf{spazio proiettivo numerico}\index{spazio!proiettivo!numerico} o \textbf{spazio proiettivo standard}\seeonlyindex{spazio!proiettivo!standard}{spazio!proiettivo!numerico} è lo spazio proiettivo su $\kamp^{n+1}$:
\begin{equation}
	\proj{\ }=\proj[n]{\kamp}=\proj{\kamp^{n+1}}
\end{equation}
Essi sono spazi di dimensione $\dim\proj[n]{\ }=n$.
\end{define}
\section{Sottospazi proiettivi}
Sia $W\subseteq V$ un sottospazio vettoriale. Allora $W\setminus\left\{0\right\}\subseteq V\setminus\left\{0\right\}$ è chiuso rispetto alla relazione di equivalenza $\sim$ precedentemente definita e $\proj{W}$ è naturalmente un sottoinsieme di $\proj{V}$.
\begin{define}
	Se $W\subseteq V$ è un sottospazio vettoriale, allora $\proj{W}$ è detto \textbf{sottospazio proiettivo}\index{sottospazio!proiettivo}:
	\begin{equation*}
		\begin{array}{rl}
			\proj{W}&=\pi\left(W\setminus\left\{0\right\}\right)=\left\{\left[w\right]\in\proj{V}\mid w\in W\right\}\\
			&=\left\{\text{sottospazi vettoriale }1\text{-dimensione di }V\text{ contenuti in }W\right\}
		\end{array}
	\end{equation*}
La dimensione del sottospazio proiettivo è $\dim\proj{W}=\dim W-1$.
\end{define}
	\begin{itemize}
	\item Se $W=\left\{0\right\}$, allora $\proj{W}=\emptyset$.
	\item Se $\dim W=1$, allora $\proj{W}$ è un punto, che indichiamo con $\left[w\right]$ per un $w\in W$.
	\item Se $\dim W=2$ ($\dim\proj{W}=1$), allora $\proj{W}$ è \textbf{retta proiettiva}\index{retta!proiettiva} in $\proj{V}$.
	\item Se $\dim W=3$ ($\dim\proj{W}=2$), allora $\proj{W}$ è \textbf{piano proiettivo}\index{piano!proiettivo} in $\proj{V}$.
	\item Se $\dim\proj{W}=\dim \proj{V}-1$, allora $\proj{W}$ è \textbf{iperpiano (proiettivo)}\index{iperpiano!proiettivo} in $\proj{V}$.
\end{itemize}
\begin{define}
Si definisce la \textbf{codimensione}\index{codimensione} di $\proj{W}$ sottospazio proiettivo come:
\begin{equation}
	\codim\proj{W}=\dim\proj{V}-\dim\proj{W}
\end{equation}
\end{define}
\begin{example}
	Gli iperpiani sono sottospazi di codimensione $1$.
\end{example}
\section{Coordinate omogenee e sistemi di riferimento proiettivo}
Consideriamo $\proj[n]{\kamp}=\proj{\kamp^{n+1}}$. Se $v=\left(x_0,\ \ldots,\ x_n\right)\in\kamp^{n+1}\setminus\left\{0\right\}$, denotiamo la corrispettiva classe in questa forma:
\begin{equation}
\left[v\right]=\left(x_0\colon \ldots\colon x_n\right)\in\proj[n]{\kamp},\ x_i\in\kamp
\end{equation}
\begin{observe}~{}
	\begin{enumerate}
		\item Le $x_i$ non possono mai essere tutte nulle, dato che $v\neq 0$.
		\item Due classi sono uguali se le componenti sono tutte in proporzione per uno scalare $\lambda\in\kamp$.\footnote{La notazione con i $\colon$ viene utilizzata per mettere in evidenza che la relazione fra classi e vettori è di proporzione.}
		\begin{equation*}
			\begin{array}{ccc}
			\left(x_0:\ldots:x_n\right)=\left(y_0:\ldots:y_n\right)&\iff&\left(x_0,\ \ldots,\ x_n\right)\sim\left(y_0,\ \ldots,\ y_n\right)\\&\iff& \exists \lambda\in\kamp\setminus\left\{0\right\}\ \colon y_0=\lambda x_0,\ \ldots,\ y_n=\lambda x_n
			\end{array}
		\end{equation*}
	\end{enumerate}
\end{observe}
\begin{examples}
	In $\proj[2]{\realset}$:
	\begin{gather*}
		\left(1\colon1\colon2\right) = \left(-2\colon-2\colon-4\right)\\
		\left(1\colon0\colon2\right) = \left(\frac{1}{3}\colon0\colon\frac{1}{3}\right)
	\end{gather*}
\end{examples}
\begin{define}
	Sia $\basis=\left\{e_0,\ \ldots,\ e_n\right\}$ una base di $V$, con $\dim V=n+1$. Se $v\in V\setminus\left\{0\right\}$, si ha:
	\begin{equation*}
		v=x_0e_0+\ldots+x_ee_n,\ \text{con}\ x_i\in\kamp
	\end{equation*}
Diciamo che $\left(x_0\colon\ldots\colon x_n\right)$ sono le \textbf{coordinate omogenee}\index{coordinate omogenee} di $\left[v\right]\in\proj{V}$ definite dalla base $\basis$ e scriviamo:
\begin{equation}
	\left[v\right]=\left(x_0\colon\ldots\colon x_n\right)
\end{equation}
La base $\basis$ definisce su $\proj{V}$ un \textbf{sistema di riferimento proiettivo}, cioè ad ogni punto vengono assegnate delle coordinate omogenee. 
\end{define}
\begin{observe}~{}
		\begin{itemize}
		\item Le coordinate omogenee non possono \textit{mai} essere \textit{tutte nulle}.
		\item Le coordinate omogenee sono definite \textit{solo a meno di multipli}.
		\item $\proj[n]{\kamp}$ ha delle coordinate omogenee ‘‘naturali'' date dalla base canonica di $\kamp^{n+1}$.
		\item Basi \textit{multiple} definiscono lo stesso riferimento proiettivo di $\proj{V}$, cioè le stesse coordinate omogenee.
	\end{itemize}
\end{observe}
\begin{demonstration}
	Dimostriamo l'ultimo punto. Siano:
	\begin{equation*}
		\basis=\left\{e_0,\ \ldots,\ e_n\right\}\quad\basis'=\left\{\mu e_0,\ \ldots,\ \mu e_n\right\}
	\end{equation*}
Con $\mu\in\kamp\setminus\left\{0\right\}$. Si ha:
\begin{equation*}
	v=x_0e_0+\ldots+x_ne_n=\frac{x_0}{\mu}\left(\mu e_0\right)+\ldots + \frac{x_n}{\mu}\left(\mu e_n\right)
\end{equation*}
Passando allo spazio proiettivo:
\begin{equation*}
\underbrace{\left(x_0\colon\ldots\colon x_n\right)}_{\text{coordinate omogenee rispetto a }\basis}=\underbrace{\left(\frac{x_0}{\mu}\colon\ldots\colon \frac{x_n}{\mu}\right)}_{\text{coordinate omogenee rispetto a }\basis'}
\end{equation*}
\end{demonstration}
\begin{define}
	Data la base $\basis$, i punti:
	\begin{equation}
		\begin{array}{l}
			P_0=\left[e_0\right]=\left(1\colon0\colon\ldots\colon0\right)\\			P_1=\left[e_1\right]=\left(0\colon1\colon\ldots\colon0\right)\\
			\ldots\\
			P_n=\left[e_n\right]=\left(0\colon0\colon\ldots\colon1\right)\\
		\end{array}
	\end{equation}
Sono detti \textbf{punti fondamentali}\index{punto!fondamentale} o \textbf{punti coordinati}\seeonlyindex{punto!coordinato}{punto!fondamentale}, mentre il punto:
\begin{equation*}
	U=\left[e_0+e_1+\ldots+e_n\right]=\left(1\colon1\colon\ldots\colon1\right)
\end{equation*}
è detto \textbf{punto unità}\index{punto!unità}.
\end{define}
\subsubsection{Descrizione dei sottospazi proiettivi in coordinate}
Siano $\left(x_0\colon\ldots\colon x_n\right)$ coordinate omogenee su $\proj{V}$, indotte da una base $\basis$, e consideriamo l'equazione lineare omogenea:
\begin{equation*}
	\textcolor{green}{\circled{\ast}}\quad a_0x_0+a_1x_1+\ldots+a_nx_n=0
\end{equation*}
Con $a_i\in\kamp$ non tutti nulli.
\begin{itemize}
	\item In $V$ l'equazione omogenea rappresenta un \textit{iperpiano vettoriale} $H$.
	\item I punti $P=\left[v\right]\in\proj{V}$, le cui coordinate soddisfano l'equazioni, sono quelli tali per cui $v\in H$, cioè sono tutti e soli i punti dell'iperpiano proiettivo $\proj{H}\subseteq\proj{V}$. L'equazione lineare $\textcolor{green}{\circled{\ast}}$ è l'\textbf{equazione (cartesiana) dell'iperpiano proiettivo} $\proj{H}$.
\end{itemize}
\begin{define}
	Gli iperpiani di equazione cartesiana $x_i=0$, cioè tutti i punti la cui $i$-esima coordinata omogenea è nulla, si dicono $i$\textbf{-esimi iperpiani coordinati}\index{iperpiano!proiettivo!coordinato}.
\end{define}
\begin{example}\item
	In $\proj[1]{\kamp}$, cioè una \textit{retta proiettiva} ($\dim \proj[1]{\kamp}=1$), i sottospazi proiettivi sono:
	\begin{itemize}
		\item $\emptyset$.
		\item I punti, che in questo caso sono gli iperpiani.
		\item Tutto $\proj[1]{\kamp}$.
	\end{itemize}
Il punto $\left(a\colon b\right)$ ha equazione cartesiana:
\begin{equation}
	bx_0-ax_1=0
\end{equation}
Ovvero l'equazione della retta in $\kamp^2$ generata dal vettore $\left(a,\ b\right)$, ottenuta pertanto dal determinante $\left| \begin{array}{cc}
	a & b \\
	x_0 & x_1
\end{array} \right|=0$.
\end{example}
\begin{attention}
	In $\proj{V}$ un sottospazio proiettivo di \textit{dimensione zero} è un singolo punto $\left[v\right]=\proj{\lin{v}}$.
\end{attention}
Più in generale: fissata una base $\basis$ di $V$, ogni \textit{sottospazio vettoriale} $W$ di $V$ può essere visto, in \textit{coordinate} rispetto alla base, come l'\textit{insieme delle soluzioni} di un \textit{sistema lineare omogeneo}.
\begin{equation*}
	Ax=O
\end{equation*}
Dove $A=\left(a_{ij}\right)$ è di dimensioni $t\times \left(n+1\right)$ a elementi in $\kamp$, mentre si ha:
\begin{gather}
	x=\left(\begin{array}{c}
		x_0 \\
		\vdots \\
		x_n
	\end{array}\right)\\
\textcolor{green}{\circled{\ast}}\begin{cases}
	a_{1,0}x_0+\ldots+a_{1,n}x_n=0\\
	\vdots\\
	a_{t,0}x_0+\ldots+a_{t,n}x_n=0\\
\end{cases}
\end{gather}
Il sistema $\textcolor{green}{\circled{\ast}}$ dà delle \textit{equazioni cartesiane} per il sottospazio proiettivo $\proj{W}$ nelle coordinate omogenee $\left(x_0\colon\ldots\colon x_n\right)$.\\
Posto dunque $t$ come il numero delle \textit{equazioni}, notiamo che:
\begin{equation*}
	\begin{array}{cc}
		\dim W=n+1-\rk A \\
\begin{array}{ccc}
	\codim W &=&\rk A \\
	\shortparallel &  \\
	\dim V-\dim W &=&\dim\proj{V}-\dim\proj{W}=\codim\proj{W}
\end{array}\\
	\implies t\geq \rk\left(A\right)=\codim\proj{W}
	\end{array}
\end{equation*}
\textit{Scartando} delle equazioni possiamo sempre ricondurci ad un sistema in cui $t=\rk A=\codim\proj{W}$.
\begin{intuit}
	Per facilitare la visualizzazione degli spazi proiettivi possiamo pensare allo spazio $\kamp^{n+1}$ come lo \textbf{spazio affine} $\aff{\kamp^{n+1}}$ in cui sia fissato un punto $O$ come origine: in questo modo, le classi di $\proj[n]{\kamp}$ corrispondono alle \textit{rette affini passanti per} $O$ (identificate con le rette vettoriali di $\kamp^{n+1}$):
	\begin{equation*}
		\left(x_0\colon\ldots\colon x_n\right)\leftrightarrow\text{retta affine di }\aff{\kamp^{n+1}}\text{formata dai punti }\left(tx_0,\ \ldots,\ tx_n\right)\text{ al variare di t}\in\realset
	\end{equation*}
	Approfondiremo formalmente la relazione tra gli spazi affini e gli spazi proiettivi più avanti, a pag. \ref{spaziaffini}.
\end{intuit}
\begin{examples}~{}
	%completare con le note della fino
	\begin{itemize}
		\item Il piano proiettivo $\proj[2]{\kamp}$ ha, come sottospazi \textit{non banali}, i punti e le rette.
		\begin{itemize}
			\item Una \textit{retta proiettiva} viene da un \textit{piano}, che nel riferimento \textit{affine} possiamo prendere passante per l'origine: $a_0x_0+a_1x_0+a_2x_2=0$.
			\item Un \textit{punto} servono due equazioni, in sostanza vedendolo come \textit{intersezione di due rette proiettive}; ad esempio, $\left(1\colon0\colon0\right)$ ha equazioni $x_1=x_2=0$, mentre $\left(1\colon2\colon3\right)$ ha equazioni $\begin{cases}
				x_1=2x_0\\
				x_2=3x_0
			\end{cases}$
		\end{itemize}
	\item Nel piano proiettivo reale $\proj[2]{\realset}$, le \textit{rette proiettive} vengono da \textit{piani vettoriali}, mentre nel modello affine di $\aff{\realset^3}$ essi sono passanti per l'\textit{origine}; utilizzando la \textit{sfera unitaria} ai quali identifichiamo i punti antipodali in una relazione di equivalenza, la retta proiettiva si visualizza facilmente come l'\textit{intersezione} della sfera in un \textit{cerchio massimo}.\\
	In questo modo, considerando la \textit{semisfera superiore}, la \textbf{proiezione} dell'intersezione su di essa sul disco unitario $D$ è la rappresentazione della retta proiettiva sul \textit{modello piano} ben noto. Dunque, guardando le rette proiettive nel \textit{modello piano}, se ne hanno di \textit{tre tipi}:
	\begin{enumerate}
		\item La \textit{retta} con equazione $z=0$, ovvero al piano $xy$ in $\realset^3$: sul modello piano corrisponde al \textbf{bordo del disco} $D$ (cioè $S^1$).
		\item Le \textit{rette} con equazione $ax+by=0$, ovvero ai \textit{piani perpendicolari} in $\realset^3$ passanti per le rette con quell'equazione $ax+by=0$:  sul modello piano corrisponde a \textbf{diametri colleganti due punti} sul bordo.
		\item Nel caso generale $ax+by+cz=0$, proiettando l'\textit{arco di cerchio massimo} viene un \textbf{arco di ellisse} in $D$.
	\end{enumerate}
	\end{itemize}
\end{examples}
\section{Operazioni con i sottospazi}
Se $W_1,\ W_2\subseteq V$ sono sottospazi vettoriali, allora $W_1\cap W_2$ è un sottospazio vettoriale e si ha che l'\textbf{intersezione}\index{sottospazio!intersezione} dei corrispettivi spazi proiettivi è ancora un sottospazio proiettivo.
\begin{equation*}
	\proj{W_1\cap W_2}=\proj{W_1}\cap\proj{W_2}
\end{equation*}
\begin{observe}
	Si ha:
	\begin{equation*}
		\proj{W_1}\cap\proj{W_2}=\emptyset\iff W_1\cap W_2=\left\{0\right\}
	\end{equation*}
In tal caso diciamo che i due sottospazi sono \textbf{sghembi}\index{sottospazio!proiettivo!sghembo} o \textbf{disgiunti}\seeonlyindex{sottospazio!proiettivo!disgiunto}{sottospazio!proiettivo!sghembo}.
\end{observe}
Come per i sottospazi vettoriali, in generale l'\textbf{unione} di due sottospazi proiettivi \textit{non} è un sottospazio proiettivo.
\begin{define}
	Sia $S\subseteq \proj{V}$ un sottoinsieme non vuoto. Il \textbf{sottospazio generato}\index{sottospazio!proiettivo!generato} da $S$, denotato con $\left<S\right>$, è l'intersezione in $\proj{V}$ di tutti i sottospazi proiettivi contenenti $S$, ed è il più piccolo sottospazio contenente $S$.
\end{define}
\begin{itemize}
	\item $\left<S\right>=S\iff S$ è un sottospazio proiettivo.
	\item Se $S=\left\{P_1,\ \ldots,\ P_m\right\}$ è finito, scriviamo $\left<P_1,\ \ldots,\ P_m\right>$ per il sottospazio generato da $P_1,\ \ldots,\ P_m$.
\end{itemize}
\begin{define}
	Dati due sottospazi proiettivi $T_1,\ T_2\subseteq \proj{V}$, cioè:
	\begin{equation*}
		T_i=\proj{W_i}\quad W_i\subseteq V,\ i=1,\ 2
	\end{equation*}
	Allora il sottospazio generato da $T_1\cup T_2$ è denotato con $T_1+T_2=\left<T_1,\ T_2\right>$ e si chiama \textbf{sottospazio somma}\index{sottospazio!somma}. In particolare, si ha:
	\begin{equation}
		\left<T_1,\ T_2\right>=\proj{W_1+W_2}
	\end{equation}
\end{define}
\begin{demonstration}~{}\\
	$\includedx$ $\proj{W_1+W_2}$ è un sottospazio proiettivo che contiene, in quanto $W_1\subseteq W_1+W_2,\ W_2\subseteq W_1+W_2$ vettorialmente, sia $T_1=\proj{W_1}$ sia $T_2=\proj{W_2}$. In particolare, contiene la loro unione\footnote{Ricordiamo che non è essa un sottospazio, ma un sottoinsieme.}, dunque $\left<T_1,\ T_2\right>\left<T_1\cup T_2\right>\subseteq \proj{W_1+W_2}$.\\
	$\includesx$ Abbiamo che $T_i\subseteq \left<T_1,\ T_2\right>=\proj{U}$, con $U$ un sottospazio vettoriale di $V$. In particolare, si ha che $W_1,\ W_2\subseteq U$, da cui $W_1+W_2\subseteq U$. Passando allo spazio proiettivo:
	\begin{equation*}
		\left<T_1,\ T_2\right>=\proj{U}\subseteq \proj{W_1+W_2}
	\end{equation*}
\end{demonstration}
\begin{proposition}\textsc{Formula di Grassmann proiettiva}\\
	Siano $T_1,\ T_2$ sottospazi proiettivi di $\proj{V}$. Si ha:
	\begin{equation}
				\dim\left<T_1,\ R_2\right>+\dim\left(T_1\cap T_2\right)=\dim T_1+\dim T_2
	\end{equation}
\end{proposition}
\begin{demonstration}
	Posti $T_i=\proj{W_i}$, con $W_i\subseteq V$ sottospazi vettoriali. Dalla \textit{formula di Grassmann vettoriale}:
	\begin{equation*}
		\dim\left(W_1+W_2\right)+\dim\left(W_1\cap W_2\right)=\dim W_1+\dim W_2
	\end{equation*}
Sottraendo $1$ a tutte le dimensioni, otteniamo le dimensioni dei corrispettivi spazi proiettivi e dunque la formula proiettiva.
\end{demonstration}
\begin{corollary}
	Siano $T_1,\ T_2$ sottospazi proiettivi di $\proj{V}$ con $\dim\proj{P}=n$. Allora:
	\begin{equation}
		\dim \left(T_1\cap T_2\right)\leq \dim T_1+\dim T_2-n
	\end{equation}
In particolare $T_1\cap T_2\neq \emptyset$ se $\dim T_1+\dim T_2\geq n$.
\end{corollary}
\begin{demonstration}
	\begin{equation*}
		\dim\left(T_1\cap T_2\right)=\dim T_1+\dim T_2-\dim\left<T_1,\ T_2\right>\leq \dim T_1+\dim T_2-n
	\end{equation*}
Chiaramente se $\dim T_1+\dim T_2\geq n$, allora $\dim \left(T_1\cap T_2\right)\geq 0$ e dunque $T_1\cap T_2\neq \emptyset$.
\end{demonstration}
\begin{example}
	Nel piano proiettivo, due rette sono \textit{sempre incidenti}. Infatti, le rette hanno dimensione $1$, mentre $\dim\proj[2]{\kamp}=2$, dunque vale $1+1\leq 2$, pertanto due rette si incontrano sempre.
\end{example}
\begin{observe}
	Se consideriamo l'insieme \textit{finito di punti}, possiamo considerare lo spazio $S$ \textit{generato} da $P_1,\ \ldots,\ P_m$, cioè $S=\left<P_1,\ \ldots,\ P_m\right>$; inoltre, si ha:
	\begin{equation*}
		\dim S\leq m-1
	\end{equation*}
	Infatti, se $P_i=\left[v_i\right]$ con $v_i\in V$, allora:
	\begin{equation*}
		S=\underbrace{\proj{\lin{v_1,\ \ldots,\ v_m}}}_{\dim \mathcal{L} \leq m}
	\end{equation*}
\end{observe}
\section{Punti linearmente indipendenti e in posizione generale}
\begin{define}
	Siano $P_1,\ \ldots, P_m\in\proj{V}$. Diciamo che i punti $P_1,\ \ldots,\ P_m$ sono \textbf{linearmente indipendenti}\index{linearmente indipendenti} se, scelti $v_1,\ \ldots,\ v_m\in V\setminus\left\{0\right\}$ tali che $P_i=\left[v_i\right]\ \forall i$, i vettori $v_1,\ \ldots,\ v_m$ sono \textit{linearmente indipendenti} in $V$.\\
	Se così non è, diciamo che $P_1,\ \ldots, P_m$ sono linearmente dipendenti.
\end{define}
\begin{observe}~{}
	\begin{itemize}
		\item La definizione è \textit{ben posta}. Dati $\lambda_1,\ \ldots,\ \lambda_m\in\kamp\setminus\left\{0\right\}$, si ha che:
		\begin{equation*}
			v_1,\ \ldots,\ v_m\text{ sono indipendenti}\iff\lambda_1 v_1,\ \ldots,\ \lambda_m v_m\text{ sono indipendenti.}
		\end{equation*}
		\item Se $\dim \proj{V}=n$, $\proj{V}$ contiene al più $n+1$ punti indipendenti.
		\item $P_1,\ \ldots,\ P_m$ sono indipendenti se e solo se $\dim\left<P_1,\ \ldots,\ P_m\right>=m-1$.
	\end{itemize}
\end{observe}
\begin{examples}~{}
	\begin{itemize}
		\item \textit{Due} punti $P,\ Q$ sono indipendenti se e solo se $P\neq Q$. Infatti, se $P=\left[v\right]$ e $Q=\left[w\right]$, allora:
		\begin{equation*}
			P\text{ e }Q\text{ sono indipendenti}\iff v\text{ e }w\text{ sono indipendenti}\iff v\nsim w\iff P\neq Q
		\end{equation*}
		In tal caso $\left<P,\ Q\right>$ è l'unico \textit{retta} contenente $P$ e $Q$, che indicheremo anche con $\overline{PQ}$.
		\item \textit{Tre} punti $P_1,\ P_2,\ P_3$ sono indipendenti se e solo se sono \textit{distinti} e \textit{non} sono \textit{allineati}, cioè appartenenti alla stessa retta. In tal caso $\left<P_1,\ P_2,\ P_3\right>$ è l'unico \textit{piano} contenente i tre punti.
	\end{itemize}
\end{examples}
\begin{define}
	Dati dei punti $P_1,\ \ldots,\ P_m\in\proj{V}$, diciamo che sono \textbf{in posizione generale}\index{in posizione generale}\index{posizione generale} se vale una delle due condizioni seguenti:
	\begin{itemize}
		\item $m\leq n+1$ e i punti sono \textit{linearmente indipendenti}.
		\item $m>n+1$ e ogni scelta di $n+1$ punti tra loro sono linearmente indipendenti.
	\end{itemize}
\end{define}
\begin{example}~{}
		\begin{itemize}
		\item Se $n=1$, cioè $\proj{V}$ è una \textit{retta proiettiva}, allora $P_1,\ \ldots,\ P_m$ sono in posizione generale se e solo se $P_1,\ \ldots,\ P_m$ sono \textit{tutti distinti}.
		\item Se $n=2$, cioè $\proj{V}$ è una \textit{piano proiettivo}, allora $P_1,\ \ldots,\ P_m$ sono in posizione generale se e solo se $P_1,\ \ldots,\ P_m$ sono a $3$ a $3$ \textit{non} allineati.
	\end{itemize}
\end{example}
\subsection{Impratichiamoci! Punti linearmente indipendenti}
\begin{exercise}\textsc{F.F.P., 2.1.}\\
	Si mostri che i punti del piano proiettivo reale:
	\begin{equation}
		\left(\frac{1}{2}\colon 1 \colon 1\right)\quad \left(1\colon \frac{1}{3} \colon \frac{4}{3}\right)\quad \left(2\colon -1 \colon 2\right)
	\end{equation}
Sono allineati, e si determini un'equazione della retta che li contiene.
\end{exercise}
\begin{solution}
	Per verificare che i $3$ punti sono allineati, dobbiamo verificare che i corrispondenti vettori di $\realset^3$ sono dipendenti. Riscriviamo i seguenti punti per facilitarci i calcoli:
\begin{equation*}
	\left(\frac{1}{2}\colon 1 \colon 1\right)=\left(1\colon 2 \colon 2\right)\quad \left(1\colon \frac{1}{3} \colon \frac{4}{3}\right)=\left(3\colon 1 \colon 4\right)
\end{equation*}
Verifichiamolo la dipendenza con il determinante.
	\begin{equation*}
		\det\left|\begin{array}{ccc}
			1 & 2 & 2\\
			3 & 1 & 4\\
			2 & -1 & 2
		\end{array}\right|=0
	\end{equation*}
L'equazione della retta è data dall'equazione del piano vettoriale in $\realset^3$ generate da $2$ dei $3$ vettori:
\begin{equation*}
	0=\left|\begin{array}{ccc}
		x_0 & x_1 & x_2\\
		1 & 2 & 2\\
		3 & 1 & 4
	\end{array}\right|=x_0\left(8-2\right)-x_1\left(4-6\right)+x_2\left(1-6\right)=6x_0+2x_1-5x_2
\end{equation*}
Verifichiamo che contenga anche il terzo:
\begin{equation*}
	6\cdot 2 + 2\cdot \left(-1\right) -5\cdot 2=0
\end{equation*}
\end{solution}
\section{Rappresentazione parametrica di un sottospazio proiettivo}
Sia $S\subseteq\proj{V}$ un sottospazio proiettivo di dimensione $m$. Allora esistono sempre $m+1$ punti $P_0,\ \ldots,\ P_m\in S$ linearmente indipendenti che generano $S$. Infatti, se $S=\proj{W}$ con $W\subseteq V$ sottospazio vettoriale di dimensione $m+1$, possiamo scegliere una base $\left\{w_0,\ \ldots,\ w_m\right\}$ di $W$ tale per cui:
\begin{equation*}
	P_i=\left[w_i\right]\in S
\end{equation*}
Sono linearmente indipendenti (perché lo sono i vettori della base) e generano $S$.\\
Allora, tutti e soli i punti di $S$ sono della forma:
\begin{equation*}
	\left[\lambda_0 w_0+\ldots+\lambda_m w_m\right]\quad \lambda_0,\ \ldots,\ \lambda_m\in\kamp
\end{equation*}
Supponiamo ora di aver fissato una base $\left\{e_0,\ \ldots,\ e_n\right\}$ di $V$ e quindi di aver considerato il corrispondente \textit{riferimento proiettivo}. In coordinate vettoriali di $V$, un punto di $W$ è $x=\left(x_0,\ \ldots,\ x_n\right)$ se e solo se:
\begin{equation*}
	x=x_0e_0+\ldots+x_ne_n=\lambda_0 w_0+\ldots+\lambda_m w_m
\end{equation*}
Il punto $P_i$ in $V$ avrà coordinate $\left(P_{0,i},\ \ldots,\ P_{n,i}\right)\ \forall i=1,\ \ldots,\ m$, dunque il generico vettore $x$ di $W$ è espresso da:
\begin{equation}
	\begin{cases}
		x_0=\lambda_0 P_{0,0}+\lambda_1P_{0,1}+\ldots+\lambda_mP_{0,m}\\
		\vdots\\
		x_n=\lambda_0 P_{n,0}+\lambda_1P_{n,1}+\ldots+\lambda_mP_{n,m}
	\end{cases}
\end{equation}
Anche i punti di $S$ sono date da queste coordinate, dunque questa viene definita la \textbf{rappresentazione parametrica}\index{rappresentazione!parametrica} del sottospazio $S$, con $\left(\lambda_0\colon\ldots\colon\lambda_m\right)$ le coordinate omogenee di $\proj{W}$ date dalla base $\left\{w_0,\ \ldots,\ w_m\right\}$.
\begin{example}
	In $\proj[3]{\realset}$ consideriamo i punti:
	\begin{equation*}
		A=\left(1\colon 0\colon -1\colon 4\right)\quad B=\left(2\colon 3\colon 0\colon 5\right)
	\end{equation*}
Allora, la rappresentazione parametrica del sottospazio $S$ con $\left(\lambda\colon \mu\right)$ è:
\begin{equation*}
	\begin{cases}
		x_0=\lambda+2\mu\\
		x_1=3\mu\\
		x_2=-\lambda\\
		x_3=4\lambda-5\mu
	\end{cases}
\end{equation*}
\end{example}
\subsection{Coordinate proiettive e punti in posizione generale}
\begin{observe}
	Sia $\proj{V}$ con un riferimento proiettivo fissato. Consideriamo i punti fondamentali $P_0,\ \ldots,\ P_n$ e il punto unità $U$.
	\begin{itemize}
		\item $P_0,\ \ldots,\ P_n,\ U$ sono $n+2$ punti.
		\item $P_0,\ \ldots,\ P_n,\ U$ sono in posizione generale: essendo $P_i=\left[e_i\right]$ con $e_0,\ \ldots,\ e_n$ base di $V$, allora $P_0,\ \ldots,\ P_n$ sono indipendenti. Se sostituiamo l'$i$-esimo punto con $U=\left[e_1+\ldots+e_n\right]$, allora:
		\begin{equation*}
			P_0,\ \ldots,\ \check{P}_i,\ \ldots,\ U
		\end{equation*}
	Sono indipendenti $\forall i=0,\ \ldots,\ n$.\footnote{Indichiamo con $\check{P}_{i}$ il punto che sostituiamo.}
	\end{itemize}
\end{observe}
\begin{observe}
	Sia $\basis=\left\{e_0,\ \ldots,\ e_n\right\}$ una base che induce un \textit{riferimento proiettivo} su $\proj{V}$.\\
	Per ogni $i$ sia $\lambda_i\in\kamp\setminus\left\{0\right\}$ e consideriamo $v_i=\lambda_i e_i$. Allora $\basis'=\left\{v_0,\ \ldots,\ v_n\right\}$ è ancora una base e i \textit{punti fondamentali} del riferimento indotto da $\basis'$ sono \textit{gli stessi} del riferimento indotto da $\basis$. Infatti:
	\begin{equation*}
		\left[e_i\right]=\left[v_i\right]=P_i
	\end{equation*}
	Però i due riferimenti sono \textbf{diversi}; dato $v$ espresso nella base $\basis$:
	\begin{equation*}
		v=x_0e_0+\ldots+x_ne_n
	\end{equation*}
	La sua classe in $\proj{V}$, rispetto a $\basis$, è:
	\begin{equation*}
		\left[v\right]=\left(x_0\colon\ldots\colon x_n\right)
	\end{equation*}
	Possiamo partire dall'espressione di $v$ nella base $\basis$ a quella nella base $\basis'$, moltiplicando e dividendo ogni $e_i$ per il corrispettivo $\lambda_i$:
	\begin{equation*}
		v=\frac{x_0}{\lambda_0}\left(\lambda_0e_0\right)+\ldots+\frac{x_n}{\lambda_n}\left(\lambda_ne_n\right)=\frac{x_0}{\lambda_0}v_0+\ldots+\frac{x_n}{\lambda_n}v_n
	\end{equation*}
	Passiamo dunque alla base $\basis'$ alla classe in $\proj{\kamp}$:
	\begin{equation*}
		\left[v\right]=\left(\frac{x_0}{\lambda_0}\colon\ldots\colon\right)
	\end{equation*}
	Notiamo che effettivamente il punto $\left[v\right]$ non cambia, ma i riferimenti \textit{non} sono multipli e quindi sono diversi!
	\begin{itemize}
		\item \textit{Conoscere} i punti fondamentali \textit{non basta} a determinare la base $\basis$.
		\item Riferimenti proiettivi \textit{diversi} possono avere gli \textit{stessi} punti fondamentali.
	\end{itemize}
\end{observe}
\begin{observe}\label{puntigeneraleindipendentiosserva}
	Supponiamo di avere $n+2$ punti $P_0,\ \ldots,\ P_{n+1}$ in $\proj{V}$, cioè $\forall i=0,\ \ldots,\ n+1\ \exists v_i\in V\ \colon P_i=\left[v_i\right]$. Allora:
	\begin{gather*}
		P_0,\ \ldots,\ P_{n+1}\text{ sono in posizione generale}\iff v_0,\ \ldots,\ v_n\text{ sono indipendenti e}\\
		v_{n+1}=a_0v_0+\ldots+a_nv_n\text{ con }a_i\neq 0\ \forall i=0,\ \ldots,\ n 
	\end{gather*}
Infatti, se $v_0,\ \ldots,\ v_n$ è una base (in quanto sono indipendenti), $v_0,\ \ldots,\ \check{v_i},\ \ldots,\ v_n,\ v_{n+1}$ sono indipendenti se e solo se $a_i\neq 0$.
\end{observe}
\begin{theorema}
	Sia $\proj{V}$ di dimensione $n$. Dati $n+2$ punti $P_0,\ \ldots,\ P_{n+1}$ in \textit{posizione generale}, esiste una base $\basis=\left\{e_0,\ \ldots,\ e_n\right\}$ di $V$ tale che:
	\begin{equation}
		P_0=\left[e_0\right],\ \ldots,\ P_n=\left[e_n\right],\ P_{n+1}=\left[e_0+\ldots+e_n\right]
	\end{equation}
Inoltre, se $\basis'=\left\{f_0,\ \ldots,\ f_n\right\}$ è un'altra base di $V$ che soddisfa la condizione sopra, allora $\basis$ è proporzionale a $\basis$, cioè $\exists\lambda\in\kamp\setminus\left\{0\right\}\ \colon f_i=\lambda e_i\ \forall i=0,\ \ldots,\ n$.
\end{theorema}
\begin{demonstration}
	Sia $P_i=\left[v_i\right]$ al variare di $i=0,\ \ldots,\ n+1$. I punti $P_0,\ \ldots,\ P_n$ sono indipendenti\footnote{Perchè se $N+2$ punti sono in posizione generale, presi $n+1$ punti fra di loro sono indipendenti.}, dunque per definizione $v_0,\ \ldots,\ v_n$ è una base di $V$. Definiamo:
	\begin{equation*}
		v_{n+1}=\lambda_0v_0+\ldots+\lambda_nv_n\quad \lambda_i\in\kamp
	\end{equation*}
	Ma allora, per l'osservazione precedente, $\lambda_i\neq 0\ \forall i$ perché i punti sono in posizione generale.\\
	Consideriamo $_0=\lambda_0v_0,\ e_1=\lambda_1v_1,\ \ldots,\ e_n=\lambda_nv_n$. Si ha che $\basis=\left\{e_0,\ \ldots,\ e_n\right\}$ è una base di $V$ perché $\lambda_i\neq 0$\ $\forall i$. Segue che:
	\begin{gather*}
		\left[e_i\right]=\left[v_i\right]=P_i\ \forall i=0,\ \ldots,\ n\\
		\left[e_0+\ldots+e_n\right]=\left[\lambda_0v_0+\ldots+\lambda_nv_n\right]=\left[v_{n+1}\right]=P_{n+1}
	\end{gather*}
Adesso, sia $\basis')\left\{f_0,\ \ldots,\ f_n\right\}$ come da ipotesi. Allora $\left[f_i\right]=P_i=\left[e_n\right]\ \forall i=0,\ \ldots,\ n$, cioè $\exists \mu_i\in\kamp\setminus\left\{0\right\}\ \colon f_i=\mu_i e_i\ \forall i=0,\ \ldots, n$. Inoltre, soddisfa anche $\left[f_0+\ldots+f_n\right]=P_{n+1}$, pertanto:
\begin{equation*}
	\left[f_0+\ldots+f_n\right]=\left[e_0+\ldots+e_n\right]
\end{equation*}
In altre parole, $\exists \mu\in\kamp\setminus\left\{0\right\}$ tale che:
\begin{equation*}
	\begin{array}{ccc}
		f_0+\ldots+f_n&=&\mu\left(e_0+\ldots+e_n\right)\\
		\shortparallel&&\\
		\mu_0e_0+\ldots+\mu_ne_n&&
	\end{array}
\end{equation*}
$e_0,\ \ldots,\ e_n$ è una base: per l'unicità della scrittura deve essere $\mu=\mu_0=\ldots=\mu_n$, cioè $f_i=\mu e_i\ \forall i=0,\ \ldots,\ n$.
\end{demonstration}
\section{Trasformazioni proiettive}
\begin{define}
	Un'applicazione $\funz{f}{\proj{V}}{\proj{V'}}$ tra spazi proiettivi si dice \textbf{trasformazione proiettiva}\index{trasformazione proiettiva} o \textbf{isomorfismo proiettivo}\seeonlyindex{isomorfismo!proiettivo}{trasformazione proiettiva} se $\exists \funz{\phi}{V}{V'}$ isomorfismo che induce un altro isomorfismo lineare:
	\begin{equation}
		\begin{tikzcd}
			\widetilde{\phi}\ \colon\\
		\end{tikzcd}
			\funztot{\ }{\proj{V}}{\proj{V'}}{\left[v\right]}{\left[\phi\left(v\right)\right]}
	\end{equation}
	Tale per cui $f=\widetilde{\phi}$.\\
	Se $V=V'$, diciamo che $f$ è una \textbf{proiettività}\index{proiettività} di $\proj{V}$.
\end{define}
\begin{demonstration}~{}
	\begin{itemize}
		\item $\widetilde{\phi}$ \textbf{è ben definita}:
		\begin{enumerate}
			\item $\phi\left(v\right)\neq 0$ perché $v\neq 0$ e $\phi$ è iniettiva, pertanto $\ker\phi=\left\{0\right\}$ e dunque l'unico vettore mappato a $0$ tramite $\phi$ è solo $0$.
			\item Se $\left[v\right]=\left[w\right]$, allora $w\sim v$, cioè $w=\lambda v$ con $\lambda\in\kamp\setminus\left\{0\right\}$; segue che per linearità di $\phi$ $\phi\left(w\right)=\lambda \left(v\right)\implies \left[\phi\left(w\right)\right]=\left[\phi\left(v\right)\right]$
		\end{enumerate}
		\item $\widetilde{\phi}$ \textbf{è iniettiva}: se $\widetilde{\phi}\left(\left[v\right]\right)=\widetilde{\phi}\left(\left[w\right]\right)$, allora
		\begin{equation*}
			\left[\phi\left(v\right)\right]=\left[\phi\left(w\right)\right]\implies\exists\lambda\in\kamp\setminus\left\{0\right\}\ \colon\phi\left(w\right)=\lambda\phi\left(v\right)=\phi\left(\lambda v\right)
		\end{equation*}
	Poichè $\phi$ è iniettiva, segue che $w=\lambda v$ e dunque $\left[v\right]=\left[w\right]$.
		\item $\widetilde{\phi}$ \textbf{è suriettiva}: infatti, se $\left[w\right]\in\proj{V'}$, essendo $\phi$ suriettiva esiste un vettore $v$ tale che $w=\phi\left(v\right)$. Segue che $\left[w\right]=\left[\phi\left(v\right)\right]=\phi\left(\left[v\right]\right)$.
	\end{itemize}
\end{demonstration}
Dato che spazi \textit{vettoriali} della \textit{stessa dimensione} sono sempre \textit{isomorfi}, due spazi \textit{proiettivi} della \textit{stessa dimensione} sono sempre \textit{isomorfi} e $\proj{V}$ è sempre isomorfo a $\proj[n]{\kamp}$, con $\dim V=n+1$.
\begin{lemming}
	Siano $\funz{\phi,\ \psi}{V}{V'}$ isomorfismi. Allora:
	\begin{equation}
		\widetilde{\phi}=\widetilde{\psi}\iff\exists\lambda\in\kamp\setminus\left\{0\right\}\ \colon\psi=\lambda\phi
	\end{equation}
\vspace{-6mm}
\end{lemming}
\begin{demonstration}~{}\\
$\impliessx$ Se $v\in\kamp\setminus\left\{0\right\}$, allora $\psi\left(v\right)=\lambda\psi\left(v\right)$. Segue:
\begin{equation*}
	\implies \widetilde{\psi}\left(\left[v\right]\right)=\left[\psi\left(v\right)\right]=\left[\psi\left(v\right)\right]=\widetilde{\psi}\left(\left[v\right]\right)
\end{equation*}
$\impliesdx$ Sia $h\coloneqq \funz{\phi^{-1}\circ \psi}{V}{V}$ automorfismo. Vogliamo mostrare che $h=\lambda Id_V$ con $\lambda\in\kamp\setminus\left\{0\right\}$. Se $v\in V\setminus\left\{0\right\}$, abbiamo:
\begin{equation*}
	\begin{array}{c}
\begin{array}{ccc}
	\widetilde{\phi}\left(\left[v\right]\right)&=&\psi\left(\left[v\right]\right)\\
	\shortparallel&&\shortparallel\\
	\left[\phi\left(v\right)\right]&&\left[\psi\left(v\right)\right]
\end{array}
\implies \lambda_v\in\kamp\setminus\left\{0\right\}\ \colon \phi\left(v\right)=\lambda_v\psi\left(v\right)
\implies h\left(v\right)=\psi^{-1}\left(\phi\left(v\right)\right)=\lambda_v v
\end{array}
\end{equation*}
Segue che $v$ è autovettore di $h\ \forall v\in V\setminus\left\{0\right\}$, in particolare ogni vettore non nullo è autovettore di $h$. Segue che $h$ è diagonalizzabile e ha un unico autovalore $\lambda$. Infatti, presi $\lambda_1$ e $\lambda_2$, si avrebbero i seguenti autovalori indipendenti:
\begin{equation*}
	v_1\in V_{\lambda_1}\setminus\left\{0\right\}\qquad v_2\in V_{\lambda_2}\setminus\left\{0\right\}
\end{equation*}
E considerato che:
\begin{equation*}
	\begin{array}{l}
		h\left(v_1\right)=\lambda_1 v_1\\
		h\left(v_2\right)=\lambda_2 v_2\\
		h\left(v_1+v_2\right)=\lambda\left(v_1+v_2\right)\\
		h\left(v_1+v_2\right)=h\left(v_1\right)+h\left(v_2\right)\\
	\end{array}
	\implies \lambda\left(v_1+v_2\right)=\lambda_1 v_1+\lambda_2 v_2
\end{equation*}
Da cui segue, in quanto $v_1,\ v_2,\ v_1+v_2\neq 0$, che $\lambda=\lambda_1=\lambda_2$ e quindi è unico.\\
Allora, $h=\lambda Id_{V}$ e pertanto $\phi=\lambda \psi$.
\end{demonstration}
\subsection{Gruppo lineare proiettivo}
\begin{observe}
	Consideriamo $\proj{V}$ e l'insieme delle proiettività $\funz{\ }{\proj{V}}{\proj{V}}$.
	\begin{itemize}
		\item La \textit{composizione} di proiettività è una \textit{proiettività} (banalmente \textit{indotta} dalla composizione delle applicazioni lineari).
		\item Poichè $Id_{\proj{V}}=\widetilde{Id_V}\implies$ L'identità $Id_{\proj{V}}$ è una \textit{proiettività}.
		\item Se $\widetilde{\phi}\! \funz{\! }{\proj{V}}{\proj{V}}$, allora $\widetilde{\phi^{-1}}=\funz{f^{-1}}{\proj{V}}{\proj{V}}$. In altre parole, l'\textit{inversa} di una proiettività è ancora una proiettività.
	\end{itemize}
L'insieme delle proiettività risulta un \textbf{gruppo} rispetto alla \textit{composizione}.
\end{observe}
\begin{define}
Il \textbf{gruppo lineare proiettivo}\index{gruppo!lineare proiettivo} $\projgl{V}$ è il gruppo delle proiettività dello spazio vettoriale $V$ con operazione la composizione di proiettività ed elemento neutro $Id_{\proj{V}}$. 
\end{define}
\subsubsection{Descrizione matriciale del gruppo lineare proiettivo}
Consideriamo gli isomorfismi $\funz{\ }{\kamp^{n+1}}{\kamp^{n+1}}$: sappiamo che la matrice associata agli isomorfismi è una matrice invertibile, cioè si ha una \textit{isomorfismo di gruppi} fra l'insieme degli isomorfismi in $\kamp^{n+1}$ al \textit{gruppo generale lineare} $\gl\left(n+1,\ \kamp\right)$:
\begin{equation*}
	\left\{\text{isomorfismi}\funz{\ }{\kamp^{n+1}}{\kamp^{n+1}}\right\}\leftrightarrow\gl\left(n+1,\ \kamp\right)
\end{equation*}
E con il gruppo lineare proiettivo si può fare? Consideriamo:
\begin{equation}
	\funztot{\oldphi}{\gl\left(n+1,\ \kamp\right)}{\projgl[n+1]{\kamp}}{\phi_A}{\widetilde{\phi}_A}
\end{equation}
 $\phi$ è \textit{omomorfismo} di gruppi \textit{suriettivo}, ma non iniettivo. Infatti, il nucleo non è \textit{triviale}:
 \begin{equation*}
 	\ker \oldphi=\left\{\phi_A\mid \phi_A=Id_{\proj[n]{\kamp}}=\widetilde{Id}_{\kamp^{n+1}}\right\}=\left\{\phi_A\mid \phi=\lambda I,\ \lambda\in\kamp\setminus\left\{0\right\}\right\}=\left\{\phi_A\mid A=\lambda I,\ \lambda\in\kamp\setminus\left\{0\right\}\right\}
 \end{equation*}
Tuttavia, possiamo per il Teorema dell'isomorfismo per i gruppi considerare il seguente diagramma commutativo:
\[\begin{tikzcd}
	{\gl\left(n+1,\ \kamp\right)} & {\projgl[n+1]{\kamp}} \\
	{\frac{\gl\left(n+1,\ \kamp\right)}{\left\{\lambda I\ \mid\ \lambda\in\kamp\setminus\left\{0\right\}\right\}}}
	\arrow["{\pi}"', from=1-1, to=2-1]
	\arrow["{\exists \overline f}"', from=2-1, to=1-2, dashed]
	\arrow["{\oldphi}", from=1-1, to=1-2]
\end{tikzcd}\]
E si ha pertanto l'isomorfismo:
\begin{equation*}
	\projgl[n+1]{\kamp}\cong \frac{\gl\left(n+1,\ \kamp\right)}{\left\{\lambda I\mid\lambda\in\kamp\setminus\left\{0\right\}\right\}}=\frac{\gl\left(n+1,\ \kamp\right)}{\left\{\lambda I\right\}}
\end{equation*}
Si può anche considerare l'isomorfismo tra $\left\{\lambda I\mid\lambda\in\kamp\setminus\left\{0\right\}\right\}$ e $\kamp\setminus\left\{0\right\}$, e riscrivere l'isomorfismo trovato come:
\begin{equation*}
	\projgl[n+1]{\kamp}\cong \frac{\gl\left(n+1,\ \kamp\right)}{\kamp\setminus\left\{0\right\}}
\end{equation*}

\begin{example}
	Consideriamo la seguente proiettività della \textit{retta proiettiva} $\proj[1]{\realset}$:
	\begin{equation*}
		\funztot{f}{\proj[1]{\realset}}{\proj[1]{\realset}}{\left(x_0\colon x_1\right)}{\left(ax_0+bx_1\colon cx_0+dx_1\right)}
	\end{equation*}
	Considerato il gruppo lineare proiettivo $\proj[2]{\realset}=\frac{\gl\left(2,\ \realset\right)}{\left\{\lambda I\right\}}$, per definizione di $f$ si ha $f=\widetilde{\phi}$. In particolare, la matrice associata a $\phi$ è:
	\begin{equation*}
		A=\left(\begin{array}{cc}
			a & b\\
			c & d
		\end{array}\right)
	\end{equation*}
	E dunque possiamo scrivere l'applicazione lineare $\phi$ come:
	\begin{equation*}
		\funztot{f}{\realset^2}{\realset^2}{\left(\begin{array}{c}
				x_0 \\
				x_1
			\end{array}\right)}{A\left(\begin{array}{c}
				x_0 \\
				x_1
			\end{array}\right)}
	\end{equation*}
	E dunque $f$ si può anche scrivere come:
	\begin{equation*}
		\funztot{f}{\proj[1]{\realset}}{\proj[1]{\realset}}{\left[v\right]}{\left[Av\right]}
	\end{equation*}
	Notiamo che se la matrice associata a $\phi$ fosse $2A$, per \textit{proporzionalità} si avrebbe comunque la stessa proiettività $f$. In modo analogo, $\lambda\in\realset\setminus\left\{0\right\}$ induce la \textit{stessa proiettività} $f$ di $A$.
\end{example}
\subsection{Proprietà delle trasformazioni proiettive}
% cercare un titolo più consono
\begin{observe}
	Se $f$ è una proiettività di $\proj{V}$ e $S\subseteq \proj{V}$ un sottospazio proiettivo, allora $f\left(S\right)$ è ancora un sottospazio proiettivo della stessa dimensione di $S$. Se $S=\proj{W}$ e consideriamo per definizione $f=\widetilde{\phi}$ con $\funz{\phi}{V}{V}$, allora:
	\begin{equation*}
		\forall \left[v\right]\in S\ f\left(\left[v\right]\right)=\widetilde{\phi}\left(\left[v\right]\right)=\left[\phi\left(v\right)\right],\ \phi\left(v\right)\in W
	\end{equation*}
	\begin{equation}
		f\left(S\right)=\proj{\phi\left(W\right)}
	\end{equation}
\vspace{-6mm}
\end{observe}
\begin{define}
	Due sottoinsiemi $A,\ B$ di $\proj{V}$ si dicono \textbf{proiettivamente equivalenti}\index{proiettivamente equivalenti} se $\exists f$ proiettività di $\proj{V}$ tale che:
	\begin{equation}
		B=f\left(A\right)
	\end{equation}
\vspace{-6mm}
\end{define}
\begin{example}
	Due sottospazi proiettivi di $\proj{V}$ della \textit{stessa} dimensione sono sempre \textit{proiettivamente equivalenti}.
\end{example}
\begin{theorema}
	Siano $\proj{V}$ e $\proj{V'}$ di dimensione $n$. Siano:
	\begin{itemize}
		\item $P_0,\ \ldots,\ P_{n+1}\in\proj{V}$ in posizione generale.
		\item $Q_0,\ \ldots,\ Q_{n+1}\in\proj{V'}$ in posizione generale.
	\end{itemize}
Allora $\exists!\funz{f}{\proj{V}}{\proj{V'}}$ trasformazione proiettiva tale che $f\left(P_i\right)=Q_i\ \forall i=0,\ \ldots,\ n+1$.\\
In particolare: se una proiettività fissa $n+2$ punti in posizione generale, allora è l'identità.
\end{theorema}
\begin{demonstration}
	\begin{itemize}
		\item \textbf{Esistenza}: Siano, $\forall i$:
		\begin{itemize}
			\item $P_i=\left[v_i\right]\ v_i\in V$.
			\item $Q_i=\left[w_i\right]\ w_i\in V'$.
		\end{itemize}
	Sappiamo, dall'osservazione a pag. \ref{puntigeneraleindipendentiosserva}, che:
	\begin{itemize}
		\item $v_0,\ \ldots,\ v_n$ è base di $V$, con $v_{n+1}=\lambda_0v_0+\ldots+\lambda_n v_n$ con $\lambda_i\neq 0\ \forall i$.
		\item $w_0,\ \ldots,\ w_n$ è base di $V'$, con $w_{n+1}=\mu_0w_0+\ldots+\mu_n w_n$ con $\mu_i\neq 0\ \forall i$.
	\end{itemize}
		A meno di cambiare i rappresentanti dei punti, possiamo supporre senza perdita di generalità che $\lambda_i=\mu_i=1$. Si ha dunque:
		\begin{gather*}
			v_{n+1}=v_0+\ldots+v_n\\
			w_{n+1}=w_0+\ldots+w_n
		\end{gather*}
	Sia $\funz{\phi}{V}{V'}$ l'applicazione lineare tale per cui $\phi\left(v_i\right)=w_i\ \forall i=0,\ \ldots,\ n$. Per linearità:
	\begin{equation*}
		\phi\left(v_{n+1}\right)=\phi\left(v_0+\ldots+v_n\right)=\phi\left(v_0\right)+\ldots+\phi\left(v_n\right)=w_0+\ldots+w_n=w_{n+1}
	\end{equation*}
Poiché $\im \phi$ contiene una base per costruzione, $\phi$ è suriettiva. In particolare, essendo endomorfismo ($\dim V=\dim V'$), $\phi$ è anche \textit{isomorfismo}.\\
Allora $f\coloneqq\widetilde{\phi}\funz{\ }{\proj{V}}{\proj{V'}}$ è una \textit{trasformazione proiettiva} e:
\begin{equation*}
	f\left(P_i\right)=f\left(\left[v_i\right]\right)=\left[\phi\left(v_i\right)\right]=\left(w_i\right)=Q_i\ \forall i=0,\ \ldots,\ n+1
\end{equation*}
\item \textbf{Unicità}: sia $\funz{g}{\proj{V}}{\proj{V'}}$ un'altra trasformazione proiettiva tale che $g\left(P_i\right)=Q_i\ \forall i=0,\ \ldots,\ n+1$. Per definizione, esiste $\funz{\psi}{V}{V'}$ isomorfismo per cui $g=\widetilde{\psi}$ e:
\begin{equation*}
	\left[\psi\left(v_i\right)\right]=\left[w_i\right]\ \forall i
\end{equation*}
Si ha che $\exists a_i\in\kamp\setminus\left\{0\right\}$ tale che $\psi\left(v_i\right)=a_iw_i$. Allora:
\begin{equation*}
	\begin{array}{ccccc}
		a_{n+1}w_{n+1}&=&\psi\left(v_{n+1}\right)&=&\psi\left(v_0+\ldots+v_n\right)\\
		\shortparallel&&&&\shortparallel\\
		a_{n+1}\left(w_0+\ldots+w_n\right)&&&&\psi\left(v_0\right)+\ldots+\psi\left(v_n\right)\\
		\shortparallel&&&&\shortparallel\\
		a_{n+1}w_0+\ldots+a_{n+1}w_n&&&&a_0w_0+\ldots+a_nw_n
	\end{array}
\end{equation*}
Poiché $w_0,\ \ldots,\ w_n$ è base, la scrittura è unica. Segue che $a_0=a_1=\ldots=a_{n+1}=a$. Allora:
\begin{equation*}
	\begin{array}{l}
		\psi\left(v_i\right)=aw_i=a\phi\left(v_i\right)\\
		\implies \psi=a\phi\\
		\implies g=\widetilde{\psi}=\widetilde{\phi}=f
	\end{array}
\end{equation*}
	\end{itemize}
\end{demonstration}
\begin{examples}
	\begin{itemize}
		\item In una \textit{retta proiettiva} ($\dim 1$), una proiettività è determinata dalle immagini di $3$ \textit{punti distinti}, dato che è equivalente alla condizione di ‘‘\textit{punti in posizione generale}''.
		\item In un \textit{piano proiettivo} ($\dim 2$), una proiettività è determinata dalle \textit{immagini} di $4$ punti, a $3$ a $3$ \textit{non allineati}.
		\item Se $A,\ B\subseteq \proj{V}$ sono insiemi finiti, ciascuno contenente $k$ punti in posizione generale, con $k\leq n+2$, allora $A$ e $B$ sono sempre proiettivamente equivalenti.
	\end{itemize}
\end{examples}
\begin{example}
	Approfondiamo l'ultimo esempio. In $\proj[2]{\kamp}$ ($\dim 2$), si prenda $A=\left\{P_1,\ P_2\right\},\ B=\left\{Q_1,\ Q_2\right\}$ con $P_1\neq P_2$, $Q_1\neq Q_2$. Ho due punti distinti sia in $A$ e $B$, dunque esiste sempre una proiettività $\funz{f}{\proj[2]{\ }}{\proj[2]{\ }}$ tale che $f\left(A\right)=B$.\\
	Se invece $A$ e $B$ contengono $3$ punti, se i $3$ punti in $A$ \textit{sono allineati} mentre i $3$ punti in $B$ \textit{non} lo sono, allora $A$ e $B$ \textit{non} sono proiettivamente equivalenti.
\end{example}
\subsection{Trasformazioni proiettive in coordinate}
Supponiamo di avere fissato dei \textit{riferimenti proiettivi} su $\proj{V}$ e $\proj{V'}$, dati da delle basi $\basis$ di $V$ e $\basis'$ di $V'$, e sia $\funz{f}{\proj{V}}{\proj{V}}$ una trasformazione proiettiva. Sappiamo che $f=\widetilde{\phi}$ con $\funz{\phi}{V}{V'}$ isomorfismo lineare.\\
Sia $A\in\gl\left(n+1,\ \kamp\right)$ la matrice associata a $\phi$ rispetto alle basi $\basis$ e $\basis'$. Abbiamo visto che $\phi$ è determinata solo a meno di multipli: chiaramente, lo stesso è vero anche per $A$.\\
Siano allora:
\begin{gather*}
	P=\left(x_0\colon\ldots\colon x_n\right)\in\proj{V}\\
	f\left(P\right)=\left(y_0\colon\ldots\colon y_n\right)\in\proj{V'}
\end{gather*}
Allora $\exists\rho\in\kamp\setminus\left\{0\right\}$ tale che $\rho y=Ax$.
\begin{observe}\textsc{Cambiamenti di coordinate.}\\
Se in $\proj{V}$ abbiamo due riferimenti proiettivi, uno dalla dalla base $\basis$, e uno dalla base $\basis'$, sia $M$ la \textit{matrice del cambiamento di base} in $V$ tale che:
\begin{equation*}
	x'=Mx
\end{equation*}
Con $x$ in coordinate rispetto alla base $\basis$ e $x'$ in coordinate rispetto alla base $\basis'$. Allora, se $P\in\proj{V}$ ha coordinate:
\begin{equation*}
	\left(x_0\colon\ldots\colon x_n\right)\text{ rispetto a }\basis\\
	\left(x_0'\colon\ldots\colon x_n'\right)\text{ rispetto a }\basis'
\end{equation*}
Esiste $\rho\in\kamp\setminus\left\{0\right\}$ tale che $\rho x'=M x$.
\end{observe}
\subsection{Punti fissi di proiettività}
\begin{define}
	Sia $\funz{f}{\proj{V}}{\proj{V}}$ una proiettività. Un \textbf{punto fisso}\index{punto!fisso} è un punto $P\in\proj{V}$ tale che:
	\begin{equation}
		f\left(P\right)=P
	\end{equation}
\vspace{-6mm}
\end{define}
Sia $\funz{\phi}{V}{V}$ un \textit{automorfismo} tale che $f=\widetilde{\phi}$, e sia $P=\left[v\right]$, con $v\in V\setminus\left\{0\right\}$. Allora:
\begin{equation*}
	\begin{array}{ll}
		& f\left(P\right)=\left[\phi\left(v\right)\right]=\left[v\right]\\
		\iff & \exists\lambda\in\kamp\setminus\left\{0\right\}\ \colon \phi\left(v\right)=\lambda v\\
		\iff & v\text{ è un autovettore per }\phi
	\end{array}
\end{equation*}
In particolare, $\phi$ è invertibile, dunque \textit{non} ha l'autovalore \textit{nullo}. Segue che i punti fissi di $f$ sono tutti e soli i punti $\left[v\right]$ con $v$ autovettore di $\phi$.
\begin{observe}~{}
	\begin{enumerate}
		\item Se $\kamp=\complexset$, allora ogni proiettività ha almeno un punto fisso, dato che $\phi$ ha sempre almeno un autovettore.
		\item Se $\kamp=\realset$ e $\dim\proj{V}=n$, allora $\dim V=n+1$. Il \textit{polinomio caratteristico} $C_\phi\left(t\right)\in\realset\left[t\right]$ ha grado $n+1$. Se $n$ è \textit{pari}, $\phi$ ha almeno un autovalore, dato che il polinomio caratteristico ha grado $n+1$ \textit{dispari}: infatti, o è di grado \textit{uno} (e quindi ha banalmente soluzione) oppure, in quanto si può decomporre in fattori a coefficienti reali al più di grado \textit{due}, ammetterà \textit{sempre} almeno un fattore di grado \textit{uno}.
		\item Portiamo un controesempio al caso $n$ dispari. Sia $\funztot{f}{\proj{\realset}}{\proj{\realset}}{\left(x\colon y\right)}{\left(-y\colon x\right)}$. La matrice $A$ associata a $f$ è:
		\begin{equation*}
			A=\left(\begin{array}{cc}
				0 & -1 \\ 
				1 & 0
			\end{array}\right)
		\end{equation*}
	Il polinomio caratteristico \textit{non} ha radici \textit{reali}:
	\begin{equation*}
		C_A\left(t\right)=\det\left(\begin{array}{cc}
			-t & -1 \\ 
			1 & -t
		\end{array}\right)=t^2-1
	\end{equation*}
Segue che $A$ non ha autovettori reali e pertanto $f$ \textit{non} ha punti fissi.
\item In generale, l'\textit{insieme} dei punti fissi di $\funz{f}{\proj{V}}{\proj{V}}$ è dato da:
\begin{equation*}
	\left\{\proj{V_{\lambda}}\mid\lambda\text{ autovalore di }\phi\right\}
\end{equation*}
Questo è un insieme di sottospazi proiettivi a 2 a 2 disgiunti.
 	\end{enumerate}
\end{observe}
\begin{define}
	Se $S\subseteq\proj{V}$ è un sottospazio, diciamo che $S$ è \textbf{fisso} per $f$ proiettività se:
		\begin{equation}
		f\left(S\right)=S
	\end{equation}
	\vspace{-6mm}
\end{define}
\subsection{Impratichiamoci! Trasformazioni proiettive}
\begin{exercise}
	In $\proj[1]{\realset}$ determinare la proiettività $f$ tale che:
	\begin{equation*}
		f\left(2\colon 1\right)=\left(1\colon1\right)\quad f\left(1\colon 2\right)=\left(0\colon1\right)\quad
		f\left(1\colon -1\right)=\left(1\colon0\right)
	\end{equation*}
\end{exercise}
\begin{solution}
Notiamo che i punti:
\begin{equation*}
	\left(2\colon 1\right)\quad\left(1\colon 2\right)\quad\left(1\colon -1\right)
\end{equation*}
E:
\begin{equation*}
		\left(1\colon 1\right)\quad\left(0\colon 1\right)\quad\left(1\colon 0\right)
\end{equation*}
Sono distinti, dunque sono in posizione generale e la proiettività è garantita. Prendiamo la generica matrice $A=\left(\begin{array}{cc}
	a & b\\
	c & d
\end{array}\right)$ associata a $\phi$ indotta da $f$ e consideriamo $\rho y=Ax$:
\begin{equation*}
	\begin{cases}
		\rho y_0=ax_0+bx_1\\
		\rho y_1=cx_0+dx_1
	\end{cases}
\end{equation*}
Imponiamo il passaggio per $f\left(2\colon 1\right)=\left(1\colon1\right)$:
\begin{equation*}
	\begin{cases}
		\rho=1a+b\\
		\rho=2c+d
	\end{cases}\implies 2a+b=2c+d
\end{equation*}
In sostanza, \textit{eliminiamo} il parametro $\rho$ per ottenere un'equazione lineare \textit{omogenea} tra gli elementi della matrice.\\
Facciamo lo stesso con i rimanenti punti $f\left(1\colon 2\right)=\left(0\colon1\right)$ e $	f\left(1\colon -1\right)=\left(1\colon0\right)$, utilizzando rispettivamente $\mu y=Ax$ e $\alpha y=Ax$:
\begin{gather*}
	\begin{cases}
		0=a+2b\\
		\mu=c+2d
	\end{cases}\implies a+2b=0\\
	\begin{cases}
		\alpha=a-b\\
		0=c-d
	\end{cases}\implies c-d=0
\end{gather*}
Costruiamo così un sistema lineare omogeneo di $3$ equazioni in $4$ incognite $a,\ b,\ c,\ d$, con una matrice dei coefficienti di rango $3$:
\begin{equation*}
	\begin{cases}
		2a+b=2c+d\\
		a+2b=0\\
		c-d=0
	\end{cases}\implies \begin{cases}
	a=2c\\
	b=-c\\
	c=c\\
	d=c
\end{cases}\implies
A=\left(\begin{array}{cc}
	2c & -c\\
	c & c
\end{array}\right)=c\left(\begin{array}{cc}
1 & -1\\
1 & 1
\end{array}\right)
\end{equation*}
A meno di multipli, $A=\left(\begin{array}{cc}
	1 & -1\\
	1 & 1
\end{array}\right)$ è la matrice cercata. Segue dunque che la proiettività cercata è:
\begin{equation*}
	\funztot{f}{\proj[1]{\realset}}{\proj[1]{\realset}}{\left(x_0\colon x_1\right)}{\left(2x_0-x_1\colon x_0+x_1\right)}
\end{equation*}
\end{solution}
\section{Geometria affine e geometria proiettiva}
Abbiamo già accennato all'esistenza di una relazione che intercorre fra \textit{geometria affine} e \textit{geometria proiettiva}. Diamo innanzitutto qualche richiamo dei concetti della geometria affine.
\begin{define}
	Sia $V$ uno spazio vettoriale di dimensione finita su un campo $\kamp$. Uno \textbf{spazio affine}\index{spazio!affine} di dimensione $n$ su $V$ (con spazio vettoriale associato $V$ di dimensione $n$ ) è un insieme $\aff{V}$ non vuoto di \textit{punti} (elementi) tale che sia data un'applicazione:
	\begin{equation*}
		\funztot{\ }{\aff{V}\times\aff{V} }{V}{\left(P,\ Q\right)}{\overrightarrow{PQ}}
	\end{equation*}
	Che alla coppia di punti $\left(P,\ Q\right)$ associa il vettore di $V$ con punto iniziale $P$ e punto finale $Q$ e tale che siano
	soddisfatti i seguenti assiomi:
	\begin{enumerate}
		\item $\forall P\in\aff{V},\ \forall v\in V$ esiste un unico punto $Q\in\aff{V}$ tale che $\overrightarrow{PQ}=v$.
		\item $\forall P,\ Q,\ R\in\aff{V}$ terna di punti di $\aff{V}$ si ha $\overrightarrow{PQ}+\overrightarrow{QR}=\overrightarrow{PR}$.
	\end{enumerate}
\end{define}
\begin{define}
	Un \textbf{riferimento affine}\index{riferimento!affine} $\mathcal{R} = (O,\  e_1,\  e_2,\ \ldots,\  e_n)$ sullo spazio $\aff{V}$ è assegnato fissando un punto $O\in \aff{V}$ detta \textbf{origine}\index{origine!affine} ed una base $\basis = (e_1,\  e_2,\ \ldots,\  e_n)$ di $V$. Dunque, per ogni $P\in \aff{V}$ si ha la $n$-upla $(X_1,\  X_2,\ \ldots,\  X_n)$ dette \textit{coordinate affini}\index{coordinate!affini} del punto $P\in\aff{V}$ (uniche per riferimento affine fissato) tale per cui:
	\begin{equation}
		P=\overrightarrow{OV}=x_1e_1+\ldots+x_ne_n
	\end{equation}
\vspace{-6mm}			 
\end{define}
Per i nostri scopi, parleremo spesso degli spazi affini di dimensione $n$ su $\kamp$.
\begin{define}
	Un'\textbf{affinità}\index{affinità} o \textbf{trasformazione lineare affine}\seeonlyindex{trasformazione lineare affine}{affinità} di $\aff{\kamp^n}$ è un'applicazione:
	\begin{equation}
		\funz{\phi}{\aff{\kamp^n}}{\aff{\kamp^n}}
	\end{equation}
Della forma $\phi\left(x\right)=Ax+b$ con $A\in\gl\left(n,\ \kamp\right)$ un'applicazione lineare invertibile e $b$ una \textit{traslazione}.
\end{define}
\begin{define}
	Un \textbf{sottospazio affine}\index{sottospazio!affine} di $\aff{\kamp^n}$ è un \textit{traslato} di un sottospazio vettoriale $W\subseteq \kamp^n$:
	\begin{equation}
		S=W+x_0=\left\{w+x_0\mid w\in W,\ x_0\in\aff{W}\right\}
	\end{equation}
\vspace{-6mm}
\end{define}
\begin{observe}~{}
	\begin{itemize}
		\item $W$ è l'unico traslato di $S$ per l'origine ($x_0=O$) e si dice \textbf{sottospazio direttore}  di $S$\index{sottospazio!direttore}, cioè ne dà appunto la \textit{direzione}. Si definisce $\dim S\coloneqq\dim W$.
		\item Un punto in $\aff{\kamp^n}$ è un sottospazio affine di dimensione $0$ ($W=\left\{0\right\}$; dopotutto non ha particolarmente senso parlare di direzione del punto).
		\item Una \textbf{retta affine}\index{retta!affine} $r$ in $\aff{\kamp^n}$ è un sottospazio affine di $\dim 1$: $W=\lin{v}$, cioè $r$ si può individuare assegnando un punto $P\in r$ e un qualsiasi vettore $v$ \textit{parallelo} alla retta $r$.
		\item Un \textbf{piano affine}\index{piano!affine} $\pi$ in $\aff{\kamp^n}$ è un sottospazio affine di $\dim 2$: $W=\lin{v,\ w}$, cioè $\pi$ si può individuare assegnando un punto $P\in r$ e una coppia di vettori l.i. \textit{paralleli} al piano $\pi$.
		\item Un \textbf{iperpiano affine}\index{iperpiano!affine} è un sottospazio di dimensione $n+1$.
		\item Due sottospazi affini della stessa dimensione si dicono \textbf{paralleli}\index{parallelo} se hanno lo \textit{stesso} sottospazio direttore.
	\end{itemize}
\end{observe}
\begin{example}
Consideriamo $r=W+x_0$ retta affine, che ha dunque $\dim r=\dim W=1$. $W$ è la retta vettoriale in $\kamp^n$, mentre un qualunque $v\in W\setminus\left\{0\right\}$ è la \textit{direzione} della retta.
\end{example}
Un sottospazio affine $S\subseteq \kamp^n$ può essere descritti con equazioni cartesiane oppure in forma parametrica.\\
	\textbf{Equazioni cartesiane}. $S$ è visto come l'insieme delle \textit{soluzioni} del seguente sistema lineare:
	\begin{equation}
		Ax=b\qquad\left(\begin{array}{c}
			X_1\\
			\vdots\\
			X_n
		\end{array}\right)\in\aff{\kamp^{n}}
	\end{equation}
Con $b$ che descrive la traslazione dovuta a $x_0\in\aff{W}$.
In tal caso $W$ è il sottospazio vettoriale delle soluzioni del sistema lineare omogeneo associato:
\begin{equation}
	Ax=0
\end{equation}
\textbf{Forma parametrica}. Supponiamo $\dim S=\dim W=m$. Siano $v_1,\ \ldots,\ v_m\in\kamp^n$ i vettori di una base di $W$; rispetto ad una base di $\kamp^n$, e dunque rispetto ad un sistema di riferimento affine con origine $O$, essi sono espressi nelle componenti:
\begin{equation*}
	v_i=\left(V_{i,1},\ \ldots,\ V_{i,n}\right)\in\aff{\kamp^n}
\end{equation*}
Consideriamo $S=W+c$, con il punto $c=\left(C_1,\ \ldots,\ C_n\right)$ rispetto allo stesso sistema affine di prima.\\
I punti $x$ di $S$ in forma parametrica sono dati da:
\begin{equation}
	x=t_1v_1+\ldots+t_mv_m+c\quad t_1,\ \ldots,\ t_m\in\kamp
\end{equation}
Da cui otteniamo il sistema $n\times\left(m+1\right)$ seguente:
\begin{equation}
	\begin{cases}
		\begin{array}{l}
			X_1=t_1V_{1,1}+\ldots+t_mV_{m,1}+C_1\\
			\vdots\\
			X_n=t_1V_{1,n}+\ldots+t_mV_{m,n}+C_n\\			
		\end{array}
	\end{cases}
\end{equation}
\begin{example}
	La retta $r$ ($\dim W=1$) passante per $c$ con direzione $v$ è descritto parametricamente da:
\begin{equation*}
	\begin{cases}
		\begin{array}{l}
			X_1=tV_1+c_1\\
			\vdots\\
			X_n=tV_n+c_n			
		\end{array}
	\end{cases}
\end{equation*}	
\end{example}
Consideriamo ora lo \textit{spazio proiettivo numerico}:
\begin{equation*}
	\proj[n]{\ }=\proj[n]{\kamp}=\proj{\kamp^{n+1}}
\end{equation*}
E i punti in coordinate omogenee $\left(x_0\colon \ldots\colon x_n\right)$ rispetto ad un dato sistema di riferimento proiettivo.
Consideriamo il seguente sottoinsieme di $\proj[n]{\ }$:
\begin{equation}
	U_0\coloneqq \left\{P=\left(x_0\colon\ldots\colon x_n\right)\in \proj[n]{\ }\mid x_0\neq 0\right\}
\end{equation}
La condizione $x_0\neq 0$ è \textit{ben posta}; infatti, se $\lambda\in\kamp\setminus\left\{0\right\}$, allora $x_0\neq 0\iff\lambda x_0\neq 0$.\\
Consideriamo anche il suo complementare, che è l'iperpiano coordinato rispetto alla prima coordinata omogenea:
\begin{equation}
	\proj[n]{\ }\setminus=H_0=\left\{P=\left(x_0\colon\ldots\colon x_n\right)\in \proj[n]{\ }\mid x_0= 0\right\}=\left\{P=\left(0\colon\ldots\colon x_n\right)\in \proj[n]{\ }\right\}
\end{equation}
Sia $P\in U_0$: allora essendo $a_0\neq 0$ si ha $P=\left(a_0\colon\ldots\colon a_n\right)=\left(1\colon\frac{a_1}{a_0}\ldots\colon \frac{a_n}{a_0}\right)$. In particolare, $\frac{a_1}{a_0},\ \ldots,\ \frac{a_n}{a_0}$ sono univocamente determinate da $P$.
\begin{example}
 Sia $\proj[2]{\realset}=\left\{\text{rette vettoriali in }\realset^3\right\}$ con punti di componenti $\left(x_0\colon x_1\colon x_2\right)$. Allora $H_0$ è una retta proiettiva in $\proj[2]{\realset}$ e risulta:
 \begin{equation*}
 	\begin{array}{ll}
 		H_0 & =\left\{P=\left(x_0\colon x_1\colon x_2\right)\in \proj[n]{\ }\mid x_0=0\right\}=\left\{P=\left(0\colon x_1\colon x_2\right)\in \proj[n]{\ }\right\} \\
 		& =\left\{\text{rette vettoriali di }\realset^3\text{ contenute nel piano affine }x_0=0\right\}
 	\end{array}
 \end{equation*}
	Infatti, prendiamo $\aff{\realset^3}$ e consideriamo il piano $x_0=1$, parallelo al piano $x_0=0$. Se $r\subseteq \realset^3$ è una retta vettoriale che \textit{non} appartiene al piano affine $\left\{x_0=0\right\}$ ($r\nsubseteq \left\{x_0=0\right\}$), $r$ interseca il piano $x_0=1$ in un solo punto! In particolare, se $r$ ha direzione $\left(a_0,\ a_1,\ a_2\right)$, il punto nel piano $\left\{x_0=1\right\}$ avrà coordinate $\left(\frac{a_1}{a_0},\ \frac{a_2}{a_0}\right)$.
\end{example}
Possiamo identificare $U_0\subseteq\proj[n]{\ }$ con $\aff{\kamp^n}$. Consideriamo le due funzioni seguenti:
\begin{equation}
	\funztot{j=j_0}{\aff{\kamp^n}}{U_0\subseteq \proj[n]{\ }}{\left(X_1,\ \ldots,\ X_n\right)}{\left(1\colon\ x_1\colon \ldots\colon X_n\right)}\\
	\funztot{\oldphi}{U_0\subseteq \proj[n]{\ }}{\aff{\kamp^n}}{\left(x_0\colon\ \ldots\colon X_n\right)}{\left(\frac{x_1}{x_0},\ \ldots,\ \frac{x_n}{x_0}\right)}
\end{equation}
\begin{itemize}
	\item $\oldphi$ è ben definita, dato che $x_0\neq 0$ per definizione di $U_0$.
	\item $j$ e $\oldphi$ sono l'una l'inversa dell'altra:
	% https://q.uiver.app/?q=WzAsNixbMCwwLCJcXGFmZntcXGthbXBebn0iXSxbMSwwLCJVXzAiXSxbMiwwLCJcXGFmZntcXGthbXBebn0iXSxbMCwxLCJcXGxlZnQoWF8xLFxcIFxcbGRvdHMsXFwgWF9uXFxyaWdodCkiXSxbMSwxLCJcXGxlZnQoMVxcY29sb24gWF8xXFxjb2xvbiBcXGxkb3RzXFxjb2xvbiBYX25cXHJpZ2h0KSJdLFsyLDEsIlxcbGVmdChYXzEsXFwgXFxsZG90cyxcXCBYX25cXHJpZ2h0KSJdLFswLDEsImoiXSxbMSwyLCJcXG9sZHBoaSJdLFszLDQsIiIsMCx7InN0eWxlIjp7InRhaWwiOnsibmFtZSI6Im1hcHMgdG8ifX19XSxbNCw1LCIiLDAseyJzdHlsZSI6eyJ0YWlsIjp7Im5hbWUiOiJtYXBzIHRvIn19fV1d
	\[\begin{tikzcd}
		{\aff{\kamp^n}} & {U_0} & {\aff{\kamp^n}} \\[-25pt]
		{\left(X_1,\ \ldots,\ X_n\right)} & {\left(1\colon X_1\colon \ldots\colon X_n\right)} & {\left(X_1,\ \ldots,\ X_n\right)}
		\arrow["{j}", from=1-1, to=1-2]
		\arrow["{\oldphi}", from=1-2, to=1-3]
		\arrow[from=2-1, to=2-2, maps to]
		\arrow[from=2-2, to=2-3, maps to]
	\end{tikzcd}\]
% https://q.uiver.app/?q=WzAsNixbMCwwLCJVXzAiXSxbMSwwLCJcXGFmZntcXGthbXBebn0iXSxbMiwwLCJVXzAiXSxbMCwxLCJcXGxlZnQoeF8wXFxjb2xvbiBcXGxkb3RzXFxjb2xvbiB4X25cXHJpZ2h0KSJdLFsxLDEsIlxcbGVmdChcXGZyYWN7eF8xfXt4XzB9LFxcIFxcbGRvdHMsXFwgXFxmcmFje3hfbn17eF8wfVxccmlnaHQpIl0sWzIsMSwiXFxsZWZ0KDFcXGNvbG9uXFxmcmFje3hfMX17eF8wfVxcY29sb25cXGxkb3RzXFxjb2xvblxcZnJhY3t4X259e3hfMH1cXHJpZ2h0KT1cXGxlZnQoeF8wXFxjb2xvblxcbGRvdHNcXGNvbG9uIHhfblxccmlnaHQpIl0sWzAsMSwiXFxvbGRwaGkiXSxbMSwyLCJqIl0sWzMsNCwiIiwwLHsic3R5bGUiOnsidGFpbCI6eyJuYW1lIjoibWFwcyB0byJ9fX1dLFs0LDUsIiIsMCx7InN0eWxlIjp7InRhaWwiOnsibmFtZSI6Im1hcHMgdG8ifX19XV0=
\[\begin{tikzcd}
	{U_0} & {\aff{\kamp^n}} & {U_0} \\[-25pt]
	{\left(x_0\colon \ldots\colon x_n\right)} & {\left(\frac{x_1}{x_0},\ \ldots,\ \frac{x_n}{x_0}\right)} & {\left(1\colon\frac{x_1}{x_0}\colon\ldots\colon\frac{x_n}{x_0}\right)=\left(x_0\colon\ldots\colon x_n\right)}
	\arrow["{\oldphi}", from=1-1, to=1-2]
	\arrow["{j}", from=1-2, to=1-3]
	\arrow[from=2-1, to=2-2, maps to]
	\arrow[from=2-2, to=2-3, maps to]
\end{tikzcd}\]
\end{itemize}
Si ha dunque che $j$ e $\oldphi$ sono \textit{biunivoche}. In questo modo identifichiamo $U_0\subseteq \proj[n]{\ }$ con $\aff{\kamp^n}$, mentre l'iperpiano $H_0$ corrisponde allo spazio proiettivo di dimensione $n-1$; si ha dunque:
\begin{equation}
	\proj[n]{\ }=U_0\amalg H_0=\aff{\kamp^n}\amalg \proj[n-1]{\ }
\end{equation}
La coppia $\left(U_0,\ j\right)$ è detta \textbf{carta affine}\index{carta affine} di $\proj[n]{\ }$.\\
In altre parole, $\proj[n]{\ }$ si può vedere come un'estensione o \textit{ampliamento} dello spazio affine $\kamp^n$. Diciamo allora che:
	\begin{itemize}
		\item I punti di $H_0$ sono detti \textbf{punti impropri}\seeonlyindex{punto!improprio}{punto!all'infinito} o \textbf{punti all'infinito}\index{punto!all'infinito}.
		\item $H_0$ è detto \textbf{iperpiano improprio}\seeonlyindex{iperpiano!improprio}{iperpiano!all'infinito} o \textbf{iperpiano all'infinito}\index{iperpiano!all'infinito}.
		\item I punti di $U_0=\aff{\kamp^n}$ sono detti \textbf{punti propri}\index{punto!proprio}.
	\end{itemize}
\begin{intuit}
In molti casi, possiamo liberamente parlare di $\aff{\kamp^n}$ come lo spazio vettoriale $\kamp^n$ inteso in senso \textit{geometrico} come insieme di punti con un punto qualunque come origine.
\end{intuit}
\begin{example}
	Consideriamo la retta proiettiva $\proj[1]{\kamp}$. L'iperpiano all'infinito è:
	  \begin{equation*}
	 		H_0=\left\{P=\left(x_0\colon x_1\right)\in \proj[1]{\ }\mid x_0=0\right\}=\left\{\left(0\colon 1\right)\right\}
	 \end{equation*}
 Mentre invece l'insieme dei punti propri è:
 \begin{equation*}
 	U_0=\left\{P=\left(x_0\colon x_1\right)\in \proj[1]{\ }\mid x_0\neq 0\right\}=\left\{\left(0\colon 1\right)\right\}
 \end{equation*}
In particolare, si ha la corrispondenza biunivoca $U_0\stackrel{1\colon1}{\leftrightarrow}\kamp$:
\begin{equation*}
	\left(x_0\colon x_1\right)=\left(1\colon \frac{x_1}{x_0}\right)\mapsto \frac{x_1}{x_0}\in\kamp
\end{equation*}
In altre parole, si può vedere la retta proiettiva come il campo $\kamp$ con l'aggiunto di un unico punto, l'\textit{infinito} $\infty$.
\begin{equation}
\proj[1]{\ }=\kamp\union\left(0\colon 1\right)=\kamp\union\left\{\infty\right\}
\end{equation}
Se $\kamp=\realset$, essendo $S^1\setminus\left\{1\text{ punto}\right\}\cong \realset$, si ha:
\begin{equation}
	\proj[1]{\realset}=\realset\union\left\{\infty\right\}\cong S^1
\end{equation}
	% inserire immagine pagine 7 console fino
\end{example}
\subsection{Chiusura proiettiva di un sottospazio affine}
\begin{define}
	Sia $r\subseteq\aff{\kamp^n}$ una retta affine. La \textbf{chiusura proiettiva}\index{chiusura proiettiva}\index{chiusura!proiettiva} di $r$ è il sottospazio proiettivo $\overline{r}\subseteq\proj[n]{\ }$ generato da $r\subseteq U_0\subseteq\proj[n]{\ }$.
\end{define}
\begin{proposition}
	$\overline{r}$ è una \textit{retta proiettiva} e si ha:
	\begin{equation}
		\overline{r}=r\union P_{\infty}
	\end{equation}
Dove $P_{\infty}=\overline{r}\cap H_0$ è detto \textit{punto all'infinito} o \textit{punto improprio} della retta $r$.
\end{proposition}
\begin{demonstration}
	Sia $v\in\kamp^n\setminus\left\{0\right\}$ la direzione di $r$ e $w\in r$ un punto della retta. Allora $r$ ha descrizione parametrica in $\aff{\kamp^n}$:
	\begin{equation*}
		\begin{cases}
			\begin{array}{l}
				X_1=tv_1+w_1\\
				\vdots\\
				X_n=tv_n+w_n\\			
			\end{array}
		\end{cases}\quad t\in\kamp
	\end{equation*}
Consideriamo la retta proiettiva $R\subseteq\proj[n]{\ }$ con descrizione parametrica:
\begin{equation*}
\begin{cases}
		\begin{array}{l}
			x_0=s\\
			x_1=tv_1+sw_1\\
			\vdots\\
			x_n=tv_n+sw_n\\			
		\end{array}
	\end{cases}\quad \left(s\colon t\right)\in\proj[1]{\ }
\end{equation*}
$R$ è la retta proiettiva per i punti:
\begin{equation*}
	t=0\ \colon\ \left(1\colon w_1\colon\ldots\colon w_n\right)\quad t=1\ \colon\ \left(0\colon v_1\colon\ldots\colon v_n\right)=P_\infty
\end{equation*}
Ponendo $s=1$ otteniamo:
\begin{equation*}
	\begin{cases}
		\begin{array}{l}
			x_0=1\\
			x_1=tv_1+w_1\\
			\vdots\\
			x_n=tv_n+w_n\\			
		\end{array}
	\end{cases}\quad t\in\kamp
\end{equation*}
Al variare di $t\in\kamp$, questi sono tutti e soli i punti di $j\left(r\right)\subseteq U_0\subseteq \proj[n]{\ }$. Si ha dunque che $R$ è una retta proiettiva contente $r$:
\begin{equation*}
	\begin{array}{ll}
			R&=r\union P_{\infty}\\
			P_{\infty}&=R\cap H_0=\left\{\left(0\colon v_1\colon v_n\right)\right\}
	\end{array}
\end{equation*}
$R$ è necessariamente il più piccolo sottospazio proiettivo contenente $r$, dato che è la retta più un solo punto. Pertanto, $R=\overline{r}$.
\end{demonstration}
\begin{observe}~{}
	\begin{enumerate}
		\item Il punto improprio di $r$ è:
		\begin{equation*}
			P_{\infty}=\left(0\colon v_1\colon \ldots\colon v_n\right)
		\end{equation*}
	E corrisponde esattamente alla \textit{direzione} $v=\left(v_1,\ \ldots,\ v_n\right)$ di $r$.
	Poiché $P_\infty=\left[v\right]$ con $v$ la direzione di $r$, ne segue che l'iperpiano improprio di $\proj[n]{\kamp }$ è:
	 \begin{equation*}
		\begin{array}{ll}
			H_0 & =\proj[n-1]{\kamp}=\proj{\kamp^n}=\left\{\text{rette vettoriali in }\kamp^n\right\}=\\
			&=\left\{\text{direzioni delle rette affini in }\aff{\kamp^n}\right\}
		\end{array}
	\end{equation*}
\item Due rette affini $r_1,\ r_2\subseteq \aff{\kamp^n}$ hanno lo stesso punto improprio se e solo hanno la \textit{stessa direzione}, cioè se sono \textit{parallele}.\\
Se $r_1\neq r_2$ e $r_1$ e $r_2$ sono parallele, allora $r_1\cap r_2=\emptyset$ in $\aff{\kamp^n}$, ma $\overline{r_1}\cap \overline{r_2}={P_{\infty}}$ in $\proj[n]{\ }$. Ciò ci porta a dire che due rette parallele $r_1$ e $r_2$ si incontrano sempre all'\textit{infinito}!
\item Se $n=2$, cioè operando in $\proj[2]{\ }$, due rette distinte $r_1,\ r_2\subseteq \aff{\kamp^2}$ sono o \textit{incidenti} o \textit{parallele}, ma in $\proj[2]{\ }$ si intersecano sempre.
\item Viceversa: sia $l\subseteq \proj[n]{\ }$ una retta proiettiva. Abbiamo due casi:
\begin{itemize}
	\item $l\subseteq H_0,\ l\cap U_0= \emptyset$.
	\item $l\nsubseteq H_0\implies l+H_0=\proj[n]{\ }$.
\end{itemize}
Infatti, si ha che $l+H_0$ è un sottospazio proiettivo che contiene strettamente $H_0$, dato che $l\nsubseteq H_0$, e usando la formula di Grassmann otteniamo:
\begin{equation*}
	\dim\left(l+H_0\right)=\dim l +\dim H_0-\dim \left(l\cap H_0\right)=1+n-1+0=n=\dim \proj[n]{\ }\implies l+H_0 = \proj[n]{\ }
\end{equation*}
Sempre dalla formula di Grassmann:
\begin{equation*}
	\dim\left(l\cap H_0\right)=0\implies l\cap H_0=\left\{1 \text{punto}\right\}=\left\{Q\right\}
\end{equation*}
Cioè $l\cap U_0=l\setminus\left\{Q\right\}$. In altre parole, $l$ è una retta affine in $\aff{\kamp^n}$ con un \textit{punto improprio} $Q$ e necessariamente $l$ è la chiusura proiettiva di $l\setminus\left\{Q\right\}$.
\item Sia $n=2$, cioè operiamo in $\proj[2]{\ }$. Una retta $r\subseteq \aff{\kamp^2}$ è descritta da un'equazione lineare:
\begin{equation}
	ax+by+c=0\quad \left(a,\ b\right)\neq\left(0,\ 0\right)
\end{equation}
Con la corrispondenza biunivoca fra le coordinate $\left(x,\ y\right)$ vettoriali e $\left(X_1,\ X_2\right)$ affini. Abbiamo tuttavia anche la corrispondenza con le coordinate omogenee in $\proj[2]{\ }$, rispettivamente $\left(x\colon y\colon z\right)$ e $\left(_0\colon x_2\colon x_3\right)$.\\
Chiamiamo $\left(x\colon y\colon z\right)$ le coordinate omogenee su $\proj[2]{\ }$ con:
\begin{equation*}
	H_0=\left\{P=\left(x\colon y\colon z\right)\in \proj[2]{\ }\mid z=0\right\}=\left\{P=\left(x\colon y\colon0\right)\in \proj[2]{\ }\right\}
\end{equation*}
Allora la chiusura proiettiva $\overline{r}\subseteq \proj[2]{\ }$ di $r$ ha in $\proj[2]{\ }$ l'equazione lineare omogenea seguente:
\begin{equation}
		ax+by+cz=0
\end{equation}
Infatti, per $z=1$ si ottiene l'equazione di $r$, mentre ponendo $z=0$ (cioè il passaggio per $H_0$) troviamo il punto improprio $P_{\infty}$ di $r$:
\begin{equation*}
		\begin{cases}
		\begin{array}{l}
			z=0\\
			ax+by=0\\	
		\end{array}
	\end{cases}\quad P_{\infty}=\left(-b\colon a\colon 0\right)
\end{equation*}
La direzione della retta $ax+by+c=0$ è data dal punto improprio $P_{\infty}$ e corrisponde al vettore $\left(-b, a\colon 0\right)$.
	\end{enumerate}
\end{observe}
Generalizziamo ora il concetto di chiusura proiettiva a un generico sottospazio affine.
\begin{define}
	Dato $S\subseteq \aff{\kamp^n}$ un sottospazio affine con $S\neq \emptyset$, la chiusura proiettiva $\overline{S}\subseteq \proj[n]{\ }$ di $S$ è il sottospazio proiettivo generato da $S$. Esso ha dimensione $\dim \overline{S}=\dim S=m$.
\end{define}
\textbf{Equazioni cartesiane}. Se $S$ come sottospazio affine è dato in forma cartesiana dal sistema lineare $h\times\left(n+1\right)$ seguente:
\begin{gather*}
			Ax+b=0\qquad\left(\begin{array}{c}
		X_1\\
		\vdots\\
		X_n
	\end{array}\right)\in\aff{\kamp^{n}}\\
	\begin{cases}
	\begin{array}{l}
		a_{1,1}X_1+\ldots+a_{1,n}X_n+b_1=0\\
		\vdots\\
		a_{h,1}X_1+\ldots+a_{h,n}X_n+b_h=0\\			
	\end{array}
\end{cases}
\end{gather*} 
Allora $\overline{S}$ è descritto dal sistema lineare omogeneo  $h\times\left(n+1\right)$ in $\left(x_0,\ \ldots,\ x_n\right)$ seguente:
\begin{gather*}
	\left(A\mid b\right)x=0\qquad\left(\begin{array}{c}
		x_1\\
		\vdots\\
		x_n\\
		x_0
	\end{array}\right)\in\proj[n]{\ }\\
	\textcolor{red}{\circled{\ast}}\begin{cases}
		\begin{array}{l}
			a_{1,1}x_1+\ldots+a_{1,n}x_n+b_1x_0=0\\
			\vdots\\
			a_{h,1}x_1+\ldots+a_{h,n}x_n+b_hx_0=0\\			
		\end{array}
	\end{cases}
\end{gather*}
\begin{demonstration}
	Studiamo le dimensioni di $S$ e $\overline{S}$ usando i sistemi cartesiani appena definiti:
	\begin{equation*}
		\begin{array}{l}
			\dim S=\dim \kamp^n-\rk\left(A\right)=n-\rk\left(A\right)\\
			\dim \overline{S}=\dim \proj[n]{\ }-\rk\left(A\mid b\right)-1=\left(n+1-\rk\left(A\mid b\right)\right)-1=n-\rk\left(A\mid b\right)\\
		\end{array}
	\end{equation*}
	Per Rouché-Capelli vale $\rk A=\rk \left(A\mid b\right)$ in quanto $S\neq \emptyset$. In questo modo abbiamo dimostrato che $\dim \overline{S}=\dim S$.
\end{demonstration}
I \textit{punti impropri} del sottospazio affine $S$ sono dati da $\overline{S}\cap H_0$, con $\overline{S}$ la chiusura proiettiva di $S$ e $H_0$ l'iperpiano improprio. Dal sistema $\textcolor{red}{\circled{\ast}}$ si ha che $\overline{S}\cap H_0$ è dato da:
\begin{equation*}
	\begin{cases}
		\begin{array}{l}
			x_0=0\\
			a_{1,1}x_1+\ldots+a_{1,n}x_n=0\\
			\vdots\\
			a_{h,1}x_1+\ldots+a_{h,n}x_n=0\\			
		\end{array}
	\end{cases}
\end{equation*}
Esso corrisponde al sistema lineare omogeneo in $\kamp^n$ $Ax=0$ associato al sistema lineare $Ax+b=0$ che definisce $S$. In altre parole, $\overline{S}\cap H_0$ corrisponde al \textit{sottospazio vettoriale direttore} $W\subseteq \kamp^n$ e vale $\overline{S}\cap H_0=\proj{W}$ direzione di $S$. La sua dimensione per definizione di direzione è:
\begin{equation*}
	\dim\left(\overline{S}\cap H_0\right)=\dim S-1=\dim\overline{S}-1
\end{equation*}
\textbf{Equazioni parametriche}. Se $S$ ($\dim S=m$) è data in \textit{forma parametrica} e il sottospazio direttore $W\subseteq \kamp^n$ ha una base $\left\{v_1,\ \ldots,\ v_m\right\}$ (tali che $v_i=\left(V_{i,1},\ \ldots,\ V_{i,n}\right)\in\aff{\kamp^n}$ per un dato sistema di riferimento affine), posto $c\in S$ ricordiamo che l'espressione parametrica di $S$ è:
\begin{gather*}
	X=t_1v_1+\ldots+t_mv_m+c\quad t_1,\ \ldots,\ t_m\in\kamp\\
		\begin{cases}
		\begin{array}{l}
			X_1=t_1V_{1,1}+\ldots+t_mV_{m,1}+C_1\\
			\vdots\\
			X_n=t_1V_{1,n}+\ldots+t_mV_{m,n}+C_n\\			
		\end{array}
	\end{cases}
\end{gather*}
Allora, $\overline{S}$ è il sottospazio generato dagli $m+1$ punti \textit{indipendenti}:
\begin{equation}
	\begin{array}{cc}
		\left(0\colon v_{i,1}\colon\ldots\colon v_{in}\right)&i=1,\ \ldots,\ m
		\left(1\colon c_1\colon\ldots\colon c_n\right)
	\end{array}
\end{equation}
Pertanto, $\overline{S}$ ha descrizione parametrica:
\begin{equation*}
			\begin{cases}
		\begin{array}{l}
			x_0=t_0\\
			x_1=t_1v_{1,1}+\ldots+t_mv_{m,1}+t_0C_1\\
			\vdots\\
			x_n=t_1v_{1,n}+\ldots+t_mv_{m,n}+t_0C_n\\			
		\end{array}
	\end{cases}
\end{equation*}
Con $\left(t_0\colon\ldots\colon t_m\right)\in\proj[m]{\ }$.
\subsection{Impratichiamoci! Geometria affine e geometria proiettiva}
\begin{exercise}
	Sia $\kamp=\realset$. Allora, preso $\realset^n$ con la topologia euclidea e $\proj[n]{\realset}$ con la topologia quoziente, mostrare che $U_0$ è un aperto di $\proj[n]{\realset}$ e che $\funz{j}{\realset^n}{U_0}$
\end{exercise}
\begin{solution}
	... % aggiungere soluzione
\end{solution}


%LEZ 31 
Vediamo un esempio di proiettività di $\proj[1]{\ }$.
\begin{example}
	Si consideri $\proj[1]{\kamp} = \kamp \cup \{\infty\}$ con $\infty=(0\colon 1)$. Sia $\funz f {\proj[1]{\ }} {\proj[1]{\ }}$ una proiettività (dunque biunivoca) definita come $f(x_0\colon x_1)=(ax_0+bx_1\colon cx_0+dx_1)$. Si ha che: $f(0\colon 1)=(b\colon d)$, mentre la sua controimmagine è $f(-b\colon a)=(0\colon 1)$, infatti siccome le coordinate sono omogenee basta porre $ax_0+bx_1=0$.\newline
	Sia $t=\frac{x_1}{x_0}$ la coordinata affine su $\kamp$, se $x_0\neq 0$ tutti i punti $(x_0\colon x_1)$ si possono scrivere come $(x_0\colon x_1)=\left( 1\colon \frac{x_1}{x_0} \right)=(1\colon t)$, il che corrisponde al punto $t\in\kamp$ . Vediamo ora come si comporta l'immagine grazie a queste osservazioni se $ax_0+bx_1\neq 0$:
	\begin{gather*}
		f(x_0\colon x_1)=(ax_0+bx_1\colon cx_0+dx_1)= \left( 1\colon \frac{cx_0+dx_1}{ax_0+bx_1} \right)  =  \left( 1 \colon  \frac{ x_0 \left( c+ d \frac{x_1}{x_0} \right) }{ x_0 \left( a+ b\frac{ x_1 }{ x_0 } \right)} \right)=\left( 1\colon \frac{dt+c}{bt+a}\right)
	\end{gather*}
	Dunque la proiettività $f$ corrisponde alla trasformazione $\funz F {\kamp\cup \{\infty\}} {\kamp\cup \{\infty\}}$ con $F(t)=\begin{cases}
		\frac{dt+c}{bt+a}, & t\in\kamp, \ t\neq -\frac{a}{b}\\
		\infty, & t=-\frac{a}{b}\\
		\frac{d}{b}, & t=\infty
	\end{cases}$
	dove per $t=-\frac{a}{b}$ si ottiene $f(-b\colon a)=(0\colon 1)=\infty$, mentre la prima equazione è detta \textit{trasformazione lineare fratta}, che è definita sulla retta affine tranne dove si annulla il denominatore. \newline
	Notiamo che $F$ diventa un'affinità $\funztot F \kamp \kamp t {\alpha t+\beta}$ se e solo se il denominatore diventa una costante ponendo $b=0$, ovvero se è della forma $F(t)=\alpha$, il che significa che la proiettività fissa il punto all'infinito, ovvero $f(0\colon 1)=(0\colon 1)$, mentre la parte affine viene mandata in sè stessa.n\newline 
	Questo ragionamento si può vedere anche in dimensione superiore.
\end{example}

			\section{Spazi proiettivi complessi}
%Digressione di topologia sugli spazi proiettivi complessi
		\subsection{Varietà compatta}
\begin{remember}
	Nel caso di $\realset^n$ si è già visto che lo spazio proiettivo reale è un quoziente del tipo $\displaystyle \proj[n]{\realset}=\nicefrac{\realset^{n+1}\setminus\{0\}}{\sim}$ dunque è dotato in maniera naturale di una topologia.\newline
	Si può anche vedere come quoziente della sfera $S^n$ dove si identificano i punti antipodali grazie alla suriezione $\surr \pi {S^n} {\proj[n]{\realset}}$, è anche una varietà topologica compatta di dimensione $n$. Inoltre $\proj[1]{\realset}\cong S^1$ e abbiamo analizzato il piano proiettivo reale $\proj[2]{\realset}$.
\end{remember}


Anche nel caso complesso per $\proj[n]{\complexset}=\nicefrac{\complexset^{n+1}\setminus\{0\}}{\sim}$ si ha in maniera naturale una topologia quoziente data dalla topologia euclidea su $\complexset^{n+1}\setminus\{0\} \cong \realset^{n+1}\setminus\{0\}$.\newline
Vogliamo vedere che è una varietà topologica compatta di dimensione $\mathbf{2n}$. Questo perché mentre $\proj[n]{\realset}$ è localmente euclideo di dimensione n, si ha che $\proj[n]{\complexset}$ localmente è come $\complexset^n\cong\realset^{2n}$, dunque la dimensione topologica è $2n$.
\begin{theorema}
	$\proj[n]{\complexset}$ è una varietà topologica di dimensione $2n$.
\end{theorema}
\begin{demonstration} 
	\begin{itemize}
		\item $\proj[n]{\complexset}$ è \textit{connesso} perché è quoziente di $\complexset^{n+1}\setminus\{0\}$ che è connesso.
		\item $\proj[n]{\complexset}$ è \textit{compatto}: per avere la tesi lo si vuole vedere come quoziente di un compatto o immagine tramite una funzione continua di un compatto. Per la relazione di equivalenza, due vettori $z\sim w\iff \exists\lambda\in\complexset\setminus\{0\}\colon w=\lambda z$. Vogliamo ora restringerci alla sfera (la cui dimensione è data da $\complexset^{n+1}=\realset^{2n+2}\supset S^{2n+1}$) e dimostrare che ogni punto del quoziente è equivalente ad un punto della sfera. Per fare ciò si sfrutta la corrispondenza fra numeri complessi e reali e la norma:
		\begin{gather*}
			z_j=x_j+iy_j\implies  z=(z_1,\dots,z_{n+1})\in\complexset^{n+1}\longleftrightarrow (x_1,y_1,\dots,x_{n+1},y_{n+1})\in\realset^{2n+2}\\
			\begin{array}{ccc}
				\displaystyle \|z\|^2=\sum_{j=1}^{n+1} \lvert z_j\rvert ^2=\sum_{j=1}^{n+1}(\lvert x_j \rvert ^2 +\lvert y_j \rvert ^2) & \wedge & \displaystyle \lambda\in\complexset,\  \ \|\lambda z \| =\sqrt{\sum_{j=1}^{n+1}\lvert \lambda z_j \rvert ^2}=\lvert\lambda\rvert \| z\|
			\end{array} \\
			z\in\complexset^{n+1}\setminus\{0\}\implies \|z\|\neq 0 \ \wedge \lambda=\frac{1}{\| z\|} \implies \underbrace{\frac{1}{\|z\|}z}_{\in S^{2n+1}}\sim z \implies \pi(S^{2n+1})=\proj[n]{\complexset}
		\end{gather*}
		Nel caso reale i punti sulla sfera sono equivalenti solo se antipodali, nel caso complesso $S^{2n+1}$ invece $z,w\in S^{2n+1}$ si ha $z\sim w\iff \exists \lambda\in\complexset\setminus\{0\} \colon w=\lambda z$ siccome $w,z\in S^{2n+1}$ hanno norma unitaria, dunque $1=\| w\|=\|\lambda z\|= \ \lambda | \|z\|=|\lambda|$. Siccome ci sono infiniti numeri di norma $1$ in $\complexset$, allora ci sono infiniti numeri nella stessa classe, infatti i punti $\lambda z\in S^{2n+1}$ sono tutti equivalenti. 		
		\item $\proj[n]{\complexset}$ è $T_2$, basta dimostrare che $\pi_0$ è un'identificazione chiusa. Sia $C\subset S^{2n+1}$ un chiuso, allora $\pi_0(C)\iff \pi_0^{-1}(\pi_0(C))$ è chiusa in $S^{2n+1}$. In effetti la relazione di equivalenza su $S^{2n+1}$ viene da un'azione del gruppo $S^1=\{\lambda\in\complexset \mid |\lambda |=1\}$ rispetto al prodotto con elemento neutro $1$ quale $\funztot F {S^1\times S^{2n+1}} {S^{2n+1}} {(\lambda, z)} {\lambda z}$. Si ha che $F$ è un'applicazione continua e siccome $S^1\times S^{2n+1}$ è compatto e $S^{2n+1}$ è $T_2$ allora $F$ è chiusa. Dato un chiuso $C\subseteq S^{2n+1}$, allora data la controimmagine dell'immagine agisco sui punti di $C$ con tutti gli elementi di $S^1$, ovvero prendo tutte le orbite che intersecano $C$, ottenendo quanto segue:	
		$\pi_0^{-1}(\pi_0(C))=F(S^1\times C)\subseteq S^{2n+1} \implies \pi_0^{-1}(\pi_0(C))$ chiuso $\implies \pi_0(C)$ chiuso in $\proj[n]{\complexset} \implies \pi_0$ applicazione chiusa $\implies \pi_0$ identificazione. Pertanto $\proj[n]{\complexset}$ è anche quoziente di $S^{2n+1}$. Siccome $S^{2n+1}$ è un compatto in un $T_2$ per 
%AAA ESERCIZIO TUTORATO QUOZIENTE CERCASI	
		e siccome $\pi_0$ è un'identificazione allora $\proj[n]{\complexset}$ è $T_2$.
		\item $\proj[n]{\complexset}$ è localmente euclideo di dimensione $2n$: per dimostrarlo sfruttiamo la costruzione
%AAA COSTRUZIONE CERCASI NELLA SCORSA LEZIONE
		ovvero identificando degli aperti di $\proj[n]{\complexset}$ con $\kamp^n$, quale la famiglia $U_j\coloneqq\{z_j\neq 0\}=\proj[n]{\complexset}\setminus H_j$, con $H_j$ $j$-esimo iperpiano coordinato. Per semplicità lavoreremo con $j=0$.\newline 
		Si considera la proiezione al quoziente $\funz \pi {\complexset^{n+1}\setminus\{0\}} {\proj[n]{\complexset}}$ e la controimmagine $\pi^{-1}(U_0)=\{z\in\complexset^{n+1}\setminus\{0\}\mid z_0\neq 0\}$ aperto in $\complexset^{n+1}\setminus\{0\}$ perché abbiamo tolto un iperpiano, pertanto $U_0$ è aperto in $\proj[n]{\complexset}$. Questo vale per tutti gli $U_j$. Ricordando la costruzione 
	%AAA COSTRUZIONE DI J E \PHI CERCASI
		si considerano le mappe biunivoche e una inversa dell'altra $\funztot j {\complexset^n} {U_0} {(z_1,\dots,z_n)} {(1\colon z_1\colon \dots\colon z_n)}$ e $\funztot \oldphi {U_0} {\complexset^n} {(z_0\colon\dots\colon z_n)} {\left( \frac{z_1}{z_0},\dots,\frac{z_n}{z_0} \right)}$. Mostriamo che $j$ e $\oldphi$ cono omeomorfismi, in questo caso siccome sono già biunivoche e una inversa dell'altra basta dimostrare che sono entrambe continue.
			\begin{minipage}[t]{0.51\textwidth}\vspace{1pt}
				Per mostrare che $j$ è continua sfruttiamo il diagramma a lato, ovvero la fattorizzazione di $j$ in $\complexset^{n+1}\setminus\{0\}$ tramite:
					\begin{equation*}
						\widetilde{j}((z_1,\dots,z_n))=(1,z_1\dots,z_n)
					\end{equation*}
				e la proiezione $\pi$. Siccome $\widetilde{j}$ e $\pi$ sono continue allora anche $j$ che è la loro composizione lo è.
			\end{minipage}\hspace{-15pt}
			\begin{minipage}[t]{0.49\textwidth}\vspace{5pt}
				% https://q.uiver.app/?q=WzAsNCxbMSwwLCJcXGNvbXBsZXhzZXRee24rMX1cXHNldG1pbnVzXFx7MFxcfSJdLFswLDIsIlxcY29tcGxleHNldF5uIl0sWzIsMiwiVV8wIl0sWzEsMl0sWzEsMCwiXFx3aWRldGlsZGV7an0iXSxbMSwyLCJqIiwyXSxbMCwyLCJcXHBpIl1d
				\[\begin{tikzcd}
					& {\complexset^{n+1}\setminus\{0\}} \\
					\\
					{\complexset^n} & {} & {U_0}
					\arrow["{\widetilde{j}}", from=3-1, to=1-2]
					\arrow["{j}"', from=3-1, to=3-3]
					\arrow["{\pi}", from=1-2, to=3-3]
				\end{tikzcd}\]
			\end{minipage}\\
			\begin{minipage}[t]{0.51\textwidth}\vspace{10pt}
				Per la continuità dell'inversa $\oldphi$ invece si procede con la fattorizzazione nella controimmagine di $U_0$ tramite $\pi$ tramite una restrizione dell'inversa di $\pi$ e $\hat{\oldphi}$ che sostanzialmente ha le stesse coordinate di $\oldphi$. Definiamo dunque $\funz {p\coloneqq \pi_{|_{\pi^{-1}(U_0)}}} {\pi^{-1}(U_0)} {U_0}$ e 
			\end{minipage}\hspace{-15pt}
			\begin{minipage}[t]{0.49\textwidth}\hspace{-15pt}\vspace{5pt}
				% https://q.uiver.app/?q=WzAsNCxbMiwwLCJcXHBpXnstMX0oVV8wKSJdLFszLDAsIlxcc3Vic2V0IFxcY29tcGxleHNldF57fW4rMSJdLFswLDIsIlVfMCJdLFszLDIsIlxcY29tcGxleHNldF5uIl0sWzIsMywiXFxvbGRwaGkiLDJdLFswLDIsInAiLDJdLFswLDMsIlxcaGF0e1xcb2xkcGhpfSJdXQ==
				\[\begin{tikzcd}
					&[-35pt]& {\pi^{-1}(U_0)}\subset \complexset^{n+1} &[-15pt] {} \\
					\\
					{U_0} &&& {\complexset^n}
					\arrow["{\oldphi}"', from=3-1, to=3-4]
					\arrow["{p}"', from=1-3, to=3-1]
					\arrow["{\widehat{\oldphi}}", from=1-3, to=3-4]
				\end{tikzcd}\]
			\end{minipage}
		$\widehat{\oldphi}(z_0,\dots, z_n)=\left( \frac{z_1}{z_0},\dots,\frac{z_n}{z_0} \right)$. Entrambe sono continue, infatti la prima è la restrizione di una funzione continua e la seconda è ben definita ($U_0=\{z_0\neq 0\}$) e continua, inoltre lavora solo con vettori e non classi di equivalenza!\\
		Per dimostrare che $\oldphi$ è continua sfruttiamo le proprietà della topologia quoziente (vedasi \ref{proprietà identificazione quoziente e mappa continua indotta}), pertanto vogliamo dimostrare che $p$ è un'identificazione: è già continua e suriettiva, basta solo che sia aperta o chiusa per il teorema \ref{condizione sufficiente identificazione}.\\
		Osserviamo che $\funz \pi {\complexset^{n+1}\setminus\{0\}} {\proj[n]{\complexset}}$ è anch'essa un quoziente dato dall'azione del gruppo \footnote{questo vale in generale per gli spazi proiettivi vedasi 
%AAA ESERCIZIO GIà DATO CERCASI	
		} $G=\complexset\setminus\{0\}$ rispetto al prodotto per la moltiplicazione su $\complexset^{n+1}\setminus\{0\}$. Essa inoltre è un'azione per omeomorfismi, infatti fissato $\lambda\in\complexset\setminus\{0\}$ si ha che $\funztot {\theta_\lambda} {\complexset^{n+1}\setminus\{0\}} {\complexset^{n+1}\setminus\{0\}} z {\lambda z}$ è continua, per la proposizione \ref{proiezione azione gruppo aperta} si ha che $\funz \pi {\complexset^{n+1}\setminus\{0\}} {\proj[n]{\complexset}}$ è un'applicazione aperta, pertanto anche $p$ che è una sua restrizione ad un aperto è aperta (verifica per esercizio), pertanto dalle considerazioni di cui sopra $p$ è un'identificazione. \\
		Ne segue che $U_0$ è un aperto di $\proj[n]{\complexset}$ omeomorfo a $\complexset^n$ e quindi a $\realset^{2n}$. Allo stesso modo, $\forall j\in\{0,\dots,n\},\ U_j$ è un aperto di $\proj[n]{\complexset}$ omeomorfo a $\complexset^n$ tramite la mappa $\funztot {\oldphi_j} {U_j} {\complexset^n} {(z_0\colon\dots\colon z_n)} {\left( \frac{z_0}{z_j},\dots,\frac{z_{j-1}}{z_j}, \frac{z_{j+1}}{z_j},\dots, \frac{z_n}{z_j} \right)}$, e siccome in coordinate omogenee c'è sempre un elemento non nullo (si lavora su $\complexset^{n+1}\setminus\{0\}$) allora ogni punto sta in uno degli aperti $U_j$, pertanto $\proj[n]{\complexset}=U_0\cup\dots\cup U_n\implies \proj[n]{\complexset}$ è localmente euclideo di dimensione $2n$, dunque è una varietà topologica compatta.
	\end{itemize}
\end{demonstration}

\begin{observe}
	\begin{itemize}
		\item Su un campo $\kamp$ qualsiasi si ha sempre la mappa $\oldphi_j$ che è un corrispondenza biunivoca fra i sottoinsiemi $U_j$ (complementari di un iperpiano coordinato) e $\kamp^n$ (senza aspetto topologico) e vale sempre che lo spazio proiettivo è unione di tali $U_j$.\\
		In particolare nel caso reale, tali $U_j$ sono aperti ed il ragionamento è analogo a quello fatto poc'anzi nel caso complesso.
		\item Non abbiamo dimostrato che è a base numerabile perché essendo compatto segue dal teorema
%AAA TEOREMA SUPERFICI COMPATTE CERCASI
		, inoltre si potrebbe dimostrare facilmente "a mano" sfruttando che gli aperti $U_j$ sono a base numerabile, dunque anche la loro unione finita lo è.
	\end{itemize}
\end{observe}

	\subsubsection{Retta proiettivo complessa}
Cosa succede per la retta proiettiva complessa? Essa è una varietà topologica compatta di dimensione $2$ (dunque una superficie topologica compatta) che abbiamo già classificato! Scopriamo di che superficie si tratta.
%AAA MOTIVAZIONE CERCASI
Si ha che $\proj[n]{\complexset}=U_0\cup\{(0\colon 1)\}$ con $U_0\cong\complexset\cong\realset^2$, pertanto la retta proiettiva complessa è un piano unito ad un punto. Dimostriamo ora che è omeomorfa a $S^2$, detta anche \textit{sfera di Riemann} \index{sfera!Riemann} \index{Riemann!sfera}, e analizziamo poi la differenza con il piano proiettivo reale.
\begin{theorema}
	$\proj[1]{\complexset}\cong S^2$
\end{theorema}
\begin{intuit}
	Per ottenere la sfera si può pensare di richiudere il piano su se stesso con aggiunto il punto all'infinito $\{(0\colon 1)\}$.
\end{intuit}
\begin{demonstration}
	Costruiamo l'omeomorfismo con $S^2\subset\realset^3$ sfruttando la \textit{proiezione stereografica}. Definiamo la funzione $\funz F {S^2} {\proj[1]{\complexset}}$ prima sulla restrizione della sfera senza il polo nord $N=(0,0,1)$ e poi la estendiamo anche in $N$
		% https://q.uiver.app/?q=WzAsNCxbMCwwLCJTXjJcXHNldG1pbnVzXFx7TlxcfSJdLFsyLDAsIlxccmVhbHNldF4yIl0sWzQsMCwiXFxjb21wbGV4c2V0Il0sWzYsMCwiVV8wIl0sWzAsMSwicF9OIl0sWzEsMiwiayJdLFsyLDMsImoiXSxbMCwzLCJGX3t8X3tTXjJcXHNldG1pbnVzXFx7TlxcfX19IiwyLHsiY3VydmUiOjV9XV0=
		\[\begin{tikzcd}
			{S^2\setminus\{N\}} && {\realset^2} && {\complexset} && {U_0}
			\arrow["{p_N}", from=1-1, to=1-3]
			\arrow["{k}", from=1-3, to=1-5]
			\arrow["{j}", from=1-5, to=1-7]
			\arrow["{F_{|_{S^2\setminus\{N\}}}}"', from=1-1, to=1-7, curve={height=30pt}]
		\end{tikzcd}\]
	con $\funz {p_N} {S^2\setminus\{N\}} {\realset^2}$ proiezione stereografica da $N$, con $\funztot k {\realset^2} \complexset {(x,y)} {x+iy}$ e con $\funztot j \complexset {U_0} w {(1\colon w)}$. Poniamo $F_{|_{S^2\setminus\{N\}}}\coloneqq j\circ k\circ p$ e $F(N)\coloneqq (0\colon 1)$ e ricordiamo che $\proj[1]{\complexset}=U_0\cup\{(0\colon 1)\}$. \\
	Siccome $j,k,p$ sono omeomorfismi allora la loro composizione $F_{|_{S^2\setminus\{N\}}}$ è biunivoca e continua su $S^2\setminus\{N\}$. Perché $F$ sia continua in tutti i suoi punti basta che sia continua in un aperto contenente $N$. Per poter di nuovo sfruttare la proiezione stereografica però dal polo sud $S=(0,0,-1)$ scegliamo l'aperto $S^2\setminus\{S\}$. Dunque ora dobbiamo mostrare la continuità di $F_{|_{S^2\setminus\{S\}}}$. \\
	Scriviamo le due proiezioni stereografiche: fissato un punto $P_0=(x_0,y_0,z_0)$ sulla sfera allora consideriamo le semirette uscenti da $N$ e da $S$ che passano per $P_0$ \footnote{le equazioni sono scritte in forma parametrica, pertanto abbiamo evidenziato il punto per cui passano e la direzione $P_0-N$ per esempio}
		\begin{gather*}
			\begin{array}{ccc}
				NP_0\colon \begin{cases}
					x=0+tx_0\\
					y=0+ty_0\\
					z=1+t(z_0-1)
				\end{cases} & \wedge & SP_0\colon \begin{cases}
					x=0+tx_0\\
					y=0+ty_0\\
					z=-1+t(z_0+1)
				\end{cases}
			\end{array}
		\end{gather*}
	Per trovare le immagini delle proiezioni stereografiche intersechiamo le due semirette con il piano $xy$, ovvero poniamo $z=0$, ottenendo così
		\begin{gather*}
			\begin{array}{ccc}
				1+t(z_0-1)=0\implies t=\frac{1}{1-z_0} & \wedge & -1+t(z_0+1)=0\implies t=\frac{1}{1+z_0}
			\end{array}
		\end{gather*}
	Notiamo che i denominatori non si annullano in entrambi i casi per la definizione delle proiezioni stereografiche sulla sfera meno $N$ ed $S$ rispettivamente.\\
	Ne segue che l'immagine di $\realset^2$ tramite la mappa standard $k$ è
		\begin{gather*}
			\begin{array}{ccc}
				\left( \frac{x_0}{1-z_0}, \frac{y_0}{1-z_0} \right) \mapsto w=\frac{x_0}{1-z_0} + i\frac{y_0}{1-z_0} \in\complexset & \wedge &  \left( \frac{x_0}{1+z_0}, \frac{y_0}{1+z_0} \right) \mapsto u=\frac{x_0}{1+z_0} + i\frac{y_0}{1+z_0} \in\complexset
			\end{array}
		\end{gather*}
	Si ha che $w=\frac{1}{\overline{u}}$ e viceversa $u=\frac{1}{\overline{w}}$, poiché quando $P_0\in S^2\setminus\{N,S\}$ allora $w,u\in\complexset\setminus\{0\}$, verifichiamolo sfruttando le proprietà dei numeri complessi:
		\begin{gather*}
			\frac{1}{\overline{u}} = \frac{1}{ \frac{x_0}{1+z_0} -i\frac{y_0}{1+z_0} } = \frac{1+z_0}{x_0-iy_0} \stackrel{!}{=} \frac{(x_0+iy_0)(1+z_0)}{x_0^2+y_0^2} \stackrel{!!}{=} \frac{(x_0+iy_0)(1+z_0)}{1-z_0^2}=\frac{x_0+iy_0}{1-z_0}=w
		\end{gather*}
	dove (!) indica che il passaggio è dovuto al fatto che siccome $P_0\neq N,S$ allora $x_0+iy_0\neq 0$, mentre (!!) segue dal fatto che il punto sta sulla sfera, per cui $x_0^2+y_0^2+z_0^2=1\implies x_0^2+y_0^2=1-z_0^2$. \\
	Abbiamo dunque ottenuto $F_{|_{S^2\setminus\{N,S\}}}$ come una composizione di mappe
		% https://q.uiver.app/?q=WzAsNCxbMCwwLCJTXjJcXHNldG1pbnVzXFx7TixTXFx9Il0sWzIsMCwiXFxyZWFsc2V0XjIiXSxbNCwwLCJcXGNvbXBsZXhzZXQiXSxbNiwwLCJVXzAiXSxbMCwxLCJwX04iXSxbMSwyLCJrIl0sWzIsMywiaiJdLFswLDMsIkZfe3xfe1NeMlxcc2V0bWludXNcXHtOLFNcXH19fSIsMix7ImN1cnZlIjo1fV1d
		\[\begin{tikzcd}
			{S^2\setminus\{N,S\}} && {\realset^2} && {\complexset} && {U_0}
			\arrow["{p_N}", from=1-1, to=1-3]
			\arrow["{k}", from=1-3, to=1-5]
			\arrow["{j}", from=1-5, to=1-7]
			\arrow["{F_{|_{S^2\setminus\{N,S\}}}}"', from=1-1, to=1-7, curve={height=30pt}]
		\end{tikzcd}\]
	dove $j(w)=(1\colon w)=\left( 1\colon \frac{1}{\overline{u}} \right)=(\overline{u}\colon 1)$ in quanto si lavora con coordinate omogenee. Inoltre c'è un'estensione continua su $S^2\setminus\{S\}$ 
		% https://q.uiver.app/?q=WzAsOSxbMCwwLCJTXjJcXHNldG1pbnVzXFx7TixTXFx9Il0sWzIsMCwiXFxyZWFsc2V0XjIiXSxbNCwwLCJcXGNvbXBsZXhzZXQiXSxbOCwwLCJVXzAiXSxbMCwxLCJQIl0sWzQsMSwidSJdLFs2LDAsIlxcY29tcGxleHNldCJdLFs2LDEsIlxcb3ZlcmxpbmV7dX0iXSxbOCwxLCIoXFxvdmVybGluZXt1fVxcY29sb24gMSkiXSxbMCwxLCJwX04iXSxbMSwyLCJrIl0sWzIsNiwiYyJdLFs2LDMsImoiXSxbNCw1LCIiLDAseyJzdHlsZSI6eyJ0YWlsIjp7Im5hbWUiOiJtYXBzIHRvIn19fV0sWzUsNywiIiwwLHsic3R5bGUiOnsidGFpbCI6eyJuYW1lIjoibWFwcyB0byJ9fX1dLFs3LDgsIiIsMCx7InN0eWxlIjp7InRhaWwiOnsibmFtZSI6Im1hcHMgdG8ifX19XV0=
		\[\begin{tikzcd}
			{S^2\setminus\{S\}} && {\realset^2} && {\complexset} && {\complexset} && {U_0} \\
			{P} &&&& {u} && {\overline{u}} && {(\overline{u}\colon 1)}
			\arrow["{p_S}", from=1-1, to=1-3]
			\arrow["{k}", from=1-3, to=1-5]
			\arrow["{c}", from=1-5, to=1-7]
			\arrow["{j}", from=1-7, to=1-9]
			\arrow[from=2-1, to=2-5, maps to]
			\arrow[from=2-5, to=2-7, maps to]
			\arrow[from=2-7, to=2-9, maps to]
		\end{tikzcd}\]
	con $c$ coniugio.\\
	Dunque $F$ è continua, chiusa (compatto in $T_2$) e biunivoca, pertanto $F$ è un omeomorfismo.
%	
%questo ci dice che f ristretto a s^2-s,n è data da una composizione di mappe: proiezione stereografica da N, identificazione standard con C, mappa j in U_0. Ora al posto di w posso scrivere 1/\overline{u}, che per il quoziente è pari a  grazie alle coordinate omogenee: funziona come un'eliminzione dell'indeterminazione: anche se u=0 non è un problema perché ottengo 0:1. Nella proz ster da S il punto che va nello 0 è il polo nord, e questo ci dice che F si estende in maniera continua su S^n-s mandando P nella proiez ster da S , poi ho la mappa j_1, con tutti omeomorfisi. Dunque F è continua perché composizione di omeomorfismi.

\end{demonstration}

\begin{observe}\textsc{$\proj[1]{\complexset}\neq \proj[2]{\realset}$}\\
	Notiamo che $\proj[1]{\complexset}$ e $\proj[2]{\realset}$ sono entrambe compattificazioni del piano, ma in modo profondamente diverso!\\
	$\proj[1]{\complexset}=\complexset\cup\{\infty\}\cong S^2$, ovvero è l'unione di un piano con un punto all'infinito.\\
	$\proj[2]{\realset}=\realset^2\cup\proj[1]{\realset}\cong\realset^2\cup S^1$, ovvero il piano unito alla retta impropria $\proj[1]{\realset}$, topologicamente è l'interno del disco omeomorfo a $\realset^2$ unito al bordo che è $S^1$ con la relazione di equivalenza per i punti antipodali.
%AAA IMMAGINI SFERA E PIANO PROIETTIVO REALE CON I DISCI CERCASI
\end{observe}

		\section{Birapporto}
Torniamo ad analizzare il caso di spazi proiettivi su un campo $\kamp$ qualsiasi. Andremo a definire \\
%AAA INTRO CARINA PER IL BIRAPPORTO CERCASI
Sia $\proj[1]{V}$ una retta proiettiva, ovvero $\dim V=2$.
\begin{define}
	Siano $P_1,P_2,P_3,P_4\in\proj[1]{V}$ dei punti con $P_1,P_2,P_3$ distinti. Il \textbf{birapporto} dei punti $P_1,P_2,P_3,P_4$ (ordinati) è 
		\begin{equation} 
			\beta(P_1,P_2,P_3,P_4)=\frac{y_1}{y_0}\in\kamp\cup\{\infty\}
		\end{equation}
	con $\beta=\infty$ se $y_0=0$ e dove $(y_0\colon y_1)$ sono le coordinate di $P_4$ nel riferimento proiettivo in cui $P_1$ è il primo punto fondamentale, $P_2$ il secondo e $P_3$ il punto unità, ovvero se $P_1=(1\colon 0), P_2=(0\colon 1), P_3=(1\colon 1)$
\end{define}

\begin{observe}
	\begin{enumerate}
		\item $y_0,y_1\in\kamp\implies\beta\in\kamp\cup\{\infty\}$
		\item $\beta$ è ben definito perché $P_1,P_2,P_3$ sono distinti $\implies$ sono in posizione generale \footnote{In una retta proiettiva essere distinti equivale ad essere in posizione generale} $\implies$ determinano in maniera univoca il riferimento proiettivo per il teorema
%AAA TEOREMA CERCASI
		sul riferimento proiettivo e punti in posizione generale
		\item per ipotesi i primi tre punti sono distinti, mentre non si fanno ipotesi sul quarto punto, vediamo cosa succede in casi speciali
			\begin{gather*}
				P_4=P_1 \iff (y_0\colon y_1)=(1\colon 0)\iff \beta=0\\
				P_4=P_2\iff (y_0\colon y_1)=(0\colon 1) \iff\beta=\infty\\
				P_4=P_3\iff (y_0\colon y_1)=(1\colon 1)\iff y_0=y_1\iff\beta=1
			\end{gather*}
		dunque $\beta\in\{0,1,\infty\}$ esattamente quando $P_4$ coincide con uno dei primi 3 punti. Quindi se $P_1,P_2,P_3,P_4$ sono distinti allora $\beta\in\kamp\setminus\{0,1\}$. \\
		Viceversa se $a\in\kamp\setminus\{0,1\}$ e $P_4=(1\colon a)$ allora $\beta=a$, dunque $\beta$ assume tutti i valori possibili in $\kamp$.
	\end{enumerate}	
\end{observe}

Vogliamo ora scoprire come si calcola il birapporto in un sistema di riferimento qualsiasi e non solo quello dato nella definizione.

%2)come mai il birapporto  interessante? quale proprietà lo caratteerizza?

\begin{theorema}
	Siano $P_1,P_2,P_3,P_4\in\proj[1]{V}$ dei punti nella retta proiettiva con $P_1,P_2,P_3$ distinti. Supponiamo che $P_i=(\lambda_1\colon \mu_i), i=1,\dots,4$. Allora
		\begin{equation}
			\beta(P_1,P_2,P_3,P_4)=\frac{ \left| \begin{array}{cc}
					\lambda_1 & \lambda_4 \\
					\mu_1 & \mu_4
				\end{array} \right| \cdot \left| \begin{array}{cc}
				\lambda_2 & \lambda_3 \\
				\mu_2 & \mu_3
			\end{array} \right| } { \left| \begin{array}{cc}
			\lambda_2 & \lambda_3 \\
			\mu_2 & \mu_3
		\end{array} \right| \cdot \left| \begin{array}{cc}
		\lambda_2 & \lambda_4 \\
		\mu_2 & \mu_4
	\end{array} \right| }
		\end{equation}
\end{theorema}




\begin{demonstration}
	$P_1\neq P_2\implies (\lambda_1,\mu_1),(\lambda_2,\mu_2)$ sono una base di $\kamp^2$. Siano ora $a,b\in\kamp \colon (\lambda_3,\mu_3)=a(\lambda_1,\mu_1)+b(\lambda_2,\mu_2)=(a\lambda_1,a\mu_1)+(b\lambda_2,b\mu_2)$, ovvero faccio una combinazione lineare e porto dentro gli scalari. Per costruzione è la base che dà il riferimento proiettivo con $P_1, P_2$ punti fondamentali e $P_3$ punto unità, basta riscalare in modo tale che sia la somma degli altri due vettori. Per ottenere $P_4$, lo scrivo come combinazione lineare di tali 2 vettori: $\exists c,d\in\kamp \colon (\lambda_4,\mu_4)=c(a\lambda_1,a\mu_1)+d(b\lambda_2,b\mu_2)\implies P_4$ ha coordinate $(c\colon d)$ nel nuovo riferimento proiettivo $\implies \beta=\frac{d}{c}.$\\
	Per non appesantire la scrittura useremo come la seguente notazione per i determinanti: $\delta_{ij}=\left| \begin{array}{cc}
		\lambda_i & \lambda_j \\
		\mu_i & \mu_j
	\end{array} \right|$.\\
	Notiamo che la prima combinazione lineare dà il seguente sistema lineare di 2 equazioni in 2 incognite $a,b : \begin{cases}
		\lambda_1 a+\lambda_2 b=\lambda_3\\
		\mu_1 a+\mu_2 b=\mu_3
	\end{cases}$\\
	Risolvendo il sistema con il metodo di Cramer si ottiene:
%possibile nota sul metodo di Cramer?
	$ \displaystyle a=\frac{\left| \begin{array}{cc}
			\lambda_3 & \lambda_2 \\
			\mu_3 & \mu_2
		\end{array} \right| }{ \left| \begin{array}{cc}
		\lambda_1 & \lambda_2 \\
		\mu_1 & \mu_2
	\end{array} \right| } = \frac{\delta_{32}}{\delta_{12}}$ e $\displaystyle b=\frac{\delta_{13}}{\delta_{12}}$\\
	La seconda combinazione lineare invece dà un sistema lineare in $c,d$, dove sostituisco i valori di $a,b$ trovati : 
	\begin{gather*}
	\begin{cases}
		(a\lambda_1)c + (b\lambda_2)d=\lambda_4\\
		(a\mu_1)c + (b\mu_2)d=\mu_4
	\end{cases} \implies \begin{cases}
		\frac{\delta_{32}}{\delta_{12}}\lambda_1 c + \frac{\delta_{13}}{\delta_{12}}\lambda_2 d = \lambda_4\\
		\frac{\delta_{32}}{\delta_{12}}\mu_1 c + \frac{\delta_{13}}{\delta_{12}}\mu_2 d = \mu_4
	\end{cases} \implies \begin{cases}
		(\delta_{32}\lambda_2)c + (\delta_{13}\lambda_2)d=\delta_{12}\lambda_4\\
		(\delta_{32}\mu_2)c + (\delta_{13}\mu_2)d=\delta_{12}\mu_4	
	\end{cases}
	\end{gather*}
	Si applica ancora Cramer e si sfrutta che il determinante è lineare in ogni colonna, dunque possiamo fare uscire i $\delta_{ij}$ e riscriverli riordinando gli indici: scambiamo l'ordine delle colonne a patto di cambiare segno, tuttavia essendo una frazione e facendolo per entrambi il segno non cambia, idem per $d$:
		\begin{gather*}
			c=\frac{ \left| \begin{array}{cc}
					\delta_{12}\lambda_4 & \delta_{13}\lambda_2 \\
					\delta_{12}\mu_4 & \delta_{13}\mu_2
			\end{array} \right| }{ \left| \begin{array}{cc}
				\delta_{32}\lambda_1 & \delta_{13}\lambda_2 \\
				\delta_{32}\mu_1 & \delta_{13}\mu_2
			\end{array} \right|  } = \frac{ \cancel{ \delta_{12} } \cancel{\delta_{13}} \delta_{42} }{ \delta_{32} \cancel{\delta_{13}}\cancel{\delta_{12}} } = \frac{-\delta_{24} }{\delta_{23} }=\frac{\delta_{24}}{\delta_{23}} \\
			d=\frac{ \left| \begin{array}{cc}
				\delta_{32}\lambda_1 & \delta_{12}\lambda_4 \\
				\delta_{32}\mu_1 & \delta_{12}\mu_4
			\end{array} \right| }{ \delta_{32} \delta_{13} \delta_{12} } = \frac{ \cancel{\delta_{32}} \cancel{\delta_{12}} \delta_{14} }{\cancel{\delta_{32}} \delta_{13} \cancel{\delta_{12}} } = \frac{\delta_{14}}{\delta_{13}}\\
			\implies \beta=\frac{d}{c}=\frac{\delta_{14}}{\delta_{13}}\cdot \frac{\delta_{23}}{\delta_{24}}
		\end{gather*}
%						
\end{demonstration}
\begin{observe}
	Il birapporto può anche essere definito tramite questa formula, che è ben definita: supponiamo di moltiplicare i punti per uno scalare: succede sia al numeratore sia al denominatore, dunque si semplifica, pertanto il birapporto così definito non dipende dalla scelta delle coordinate omogenee. Inoltre al denominatore il primo determinante è sempre diverso da $0$ perché i punti sono distinti. Il secondo determinante al denominatore è nullo quando $P_2=P_4$, il che torna con quanto definito prima.	
\end{observe}

\begin{tips}
Se tutti e 4 i punti sono diversi da $(0\colon 1)$, ovvero se $\forall i,\ \lambda_i\neq 0 \\ P_i=(1\colon z_i), i=1,\dots,4$ allora $\displaystyle \beta(P_1,P_2,P_3,P_4)=\frac{ (z_4-z_1)(z_3-z_2) }{ (z_4-z_2)(z_3-z_1) }$.\\ Infatti $P_i=(\lambda_i\colon\mu_i)=(1\colon z_i)$, cioé  $z_i=\frac{\mu_i}{\lambda_i}$, per la linearità delle colonne si ottiene
	\begin{gather*}
		\left| \begin{array}{cc}
			\lambda_1 & \lambda_4 \\
			\mu_1 & \mu_4
		\end{array} \right| = \lambda_1\lambda_4 \left| \begin{array}{cc}
		1 & 1 \\
		\frac{\mu_1}{\lambda_1} & \frac{\mu_4}{\lambda_4}
		\end{array} \right|= \lambda_1\lambda_4 \left| \begin{array}{cc}
			1 & 1 \\
			z_1 & z_4
		\end{array} \right| = \lambda_1\lambda_2(z_4-z_1)
	\end{gather*}
Si procede allo stesso modo per gli altri determinanti e le $\lambda$ si semplificano.
\end{tips}
%ESERCIZIO
%Verificare che se $P_1,P_2,P_3,P_4$ sono tutti diversi da $(1\colon 0)\implies P_i=(w_i\colon 1), \forall i=1,\dots,4$, allora $\beta=\frac{ (w_2-w_1)(w_3-w_2) }{ (w_4-w_2)(w_3-w_1) }$

%LEZ 32
\begin{remember} 
	Date due rette proiettive $\proj[1]{V}$ e $\proj[1]{V'}$, e $P_1,P_2,P_3 \in \proj[1](V)$ distinti e $Q_1,Q_2,Q_3 \in \proj[1]{V'}$ distinti, esiste sempre ed è unica una trasformazione proiettiva $\funz d {\proj[1](V)} {\proj[1]{V'}}$ tale che $f(P_i)=Q_i, \ i=1,2,3$
\end{remember}
Ci domandiamo ora se è possibile farlo anche con quattro punti, per riuscirci sfruttiamo il birapporto.
\begin{theorema}
	Siano $\proj[1]{V}$ e $\proj[1]{V'}$ due rette proiettive e siano i punti $P_1,P_2,P_3,P_4\in\proj[1]{V}$ di cui i primi 3 distinti, e $Q_1,Q_2,Q_3,Q_4\in\proj[1]{V'}$ di cui i primi 3 distinti. Allora $\exists$ trasformazione proiettiva $\funz f {\proj[1]{V}} {\proj[1]{V'}}$ tale che $f(P_i)=Q_i, \forall i=1,\dots,4  \iff \beta(P_1,P_2,P_3,P_4)=\beta(Q_1,Q_2,Q_3,Q_4)$, ovvero se il birapporto delle quaterne è lo stesso.
\end{theorema}
\begin{observe}
	Consideriamo solo i primi 3 punti e scegliamone dei rappresentanti: $v_1,v_2,v_3\in V \colon P_i=[v_i],\ i=1,2,3$ e $v_3=v_1+v_2$. Dunque $\{v_1,v_2\}$ è base di $V$ che dà il riferimento proiettivo di $\proj[1]{V}$ in cui $P_1=(1\colon 0), P_2=(0\colon 1), P_3=(1\colon 1)$. Sia $P_4=[v_4]$ con $v_4=av_1+bv_2$. Allora $P_4=(a\colon b)$ e $\beta(P_i)=\frac{b}{a}$.\\
	Allo stesso modo per l'altra quaterna, siano $v'_1,v'_2,v'_3\in V' \colon Q_i=[v'_i],\ i=1,2,3$ e\\ $v'_3=v'_1+v'_2$.\\
	Siccome $P_1,P_2,P_3$ e $Q_1,Q_2,Q_3$ sono in posizione generale allora esiste ed è unica una trasformazione proiettiva $\funz f {\proj[1]{V}} {\proj[1]{V'}}$ tale che $f(P_i)=Q_i$. Inoltre $f=\widetilde{\phi}$ con $\funz \phi V {V'}$ applicazione lineare tale che $\phi(v_1)=v'_1,\ \phi(v_2)=v'_2$, ovvero porta una base di $V$ in una base di $V' \implies \phi(v_4)=\phi(av_1+bv_2)=av'_1+bv'_2 \implies f(P_4)=[\phi(v_4)]=(a\colon b)$ nel riferimento in $\proj[1]{V'}$.
\end{observe}
\begin{demonstration}~{}\\
	$\impliesdx$ Siccome la $f$ è unica e $f(P_4)=Q_4 \implies Q_4=(a\colon b)$ nel riferimento in cui $Q_1=(1\colon 0), Q_2=(0\colon 1), Q_3=(1\colon 1) \implies \beta(Q_i)=\frac{b}{a}=\beta(P_i)$.\\
	$\impliessx$ Se $\beta(Q_i)=\frac{b}{a}$ allora distinguiamo i casi in cui il birapporto è nel campo o infinito
		\begin{gather*}
			\frac{b}{a}\in\kamp \implies Q_4=\left(1\colon \frac{b}{a} \right)=(a\colon b)=f(P_4)\\
			\frac{b}{a}=\infty  \implies a=0\implies Q_4=(0\colon 1)=f(P_4)
		\end{gather*}
\end{demonstration}
\begin{corollary}
	Siano $\proj[1]{\kamp}$ e siano i punti $P_1,P_2,P_3,P_4\in\proj[1]{\kamp}$ di cui i primi 3 distinti, e $Q_1,Q_2,Q_3,Q_4\in\proj[1]{\kamp}$ di cui i primi 3 distinti. Allora $\exists$ proiettività $\funz f {\proj[1]{\kamp}} {\proj[1]{\kamp}}$ t.c. $f(P_i)=Q_i, \forall i=1,\dots,4  \iff \beta(P_i)=\beta(Q_i)$, ovvero se il birapporto delle quaterne è lo stesso.
\end{corollary}

\begin{observe}
	Sia $\mathcal{S}=\{$quaterne ordinate di punti distinti in $\proj[1]{\kamp}\}$. Siano due quaterne $\{P_1,P_2,P_3,P_4\}, \{Q_1,Q_2,Q_3,Q_4\} \in\mathcal{S}$, esse sono \textit{proiettivamente equivalenti} \index{equivalenza!proiettiva} se $\exists f$ proiettività t.c. $f(P_i)=Q_i
, \forall i=1,2,3,4$, ovvero per il teorema precedente se le due quaterne hanno lo stesso birapporto.\\
	Notiamo	che quella appena data è una relazione di equivalenza (verifica per esercizio), per cui le classi di equivalenza proiettiva di 4 punti distinti e ordinati in $\proj[1]{\kamp}$ sono in corrispondenza biunivoca con il campo meno lo $0$ e l'$1$ visto che sono 4 punti distinti, val a dire
		\begin{equation*}
			\displaystyle \nicefrac{\mathcal{S}}{\sim} \leftrightarrow \kamp\setminus\{0,1\}
		\end{equation*}
	Si ha dunque che ad ogni quaterna di punti distinti associamo il suo birapporto (applicazione suriettiva) e per ogni elemento nel campo troviamo una quaterna di punti distinti con tale birapporto (quozientando l'applicazione è iniettiva)
\end{observe}
%"il birapporto misura l'equivalenza proiettiva su punti di una retta proiettiva"

\begin{observe}
	In dimensione maggiore generalmente il birapporto non è definito, a meno che i 4 punti sono allineati su una retta proiettiva $r$.
\end{observe}


\begin{examples}~{}\\
%AAA DISEGNI CERCASI
	Nel piano proiettivo $\proj[2]{\kamp}$ consideriamo due quaterne di punti distinti quali $\{P_1,P_2,P_3,P_4\}$ e $\{Q_1,Q_2,Q_3,Q_4\}$. Grazie al birapporto analizziamo per ciascuna delle due quaterne in che posizione sono: generale (ovvero a tre a tre non allineati), o non in posizione generale, in cui si differenzia se i punti allineati sono 3 o 4.
%"Nel secondo caso ci sono tutte le possibili permutazioni fra pt allineati"
	Se i punti $P_i$ sono proiettivamente equivalenti ai punti $Q_i$, allora tali posizioni devono essere mantenute: le proiettività mandano rette in rette, posizioni generali in posizioni generali. Per contronominale, se si verificano casi diversi per le due quaterne possiamo afermare che non sono proiettivamente equivalenti.
	\begin{enumerate}
		\item $P_i$ e $Q_i$ sono in \textit{posizione generale}. Vogliamo vedere se sono proiettivamente equivalenti, per farlo dobbiamo controllare se le dimensioni sono giuste: siccome abbiamo 4 punti e $4=\dim\proj[2]{\kamp}+2$ allora $\exists !$ proiettività $f$ di $\proj[2]{\kamp}$ tale che $f(P_1)=Q_i, i=1,\dots,4$, dunque hanno lo stesso birapporto e sono sempre proiettivamente equivalenti
		\item $P_1,P_2,P_3$ allineati ma $P_4$ no, idem per i $Q_i$, ovvero $P_1,P_2,P_3\in r$ retta proiettiva. Vogliamo dimostrare che anche in questo caso le quaterne sono proiettivamente equivalenti,
%sfruttando la proiettività fra i tre punti ed estendendola al quarto punto
		Scegliamo dei rappresentanti $P_i=[v_i],\ i=1,2,3,4, v_i\in\kamp^3$ t.c. $v_3=v_1+v_2$, il che è possibile perché i punti sono allineati. Si ha che $\{v_1,v_2,v_3$ è una base di $\kamp^3\}$ visto che $P_4\notin r$ allora $v_4$ non è linearmente dipendente da $v_1,v_2$. Allo stesso modo sia $Q_i=[w_i],\ i=1,2,3,4, w_i\in\kamp^3$ t.c. $w_3=w_1+w_2$ con $\{w_1,w_2,w_4\}$ base di $\kamp^3$. \\
		Definiamo $\funz \phi {\kamp^3} {\kamp^3}$ lineare t.c. $\phi(v_1)=w_1, \phi(v_2)=w_2, \phi(v_4)=w_4\implies \phi(v_3)=\phi(v_1+v_2)=w_1+w_2=w_3$. Dunque $\funz {f=\widetilde{\phi}} {\proj[2]{\kamp}} {\proj[2]{\kamp}}$ è una proiettività che manda $P_i$ in $Q_i,\ \forall i=1,2,3,4$
		\item Siccome tutti i punti sono allineati allora è definito il loro birapporto. Se le due quaterne sono proiettivamente equivalenti, sia $\funz f {\proj[2]{\kamp}} {\proj[2]{\kamp}}$ la proiettività, essa porta una quaterna nell'altra e necessariamente una retta nell'altra, ovvero $f(r)=s$, dunque la restrizione alle due rette $\funz {f_{|_r}} r s$ porta $P_i$ in $Q_i,\ \forall i \implies \beta(P_i)=\beta(Q_i)$.\\
		Viceversa se $\beta(P_i)=\beta(Q_i)$ allora $\exists \funz g r s$ trasformazione proiettiva che manda $P_i$ in $Q_i,\ \forall i=1,2,3,4$. Si ha che $g$ si estende in maniera non unica ad una proiettività di $\proj[2]{\kamp}$. Infatti dati $r=\mathbb{P}(U),\ U\subset \kamp^3$ e $s0\mathbb{P}(W),\ W\subset\kamp^3$ (gli ultimi sono piani vettoriali), si ha che $g=\widetilde{\psi}$ con $\funz \psi U W$ isomorfismo lineare. Vogliamo estenderla ad un automorfismo lineare $\funz \phi {\kamp^3} {\kamp^3}$ scegliendo basi con due vettori nel pinao ed uno esterno, ovvero $u_1,u_2\in U$ base di $U$ e $u_3\notin U$. Dunque $\psi(u_1),\psi(u_2)$ è una base di $W$ e $w_3\notin W \implies \{u_1,u_2,u_3\}$ base di $\kamp^3$, $\{\psi(u_1),\psi(u_2),\psi(u_3) \}$ un'altra base. Ponendo $\funz \phi {\kamp^3} {\kamp^3}$ tale che $\phi(u_1)\coloneqq \psi(u_1), \phi(u_2)\coloneqq \psi(u_2), \phi(u_3)\coloneqq w_3$ si ha $f=\widetilde{\phi}$. \\
		In questo caso dunque i punti sono proiettivamente equivalenti se e solo se hanno lo stesso birapporto.
	\end{enumerate} 
\end{examples}

%STUDIO DELLA GEOMETRIA DI RETTE O CURVE NEL PIANO PROIETTIVO
		\section{Rette nel piano proiettivo}

Una retta in $\proj[2]{\kamp}$ ha equazione $r\colon a_0x_0+a_1x_1+a_2x_2=0$ che è un'equazione lineare omogenea in coordinate omogenee, dunque è determinata dai coefficienti $a_0, a_1, a_2$ dell'equazione con la proprietà che devono essere non tutti nulli e in più fissati i coefficienti l'equazione è determinata a meno di costante moltiplicativa non nulla. Dunque si può associare a $r$ un punto del piano proiettivo dato esattamente dai coefficienti delle coordinate omogenee, ovvero $(a_0\colon a_1\colon a_2)\in\proj[2]{\kamp}$ per cui si ha una corrispondenza biunivoca fra le rette in $\proj[2]{\kamp}$ e $\proj[2]{\kamp}$ (che non va pensato come lo stesso piano)
	% https://q.uiver.app/?q=WzAsNCxbMCwwLCJcXHtcXHRleHR7cmV0dGUgaW4gfSBcXHByb2pbMl17XFxrYW1wfVxcfSJdLFszLDAsIlxccHJvalsyXXtcXGthbXB9Il0sWzAsMSwiclxcY29sb24gYV8weF8wK2FfMXhfMSthXzJ4XzI9MCJdLFszLDEsIihhXzBcXGNvbG9uIGFfMVxcY29sb24gYV8yKSJdLFswLDEsIiIsMCx7InN0eWxlIjp7InRhaWwiOnsibmFtZSI6ImFycm93aGVhZCJ9fX1dLFsyLDMsIiIsMCx7InN0eWxlIjp7InRhaWwiOnsibmFtZSI6ImFycm93aGVhZCJ9fX1dXQ==
	\[\begin{tikzcd}
		{\{\text{rette in } \proj[2]{\kamp}\}} &&& {\proj[2]{\kamp}} \\
		{r\colon a_0x_0+a_1x_1+a_2x_2=0} &&& {(a_0\colon a_1\colon a_2)}
		\arrow[from=1-1, to=1-4, tail reversed]
		\arrow[from=2-1, to=2-4, tail reversed]
	\end{tikzcd}\]
Notiamo che ciò funziona bene con $\proj[2]{\kamp}$, infatti le coordinate omogenee si comportano proprio come i coefficienti dell'equazione.

\begin{example}
	Retta nel piano proiettivo reale $\proj[2]{\realset}$
		\begin{equation*}
			l_i\colon x_0+x_1+2x_2=0 \leftrightarrow (1\colon 1\colon 2)\in\proj[2]{\realset}
		\end{equation*}
\end{example}

Quando pensiamo a $\proj[2]{\kamp}$ come lo spazio che parametrizza le rette in $\proj[2]{\kamp}$, lo denotiamo con $\left(\proj[2]{\kamp}\right)^{*}$ e lo chiamiamo \textit{piano proiettivo duale}. \index{piano proiettivo!duale}.\\
In prima istanza questo significa semplicemente che si interpreta un punto del duale come un punto associato ad una retta.
%collgamento co lo spazio vettoriale duale        forma lineare
%prima costruzione come corrispondenza
	\subsection{Fascio di rette}
\begin{define} \index{fascio}
	Un \textbf{fascio} di rette in $\proj[2]{\kamp}$ è l'insieme delle rette di equazione
		\begin{equation*}
			\mathcal{F}\colon \lambda l_1+\mu l_2=0, \ (\lambda\colon\mu)\in\proj[1]{\kamp}
		\end{equation*}
	dove $l_1,l_2$ sono due rette fissate e distinte.
\end{define}
\begin{observe}
	Possiamo pensare al fascio di rette come una collezione di rette le cui equazioni si ottengono come combinazione lineare delle due rette del fascio con $\lambda,\mu$ come parametri.
\end{observe}
\begin{example}
	Consideriamo le rette $l_1\colon x_0+x_1+2x_2=0$ e $l_2\colon 3x_0-2x_1+4x_2=0$. Il fascio di rette determinato da $l_1,l_2$ è
		\begin{gather*}
			(\lambda+3\mu)x_0+(\lambda-2\mu)x_1+2(\lambda+2\mu)x_2=0\\
			(\lambda\colon\mu)=(1\colon 0) \rightarrow l_1\\
			(\lambda\colon\mu)=(0\colon 1) \rightarrow l_2\\
			(\lambda\colon\mu)=(1\colon 1) \colon 4x_0-x_1+6x_2=0			
		\end{gather*}
\end{example}

\begin{observe}
	Abbiamo detto che ad ogni retta corrisponde un punto del piano proiettivo duale, ci chiediamo ora a cosa corrisponda la costruzione del fascio. \\
	Il fascio $\mathcal{F}$ corrisponde alla retta passante per i punti corrispondenti a $l_1$ e $l_2$
		\begin{gather*}
			l_1\colon a_0x_0+a_1x_1+a_2x_2=0 \rightarrow (a_0\colon a_1\colon a_2)\\
			l_2\colon b_0x_0+b_1x_1+b_2x_2=0 \rightarrow (b_0\colon b_1\colon b_2)\\
			\mathcal{F}\colon (\lambda a_0+\mu b_0)x_0+ (\lambda a_1+\mu b_1)x_1 +(\lambda a_2+\mu b_2)x_2=0 \rightarrow (\lambda a_0+\mu b_0 \colon \lambda a_1+\mu b_1 \colon \lambda a_2+\mu b_2)
		\end{gather*}	
\end{observe}

\begin{example}
	Fascio visto come retta per due punti del duale
		\begin{gather*}
			l_1 \leftrightarrow (1\colon 1\colon 2)=Q_1\\
			l_2\colon 3x_0-2x_1+4x_2=0 \leftrightarrow (3\colon -2\colon 4)=Q_2\\
			\mathcal{F} \leftrightarrow (\lambda+3\mu \colon \lambda-2\mu \colon 2(\lambda+2\mu))
		\end{gather*}
	che è la retta $\overline{Q_1Q_2}$ in forma \textit{parametrica}.
\end{example}

\begin{observe}
	Siccome due rette distinte nel piano si intersecano in un punto solo, sia $P\coloneqq l_1\cap l_2$. Allora
		\begin{itemize}
			\item ogni retta del fascio passa per $P$ perché è lì che la combinazione lineare si annulla
			\item $P$ è l'unico punto comune a tutte le rette del fascio $\mathcal{F}$
			\item viceversa, ogni retta per $P$ appartiene al fascio $\mathcal{F}$
		\end{itemize}
	Ciò significa che $\mathcal{F}$ è la famiglia delle rette per il punto fissato $P$, che è detto \textbf{punto base} del fascio. \index{fascio!punto base}
	%P PUZZA DI SOTTOSPAZIO VETT CON VETT NULLO P 
\end{observe}

\begin{example}
	Punto base di un fascio
		\begin{gather*}
			\begin{cases}
				l_1\colon x_0+x_1+2x_2=0\\
				l_2\colon 3x_0-2x_1+4x_2=0
			\end{cases} \implies \begin{cases}
				x_0=-x_1-2x_2\\
				-3x_1-6x_2-2x_1+4x_2=-5x_1-2x_2=0
			\end{cases} \\
		\implies x_1=2, x_2=-5, x_0=-2+10=8\\
			P=(8\colon 2\colon -5)=l_1\cap l_2
		\end{gather*}
	Tale fascio $\mathcal{F}$ corrisponde alla retta in $\left(\proj[2]{\kamp}\right) ^{*}$ per i punti $Q_1=(1\colon 1 \colon 2)$ e \\ $Q_2=(3\colon -2\colon 4)$ che è già scritta in forma parametrica. Cerchiamo ora l'equazione cartesiana della retta $\overline{Q_1 Q_2}$ nelle coordinate $(a_0\colon a_1\colon a_2)$: 
	\begin{gather*}
	\left| \begin{array}{ccc}
		a_0 & a_1 & a_2\\
		1 & 1 & 2 \\
		3 & -2 & 4 \end{array} \right| = 8a_0 + 2a_1-5a_2=0
	\end{gather*}
	Notiamo che i coefficienti della retta ottenuta sono esattamente le coordinate omogenee di $P$ che è intersezione delle due rette.
\end{example}
Più in generale, fissato un punto base $P\in\proj[2]{\kamp}$, l'insieme delle rette per $P$ in $\proj[2]{\kamp}$ quale $\mathcal{F}_P=\{$rette per $P$ in $\proj[2]{\kamp} \}$ è un fascio di rette corrispondente a una retta nel piano proiettivo duale $\left(\proj[2]{\kamp}\right)$. Se le coordinate sono $P=(c_0\colon c_1\colon c_2)$, la retta corrispondente nel piano proiettivo duale $\left(\proj[2]{\kamp}\right)^{*}$ ha equazione $c_0a_0+c_1a_1+c_2a_2=0$. Infatti data una retta $r$ qualsiasi di equazione $a_0x_0+a_1x_1+a_2x_2=0$, il punto $P$ appartiene a $r$, ovvero $P\in r$, se e solo se vale l'equazione $c_0a_0+c_1a_1+c_2a_2=0$. \\
Per scrivere il fascio $\mathcal{F}$ in forma parametrica scelgo due rette distinte passanti per $P$.
%    sostituisco le coordinate di P e trovo quell'eq:   condizione perchè appartenga alla retta   o al fascio, collezione delle rette per p     fisso p e retta che varia (duale )   retta r fissata e p che varia. Ma l'eq è la stessa
%di fatto il fascio si scrive in forma parametrica scegliendo due rette specifiche che passano per p

%ESEMPIO O ESERCIZIO?
\begin{example}
	In $\proj[2]{\realset}$ scrivere in forma parametrica il fascio delle rette per il punto base $P$ di coordinate $(1\colon -1 \colon4)$.\\
	Scegliamo 2 rette distinte a caso che passano per il punto $P$, ad esempio $l_1\colon x_0+x_1=0$ e $l_2\colon 4x_0-x_2=0$. Il fascio sarà 
		\begin{gather*}
			\begin{array}{cc}
				\mathcal{F}\colon & \lambda(x_0+x_1)+\mu(4x_0-x_2)=0 \\
				& (\lambda+4\mu)x_0+\lambda x_1-\mu x_2=0, \ (\lambda\colon\mu)\in\proj[1]{\ }
			\end{array}
		\end{gather*}
	Ovvero se facciamo variare $\lambda$ e $\mu$ otteniamo tutte le rette di $\proj[2]{\realset}$ che passano per $P$.
\end{example}

\begin{observe}\textsc{Interpretazione affine}\\
	Se interpretiamo $\kamp^2=U_0\subset\proj[2]{\kamp}$ e consideriamo il fascio di rette proiettive $\mathcal{F}$ con punto base $P$ in $\proj[2]{\kamp}$, allora ci sono 2 possibilità: $P$ è punto base proprio o all'infinito.\\
	Se $P$ è un punto proprio, allora $P\in\kamp^2$ e $\mathcal{F}$ corrisponde alle rette affini in $\kamp^2$ per il punto $P$ a meno di passare alla chiusura proiettiva dalla retta proiettiva a quella affine.\\
	Se $P$ invece è un punto improprio, corrisponde ad una direzione di rette nel piano affine e $\mathcal{F}$ corrisponde a tutte le rette affini che hanno questa direzione fissata, ovvero è un fascio di rette parallele.\\
	Il caso proiettivo dunque è interessante perché la distinzione fra questi due tipi di fasci è data solo dal fatto se il punto $P$ è proprio o improprio.  	
\end{observe}

	\subsection{Interpretazione duale}

Sappiamo che $\proj[2]{\kamp}$ è il proiettivizzato di $\kamp^3$, ovvero $\proj[2]{\ }=\mathbb{P}(\kamp^3)$, inoltre dal corso di Geometria 1 sappiamo che $\left(\kamp^3\right)^{*}=\{$ forme lineari $\alpha$ su $\kamp^3\}$ del tipo $\funz \alpha {\kamp^3} \kamp$ e $\alpha(x_0,x_1,x_2)= ax_0+a_1x_1+a_2x_2$. L'unica differenza che per ora osserviamo da quanto visto nel corso precedente è la numerazione delle coordinate da $0$ a $2$.\\
Quando consideriamo la retta $r\colon a_0x_0+a_1x_1+a_2x_2=0$, allora stiamo dicendo che $r$ corrisponde ad un piano proiettivo che è esattamente il proiettivizzato del nucleo di $\alpha$, che è un piano vettoriale $\ker\alpha\subset\kamp^3$ la cui equazione è proprio quella di $r$.\\
Stiamo dunque considerando $\left( \proj[2]{\ }\right)^{*}=\mathbb{P}\left( (\kamp^3)^{*} \right)\ni [\alpha]\leftrightarrow r$, infatti $\alpha$ è una forma lineare non nulla determinata a meno di multipli. Passando alle coordinate si riottiene quanto visto prima, infatti si ha che $\{x_0,x_1,x_2\}$ è una base di $(\kamp^3)^{*}$ che induce le coordinate proiettive $(a_0\colon a_1\colon a_2)$ su $\left( \proj[2]{\ }\right)^{*}$. Pertanto tale interpretazione astratta diventa operativa (con dei numeri) fissando la base naturale delle forme lineari che è data dalle coordinate proiettive associate: scrivo $\alpha$ come combinazione lineare della base, e i coefficienti saranno le coordinate omogenee.\\
Più in generale, dato uno spazio vettoriale $V$, il suo spazio proiettivo associato $\mathbb{P}(V)$ ed il suo spazio vettoriale duale $V*=\{$ forme lineari $\funz \alpha V \kamp \}$, si ha che $\mathbb{P}(V*)=\left(\mathbb{P}(V)\right)^{*}$.\\
In particolare si ha una corrispondenza biunivoca
	% https://q.uiver.app/?q=WzAsNCxbMCwwLCJcXGxlZnQoXFxtYXRoYmJ7UH0oVilcXHJpZ2h0KV57Kn0iXSxbMywwLCJcXHtcXHRleHR7aXBlcnBpYW5pIGRpIH0gXFxtYXRoYmJ7UH0oVikgXFx9Il0sWzAsMSwiW1xcYWxwaGFdIl0sWzMsMSwiXFxtYXRoYmJ7UH0oXFxrZXJcXGFscGhhKVxcc3Vic2V0XFxtYXRoYmJ7UH0oVikiXSxbMCwxLCIiLDAseyJzdHlsZSI6eyJ0YWlsIjp7Im5hbWUiOiJhcnJvd2hlYWQifX19XSxbMiwzLCIiLDAseyJzdHlsZSI6eyJ0YWlsIjp7Im5hbWUiOiJhcnJvd2hlYWQifX19XV0=
	\[\begin{tikzcd}
		{\left(\mathbb{P}(V)\right)^{*}} &&& {\{\text{iperpiani di } \mathbb{P}(V) \}} \\
		{[\alpha]} &&& {\mathbb{P}(\ker\alpha)\subset\mathbb{P}(V)}
		\arrow[from=1-1, to=1-4, tail reversed]
		\arrow[from=2-1, to=2-4, tail reversed]
	\end{tikzcd}\]
In coordinate, ad un piano di equazione $\displaystyle \underbrace{a_0x_0+\dots +a_nx_n}_{\alpha}=0$ associamo il punto $(a_0\colon\dots\colon a_n)$, nello stesso modo in cui ad un vettore associo i coefficienti della scrittura secondo una tale base.

		\section{Coniche nel piano proiettivo}
Nel corso di Geometria 1 abbiamo già analizzato le coniche nel piano affine $\mathcal{A}(\realset^2)$ e le abbiamo classificate a meno di rototraslazione. Generalizziamo ora al caso proiettivo tenendo conto del fatto che nel piano proiettivo le coordinate sono omogenee.\\
Consideriamo $\proj[2]{\kamp}$ con coordinte omogenee $(x_0\colon x_1\colon x_2)$. Indicheremo con $\kamp[x_0,x_1,x_2]$ l'anello dei polinomi in $x_0,x_1,x_2$ a coefficienti in $\kamp$. Se $F\in\kamp[x_0,x_1,x_2]$ è un polinomio qualsiasi, l'equazione $F(x_0,x_1,x_2)=0$ non dà una condizione ben definita in $\proj[2]{\kamp}$: ad esempio $x_0+1=0$ non ha senso perché $x_0$ è determinato solo a meno di multipli. Cerchiamo dunque dei polinomi che ha senso studiare in $\proj[2]{\kamp}$.

\begin{define} \textsc{Polinomio omogeneo}\\ \index{polinomio!omogeneo}
Sia $F\in\kamp[x_0,x_1,x_2]$ un polinomio. Si dice che $F$ è un \textbf{polinomio omogeneo} se tutti i monomi a coefficienti non nulli hanno lo stesso grado.
\end{define}
Notiamo che la definizione è significativa per polinomi a più variabili, altrimenti i polinomi omogenei sarebbero solo monomi.

\begin{example}
Un esempio di polinomio omogeneo è $F=x_0^3+x_0x_1^2-3x_1x_2x_3\in\realset[x_0,x_1,x_2]$, che p un polinomio omogeneo di grado $3$.\\
Un polinomio non omogeneo invece è $G=x_0^3-x_1x_2+1$
\end{example}

\begin{observe}
Considerato il caso del grado pari a $1$, se $\deg F=1$, ovvero $F=a_0x_0+\dots+a_nx_n+b$, allora $F$ è omogeneo $\iff b=0$
\end{observe}

\begin{observe}
Se $F\in\kamp[x_0,x_1,x_2]$ è omogeneo di grado $d$ allora 
\begin{equation}
F(\lambda x_0,\lambda x_1,\dots,\lambda x_n)=\lambda^d F(x_0,\dots,x_n)
\end{equation}
Infatti $F$ è somma di monomi di grado $d$ del tipo $ax_0^{i_0}x_1^{i_1}\cdots x_n^{i_n}$ con $\sum_{j_0}^n i_j=d$ e si ha che $a(\lambda x_0)^{i_0} (\lambda x_1)^{i_1} \cdots (\lambda x_n)^{i_n}=\lambda^{i_0+\dots +i_n} (ax_0^{i_0}\dots x_n^{i_n})=\lambda^d(ax_0^{i_0}\dots x_n^{i_n})$
\end{observe}

Torniamo al piano proiettivo $\mathbb{P}^2$ con le coordinate omogenee $(x_0\colon x_1\colon x_2)$ e consideriamo $F\in\kamp[x_0,x_1,x_2]$ un polinomio omogeneo nelle coordinate omogenee di grado $d$. Se abbiamo un punto $P=(c_0\colon c_1\colon c_2)\in\mathbb{P}^2$, allora tutte le possibili scelte per le coordinate di $P$ sono $(\lambda c_0\colon \lambda c_1 \colon \lambda c_2)$ con $\lambda\in\kamp\setminus\{0\}$ e valutando $F$ otteniamo $F(\lambda c_0,\lambda c_1, \lambda c_2)=\lambda^d F(c_0,c_1,c_2)$, e questo ci dice che $F$ si annulla in una scelta di coordinate se e solo se si annulla in qualsiasi scelta di coordinate, ovvero 
\begin{equation*}
F(c_0,c_1,c_2)=0\iff F(\lambda c_0, \lambda c_1, \lambda c_2)=0,\ \forall \lambda\in\kamp\setminus\{0\}
\end{equation*}
Pertanto l'equazione $F(x_0,x_1,x_2)=0$ è ben posta in $\mathbb{P}^2$.

\begin{example}
Si ha che $x_0^2-x_1x_2=0$ definisce un sottoinsieme del piano proiettivo.
\end{example}
Le coniche sono esattamente i sottoinsiemi di $\mathbb{P}^2$ che sono dati da polinomi omogenei di grado 2.
%AAA ENVIRONMENT CERCASI: CC qui mette un define, però poi non si capisce dove finisca perché sbordola con discorsi, anche nell'esempio successivo
Una \textbf{curva algebrica piana proiettiva} è data da un polinomio omogeneo $F\in\kamp[x_0,x_1,x_2]$ a meno di multipli. Se $G=\lambda F$ con $\lambda\in\kamp\setminus\{0\}$ considereremo $G$ e $F$ come la stessa curva.\\
La curva $C$ ha un \textbf{supporto} $\{P\in\mathbb{P}^2\mid F(P)=0\}$ che è l'insieme dove il polinomio si annulla. $F$ è l'equazione della curva $C$ e oltre al supporto vogliamo ricordarci anche di essa, a meno di multipli. Questo perché l'equazione determina il supporto, ma in generale non vale il contrario, come nel caso dell'ellisse immaginario.\\
Le curve che andremo a studiare sono sottoinsiemi di $\mathbb{P}^2$ che sono luoghi di zeri di polinomi omogenei, inserendo anche la nozione di molteplicità per la curva.\\
Sia $F=a_0x_0+a_1x_1+a_2x_2=0 \implies C$ è una retta. Siccome il grado della curva $C$ è dato dal grado dell'equazione $F$, allora le curve di grado $1$ sono le rette proiettive.\\
Le coniche che vogliamo studiare sono le curve di grado 2. Inoltre diremo che una curva $C$ è reale se $\kamp=\realset$ (in $\proj[2]{\realset}$) ed è complessa se $\kamp=\complexset$ (in $\proj[2]{\complexset}$).




%LEZ 33
D'ora in poi ci restringeremo ai casi $\kamp=\realset$ e $\kamp=\complexset$
\begin{define}
Una curva $C$ è \textbf{irriducibile} se lo è la sua equazione $F$. Altrimenti sia $F=F_1^{m_1}\dots F_r^{m_r}$ la fattorizzazione in irriducibili. Siccome ogni fattore irriducibile $F_i$ è omogeneo allora ognuno definisce una curva, e vengono definite \textbf{componenti irriducibili} della curva $C$ le curve $C_i\colon F_i=0$.\\
Se $m_i>1$ diciamo che $C_i$ è una componente di \textit{molteplicità} $m_i$ in $C$
\end{define}

\begin{examples}
Le rette sono curve di grado 1 e sono sempre irriducibili.\\
Le coniche sono curve di grado 2. Sia $C$ una conica di equazione $F=0$, ci sono 3 possibilità:
\begin{enumerate}
\item	$C$ è irriducibile
\item	$C$ è il prodotto di fattori lineari distinti e non multipli: $F=L_1\cdot L_2$ con $L_i$ forme lineari non proporzionali $\implies C$ è una coppia di rette distinte, ad esempio $F=x_0x_1$, ovvero $C$ è unione delle rette $x_0=0$ e $x_1=0$
\item	$C$ è data da fattori lineari associati, ovvero $F$ è un quadrato a meno di uno scalare: $F=\lambda L^2, \lambda\in\kamp\setminus\{0\} \implies C$ è una retta doppia: 1 sola componente irriducibile, la retta, di molteplicità 2, ad esempio $F=x_0^2$
\end{enumerate}
\end{examples}

\subsection{Coniche proiettive}
Una conica è data da un polinomio $F$ omogeneo di grado 2 in $x_0,x_1,x_2$ a coefficienti reali o complessi.
\begin{equation*}
F=a_{00}x_0^2 +a_{01}x_0x_1+a_{02}x_0x_2+a_{11}x_1^2+a_{12}x_1x_2+a_{22}x_2^2
\end{equation*}
Tale scrittura ci ricorda l'espressione in coordinate una forma quadratica sullo spazio vettoriale $\kamp^3$, e in generale i polinomi omogenei di grado 2 sono forme quadratiche, che abbiamo già affrontato nel corso di \textit{Geometria 1}.
%forma <---> polinomio omogeneo
Volendo associare alla forma la  corrispondente matrice simmetrica, per evitare di dividere per 2 i termini misti, li  moltiplichiamo per 2 nell'espresisione polinomiale, ottenendo così:
\begin{equation*}
F=a_{00}x_0^2 +2a_{01}x_0x_1+2a_{02}x_0x_2+a_{11}x_1^2+2a_{12}x_1x_2+a_{22}x_2^2
\end{equation*}
Sia dunque $A=(a_{ij})$ la matrice simmetrica $3\times 3$ associata alla forma quadratica, ovvero $\displaystyle F=x^tAx$ con $x=\left( \begin{array}{c}
x_0 \\ x_1 \\ x_2
\end{array} \right)$ vettore delle coordinate omogenee.
Definiamo il \textbf{rango} della conica $C$ come il rango della matrice associata $A$.
\begin{observe}
L'equazione della conica $C$ determina $F$ solo a meno di multipli, dunque anche la matrice $A$ è determinata a meno di multipli. 
Tuttavia il rango rimane ben definito in quanto $\rk(\lambda A)=\rk(A), \forall\lambda\neq 0$. Inoltre il rango non può essere $0$ perché essendo l'equazione di una conica il polinomio non può essere nullo.
\end{observe}
Vogliamo studiare le coniche e le curve di grado maggiore a meno di equivalenza proiettiva, allo stesso modo in cui abbiamo classificato le coniche in $\realset^2$ a meno di rototraslazioni.\\
Sia $\funz f {\proj[2]{\ }} {\proj[2]{\ }}$ una proiettività definita da $x'=Mx,\ M\in\gl(e,\kamp)$. Allora $f$ porta la conica $C\colon F=0$ nella conica $\widetilde{C}\colon \widetilde{F}=0$, dove $\widetilde{F}$ si ottiene sostituendo in $f$ $x=M^{-1}x'$.

\begin{example}
Sia $C \colon x_ox_1=0$ una coppia di rette e $f$ una proiettività tale che $f(x_0\colon x_1\colon x_2)=(x_0+x_1\colon x_0-2x_1\colon x_2)$. Scriviamo $x'_i$ in funzione di $x_i$ e poi facciamo il contrario cercando di scrivere $x_i$ in funzione di $x'_i$
\begin{gather*}
f\colon \begin{cases} 
x'_0=x_0+x_1\\
x'_1=x_0-2x_2\\
x'_2=x_2
\end{cases} \implies \begin{cases}
-3x_1=x'_1-x'_0 \implies x_1=\frac{1}{3}(x'_0-x'_1)\\
x_0=x'_0-x_1=x'_0 -\frac{1}{3}(x'_0-x'_1)=\frac{1}{3}(2x'_0+x'_1)
\end{cases}\\
f^{-1}\colon \begin{cases}
x_0=\frac{1}{3}(2x'_0+x'_1)\\
x_1=\frac{1}{3}(x'_0-x'_1)\\
x_2=x'_2
\end{cases}
\end{gather*}
In sostanza abbiamo ottenuto l'espressione dell'inversa di $f$ e quindi la trasformata di $C$ tramite $f$ è esattamente $(2x_01+)(x'_0-x'_1)=0$, che è ancora una coppia di rette che sono le immagini tramite $f$ delle rette $x_0=$ e $x_1=0$, ignorando i 
fattori moltiplicativi $\frac{1}{3}$.
\end{example}
Osserviamo che la proiettività manda il supporto della prima conica nel supporto della seconda conica e che trasformando la conica tramite una proiettività, trasformiamo la forma quadratica $F$ tramite un cambiamento di coordinate di $\kamp^3$, dunque se $A$ è la matrice associata a $C$ e $\widetilde{A}$ è la matrice associata alla trasformata $\widetilde{C}$ tramite $f$, allora $A$ e $\widetilde{A}$ sono congruenti, infatti il cambiamento di coordinate su uno spazio vettoriale per la forma quadratica è dato da $\widetilde{A}=M^tAM$ con $M\in\gl{3,\kamp}$ con $M$ matrice della proiettività che si interpreta come matrice del cambiamento di base.
Viceversa, date due coniche $C_1$ e $C_2$ le cui matrici associate (simmetriche) $A_1$ e $A_2$ sono congruenti, allora $C_1$ e $C_2$ sono proiettivamente equivalenti, questo perché vale anche per le forme quadratiche: forme congruenti differiscono per cambiamento di base, ottenendo così la seguente corrispondenza:

\begin{equation*}
\begin{array}{ccc}
C_1\text{ e }C_2\text{ equivalenti}& \iff & A_1\text{ e }A_2\text{ congruenti}
\end{array}
\end{equation*}
Pertanto lo studio delle coniche a meno di equivalenza proiettiva passa per lo studio delle matrici congruenti.

\subsection{Classificazione delle coniche proiettive complesse}
\begin{remember}
Nel campo dei complessi, ovvero se $\kamp=\complexset$, due matrici simmetriche sono congruenti se e solo se hanno lo stesso rango. In generale vale solo che se sono congruenti allora hanno lo stesso rango.
\end{remember}
A meno di equivalenza proiettiva allora ci sono solo 3 possibili coniche: quelle di rango 1, rango 2 e rango 3.
\begin{theorema}
\begin{enumerate}
\item	Due coniche in $\proj[2]{\complexset}$ sono proiettivamente equivalenti $\iff$ hanno lo stesso rango
\item	forma canonica: ogni conica di P2C è proiettivamente equivalente ad una ed una sola delle tre coniche seguenti\\
\begin{equation*}
		\begin{array}{ccc}
		\rk 3\colon & x_0^2+x_1^2+x_3^2=0 &	\text{conica irriducibile}\\
		\rk 2 \colon & x_0^2+x_1^2=(x_0+ix_i)(x_0-ix_1)=0 & \text{ coppia di rette distinte}\\
		\rk 1 \colon & x_0^2=0 & \text{retta doppia}
	\end{array}
\end{equation*}
\end{enumerate}
\end{theorema}

%questo è dato dalla classificazione delle forme quadratiche du \complexset^3

	\subsection{Classificazione delle coniche proiettive reali}
	Sia $C$ una conica in $\proj[2]{\realset}$ con matrice associata $A$, che è simmetrica reale $3\times 3$, perché sia congruente ad un'altra matrice simmetrica serve anche la segnatura oltre al rango.
	\begin{observe}
	Siccome $A$ è determinata a meno di multipli, allora in principio la segnatura può cambiare. Vediamo cosa succede effettivamente.\\
	Se $A$ ha segnatura $(p,q)$ con $p=$numero di autovalori positivi e $q=$ numero di autovalori negativi, allora $\lambda A$ può avere segnatura: $(p,q)$ se $\lambda>0$ oppure $(q,p)$ se $\lambda <0$.\\
	Quindi la segnatura di una conica è definita solo "a meno del segno" nel senso che $(p,q)=(q,p)$
	\end{observe}
	\begin{theorema}~{}
	\begin{enumerate}
	\item	 Due coniche in $\proj[2]{\realset}$ sono proiettivamente equivalenti $\iff$ hanno la stessa segnatura a meno del segno (dalla segnatura si deduce anche il rango).
	\item	Ogni conica in $\proj[2]{\realset}$ è proiettivamente equivalente a una ed una sola delle seguenti coniche con segnature distinte a meno del segno:
	\begin{equation*}
		\arraycolsep=2.5pt
		\begin{array}{cccc}
			\rk 3 & \begin{array}{cc}
					(3,0)/(0,3) \\
					\\
					(1,2)/(2,1)
				\end{array} & \begin{array}{cc}
				x_0^2+x_1^2+x_2^2=0\\
				\\
				x_0^2+x_1^2-x_2^2=0\\
			\end{array} 
				 & \begin{array}{c}
			\begin{array}{c}
				\text{Conica irriducibile senza} \\
				\text{punti reali (supporto vuoto)}
			\end{array} \\
			\begin{array}{c}
				\text{Conica irriducibile a punti reali,} \\
				\text{contiene infiniti punti in }\proj[2]{\realset}
			\end{array}
		\end{array}\\ \hline %ha un supporto? ci sono dei punti in P2R che hanno questa equazione? no perché escludiamo l'origine	conica irriducibile senza punti reali /tipo ellisse immaginario/ dunque il supporto è vuoto
		\rk 2 &\begin{array}{c}
		(2,0)/(0,2) \\
		\\
		(1,1)
		\end{array} &\begin{array}{c}
		x_0^2+x_1^2=0 \\
		\\
		x_0^2-x_1^2=\\[-0.75ex]
		=(x_0-x_1)(x_0+x_1)=0
		\end{array} & \begin{array}{c}
		\begin{array}{c}
		\text{Coppia di rette non reali} \\
		\text{con } 1 \text{ punto reale } (0\colon 0\colon 1)
		\end{array} \\ %	perché si fattorizza ma a coeff complessi. Ha un unico punto reale (0\colon 0\colon 1) intersezione delle due rette complesse coniugate
		\begin{array}{c}
		\text{Conica irriducibile a punti reali,} \\
		\text{coppia di rette reali distinte}
		\end{array}
		\end{array} \\ \hline %che si fattorizza su R
		\rk 1 & (1,0) & \begin{array}{c}
			\\[-2.75ex]
			x_0^2=0
		\end{array} & \text{Retta doppia}	
\end{array}	
	\end{equation*}
	\end{enumerate}
	\end{theorema}

	\subsection{Curve algebriche piane affini e chiusura proiettiva}
Siccome abbiamo interpretato il piano proiettivo come un'estensione di quello affine, possiamo confrontare la classificazione delle curve nel piano proiettivo con la classificazione nel caso affine.\\

Una curva algebrica piana $C$ affine in $\kamp^2$ è data dall'equazione $f(x,y)=0$, dove $f\in\kamp[x,y]$ è un polinomio.
Per definizione, due equazioni $f,g$ definiscono la stessa curva $\iff$ sono proporzionali, ovvero $g=\lambda f, \lambda\in\kamp\setminus\{0\}$. Si definisce dunque il grado di una curva $C$ come $\deg f$ ed il supporto di $C$ come $\{(x,y)\in\kamp^2 \mid f(x,y)=0\}$, e di conseguenza anche le componenti irriducibili, le curve irriducibili e la molteplicità di una componente.\\
Allo stesso modo un retta è una curva di grado $1$: $ax+by+c=0$ e una conica è una curva di grado $2$: $ax^2+by^2+cxy+dx+ey+f=0$.\\

Vediamo ora qual è il legame fra curve affini e proiettive passando alla chiusura proiettiva. Ricordiamo che $\kamp^2=U_0\subset \proj[2]{\kamp}$ con $(x,y)\in\kamp^2$ che corrispondono a $\displaystyle x=\frac{x_1}{x_0}$ e $\displaystyle y=\frac{x_2}{x_0}$ dato $(x_0\colon x_1\colon x_2)\in\proj[2]{\kamp}$.\\

\subsubsection{Omogeneizzazione di un polinomio}
Partiamo da una curva affine $C$ di equazione $f(x,y)=0$. Vogliamo associare a $f$ un polinomio omogeneo nelle coordinate $x_0,_1,x_2$ dello stesso grado di $f$.
Consideriamo dunque il polinomio $F\in\kamp[x_0,x_1,x_2]$ così definito: se $d=\deg f$, allora $F\coloneqq x_0^d f\left( \frac{x_1}{x_0}, \frac{x_2}{x_0} \right)$. Scritto così non è immediato che sia un polinomio, per cui dimostriamolo.\\
$F$ è un polinomio omogeneo di grado $d$, infatti, considerato un monomio in $f$ quale $ax^iy^j$ allora $i+j\leq d=\deg f$ e si "omogeneizza" rispetto a $x_0$ per ottenere un monomio di grado $d$ in $x_0,x_1,x_2$
	\begin{gather*}
		ax^iy^j \rightarrow x_0^d a \left( \frac{x_1}{x_0} \right)^i \left( \frac{x_2}{x_0} \right)^j = ax_0^{d-i-j} x_1^i x_2^j
	\end{gather*}
Notiamo che operativamente l'omogeneizzazione consiste nel cambiare nome alle variabili e  moltiplicare per una potenza di $x_0$ in modo tale che il monomio sia di grado $d$. Si ripete questa procedura per ogni monomio si ottiene un polinomio omogeneo $f$ di grado $d$ come desiderato

\begin{example} \textsc{Omogeneizzazione di un polinomio} \\
	Sia $f=x^3-2xy+3y+1$ il polinomio da omogeneizzare, prima di tutto si cambia il nome delle variabili e si ottiene $x_1^3-2x_1x_2+3x_2+1$. Infine il polinomio omogeneizzato rispetto a $x_0$ sarà $F=x_1^3-2x_0x_1x_2 +3x_0^2x_2+x_0^3$.
\end{example}
\begin{observe}
	Con questo procedimento, ponendo $x_0=1$ si riottiene il polinomio di partenza $f(x_1x_2)$.
\end{observe}

\subsubsection{Chiusura proiettiva}

\begin{define}
	La curva $\overline{C}$ in $\proj[2]{\kamp}$ definita da $F=0$ si dice \textbf{chiusura proiettiva} della curva affine $C$ di equazione $f=0$.
\end{define}

Se $P=(1\colon x\colon y)\in U_0$  allora $f(x,y)=F(P)\implies \overline{C}\cap U_0=C$ come supporti.\\
I \textit{punti impropri} o \textit{punti all'infinito} della curva $C$ sono dati dall'intersezione della chiusura proiettiva con la retta impropria, ovvero da $\overline{C}\cap\{x_0=\}$

\begin{example} \textsc{Chiusura proiettiva di una retta}\\
	Se $C$ è una retta $ax+by+c=0$allora la chiusura proiettiva di $C$ è $ax_1+bx_2+cx_0=0$ ed il punto improprio di $C$ è $(0\colon -b\colon a)$ che corrisponde alla direzione della retta $C$.
\end{example}

\begin{examples}
	Consideriamo in $\realset^2$ le coniche 
		$\begin{array}{ccc}
			C_1\colon & y=x^2 & 	\text{parabola}\\
			C_2\colon & x^2+y^2=1 &		\text{circonferenza}\\
			C_3\colon &	x^2-y^2=1 & \text{iperbole}
		\end{array}$\\
	Consideriamo ora le loro chiusure proiettive reali tramite l'omogeneizzazione, ovvero $\overline{C_i}$ conica proiettiva in $\proj[2]{\realset}$:
		$\begin{array}{cc}
			\overline{C_1} \colon & x_0x_1=x_1^2\\
			\overline{C_2} \colon & x_1^2+x_2^2=x_0^2\\
			\overline{C_3} \colon & x_1^2-x_2^2=x_0^2
		\end{array}$.
	Scrivendo le matrici associate e guardandone la segnatura, si ha che tutte e tre hanno segnatura $(2,1)/(1,2)$ e quindi sono coniche irriducibili a punti reali in $\proj[2]{\realset}$ e sono tutte proiettivamente equivalenti per la classificazione delle coniche nel piano proiettivo reale.\\
	Consideriamo ora i loro punti impropri:
		\begin{itemize}
			\item	parabola: $\overline{C_1}\cap\{x_0=0\}\colon (0\colon 0\colon 1)$, dunque un solo punto improprio, ovvero la direzione $(0,1)$ dell'asse $y=\mathcal{L}(0,1)$, quindi è l'asse della parabola
			\item	circonferenza: $\overline{C_2}\cap \{x_0=0\} \colon x_0=0 \implies x_1=x_2=0$ ma non si possono avere tute le coordinate omogenee nulle, dunque non ci sono punti impropri 
			\item	iperbole: $\overline{C_3}\cap\{x_0=0\}\colon x_1^2-x_2^2=0$, dunque ci sono	due punti impropri quali $(0\colon 1\colon 1)$ e $(0\colon 1\colon -1)$, a cui corrispondono le direzioni degli asintoti dell'iperbole
		\end{itemize}
%AAA DISEGNI CERCASI
	Notiamo che le chiusure proiettive sono tutte proiettivamente equivalenti, ma dal punto di vista affine hanno 3 posizioni diverse rispetto alla retta impropria: tangente, disgiunta e secante.
\end{examples}

\begin{example}
	In $\realset^2$ possiamo considerare la coppia di rette parallele distinte $x(x+1)=0$ oppure una coppia di rette incidenti distinte quali $xy=0$.\\
	Considerandone le chiusure proiettive si ottiene $x_1(x_1+x_0)=0$ e $x_1x_2=0$ che sono entrambe coppie di rette distinte reali in $\proj[2]{\realset}$ con segnatura (1,1). Dunque sono proiettivamente equivalenti fra loro ma hanno posizione diversa rispetto alla retta impropria, infatti guardando i punti impropri si ha che la prima ha un solo punto improprio quale $(0\colon 0\colon 1)$ che è la direzione comune delle due rette parallele, mentre nel secondo caso si hanno due punti impropri quali $(0\colon 0\colon 1)$ e $(0\colon 1\colon 0)$ che sono le direzioni delle due rette.
%AAA DISEGNI CERCASI
	%passa nell'intersezionie delle due rett
\end{example}

Ragionando in questo modo dalla classificazione delle coniche proiettive si può riottenere la classe delle coniche nel caso affine $\\aff{\realset^2}$ a meno di affinità (ovvero procedendo per rototraslazione), prestando	attenzione alla posizione rispetto alla retta impropria.

	\subsection{Classificazione affine delle coniche nel caso complesso}

\begin{proposition}
	Ogni conica in $\complexset^2$ si può ridurre con una trasformazioni
	e del tipo $\begin{pmatrix} x' \\ y' \end{pmatrix} =A\begin{pmatrix} x \\ y \end{pmatrix} +b$ con $b\in\complexset^2$ e $A\in\gl(2,\complexset)$ ad una delle cinque coniche
%	DA RIASCOLTARE
%	vediamo dove andiamo a parare:guardando la chiusura proiettiva, ho 3 ranghi possibili con la loro ir/riducibilità. Dobbamo guarare la posizione possibile rispetto alla retta allìinfinito, Siccome simao su C la chiusura proj ha solo 2 posizioni possibili: 2 punt distini o 2 punti coincidenti se irriducibili in base a 2 pt impropri o un solo. Idem per la coppia di rette al caso 			1 caso in rango 1
		\begin{enumerate}
			\item	$x^2+y^2+1=0$: la chiusura proiettiva ha rango 3 ed abbiamo 2 punti impropri distinti
			\item	$y-x^2=0$: la chiusura proiettiva ha ancora rango 3 ma abbiamo un unico punto improprio
			\item	$x^2+y^2=(x+iy)(x-iy)=0$: è una coppia di rette distinte incidenti, la chiusura proiettiva ha rango 2 ed abbiamo 2 punti impropri
			\item	$x(x+1)=0$:	coppia di rette distinte ma parallele, la chiusura proiettiva ha rango 2 e c'è un solo punto improprio
			\item	$x^2=0$ che è una retta doppia
		\end{enumerate}
\end{proposition}
%	non la dimostriamo ma abbiamo dato una giustificazione geometrica: class a meno di proj e #punti impropri
%RECAP	
%nel piano proj nel piano proj si riduce a classificare le forme quadratiche in K^3 ed usiamo l'algebra lineare: equiv proj dal rango (3 classi) mentr ein quello reale dipende anche dalla segnatura (a meno del segno) ed abbiamo 5 classi di equiv proj di coniche nel pin proj reale
%curve alg aff e chius proj
%	class affine coniche in r2 passando alla chiusura proj 
%		esempi che spiegao il significato geometrico
%			ellisse ierbole etc	chiusura proj stessa ma cambia pos retta impropria
%			
%			
%	class affine coniche in c2, guardo anche il numero di punti impropri
%	
%class coniche semplice perché è alg ineare, da grado 3 in su è meno semplice, servono dunque le nozioni per studiare curva algebrica, che sia affine o proiettiva

	\subsection{Polinomi omogenei in 2 variabili}
L'obiettivo ora è mostrare che i polinomi omogenei in 2 variabili si comportano per alcuni aspetti come polinomi in una sola variabile.\\
Sia $F\in\kamp[x_0x_1]$  omogeneo di grado $d$ come $F=a_0x_0^d+a_1x_0^{d-1}x_1+a_2x_0^{d-2}x_2^2+\dots + a_{d-1}x_0x_1^{d-1}a_dx_1^d$ che ha $d+1$ monomi. Ricordiamo che vedendo $x_0:x_1\in\proj[1]{\ }$, allora $F$ ha degli zeri su $\proj[1]{\ }$, ovvero $F(P)=0$ è ben posta per $P=(a\colon b)\in\proj[1]{\ }$.

\begin{define}
	Diciamo che $F$ si \textbf{annulla in } $p=(a\colon b)$ \textbf{all'ordine } $m$ se $(ax_1-bx_0)^m$ è la massima potenza di $ax_1-bx_0$ che divide $F$.
\end{define}
%		va letta ome la propr in 1 var come le radici /Ruffini!/
\begin{proposition}
	\begin{itemize}
		\item	$F$ si annulla in un punto $P=(a\colon b)\in\proj[1]{\ } \iff ax_1-bx_0\mid F$
		\item 	Se $d=\deg F$, $F$ ha al più $d$ zeri su $\proj[1]{\ }$ contati con molteplicità %/analogo degli zeri 
		\item	Se $F\in\complexset[x_0,x_1]$, allora $F$ si fattorizza come prodotto di forme lineari e ha esattamente $d$ zeri in $\proj[1]{\ }$ contati con molteplicità.\footnote{è analogo al caso in un variabile per cui in $\complexset$ ogni polinomio si fattorizza come prodotto di polinomi di grado 1 ed ha tutti gli zeri}
	\end{itemize}
\end{proposition}
\begin{demonstration}
	Facciamo un'ipotesi che semplifica la notazione per poi studiare il caso generale.\\
	Supponiamo che $x_0 \cancel\mid F$, ovvero $a_d\neq 0$ e $F(0\colon 1)\neq 0$. Poniamo $f\coloneqq F(1,t)\in\kamp[t] = a_0+a_1t+\dots+a_{d-1}t^{d-1}+a_dt^d$, dunque è un polinomio in una variabile, infatti si è posto $x_0=1$ e $x_1=t$, inoltre è ancora di grado $d$ perché $a_d\neq 0\implies \deg f=\deg F=d$. Si ha inoltre che:
		\begin{itemize}
			\item	$F$ è l'omogeneizzato di $f$ rispetto a $x_0$, ovvero $F=x_0^2f\left( \frac{x_1}{x_0} \right)$
			\item	gli zeri di $F$ sono tutti e soli della forma $(1\colon\lambda)$ con $\lambda$ radice di $f$, ovvero deomogeneizzando passiamo da 2 variabili in 1 variabile, infatti $F(1,\lambda)=f(\lambda)$.\\
		\end{itemize}
	Pertanto le proprietà di $F$ che vogliamo dimostrare seguono da quelle di $f$ che conosciamo già.\\
		\begin{enumerate}
			\item	$F$ si annulla in $(1\colon\lambda)=(a\colon b)\iff f(\lambda)=0 \iff t-\lambda \mid f \iff x_1-\lambda x_0\mid F$, ovvero l'omogeneizzato divide $F$.
			\item	è immediato dal punto $1$, perché se $F$ si annulla in $p_i=(a_i\colon b_i)$ distinti con molteplicità $m_i$, allora $(a_ix_1-b_ix_0)^{m_i} \mid F,\ \forall i=1,\dots,r $ siccome i punti $P_i$ sono distinti, allora i polinomi sono primi fra loro al variare di $i$, dunque anche il loro prodotto deve dividere $F$, ovvero $\prod_{i=1}^r (a_ix_1-b_ix_0)^{m_i}\mid F	\implies \sum_{i=1}^r m_i\leq d=\deg F$.
			\item	segue immediatamente dal caso complesso in $1$ variabile, infatti $f$ si scrive come $f=c(t-\lambda_1)^{m_1}\dots(x_1-\lambda_r x_0)^{m_r}$	siccome $\complexset$ è algebricamente chiuso $\implies F=c(x_1-\lambda_1x_0)^{m_1}\dots(x_1-\lambda_rx_0)^{m_r}$, ovvero si fattorizza completamente con forma lineari e non solo lo divide ma a meno di costante ho l'uguaglianza, per cui il numero di zeri contati con molteplicità è pari al grado.
		\end{enumerate}
\end{demonstration}

\begin{observe}
	Se fossimo su $\realset$ potremmo dedurre che un polinomio reale $f$ in una variabile ha radici reali o complesse coniugate, se ha grado dispari posso dedurre da $F$ che ha sempre almeno uno zero nella retta proiettiva reale.\\ 
	Vediamo il caso generale. Se $x_0\mid F$, ovvero $F=x_0^rG$ con $G$ omogeneo di grado $d-r$ per cui $x_0\cancel\mid G$, allora $F(0\colon 1)=0$ con molteplicità $r$.
	Questo significa che $F$ si annulla in $(0\colon 1)$ con molteplicità $r$ e tutte le proprietà di $F$ seguono dalle proprietà che sono vere per $G$.\\
	Conclusione: i polinomi omogenei in 2 variabili si comportano come i polinomi in una variabile.
\end{observe}

	\subsection{Intersezione tra una retta ed una curva nel piano proiettivo}
	
Useremo queste proprietà dei polinomi omogenei di secondo grado per studiare l'intersezione fra una retta ed una curva in $\proj[2]{\ }$.\\
Sia $C$ una curva in $\proj[2]{\ }$ di grado $d$ ed equazione $F(x_0,x_1,x_2)=0$ e sia $r\subset\proj[2]{\ }$ una retta. Vogliamo intersecare la retta $r$ con il supporto di $C$.\\
Quando interseco 2 sottoinsiemi è ottimale se uno è descritto per equazioni e l'altro in forma parametrica e poi sostituisco.\\
%Di unoho le equazioni, mentre so come scrivere in forma parametrica la retta
Scriviamo una parametrizzazioe per $r$, per farlo servono 2 punti distinti quali $A,B\in R$, e ogni punto di $r$ si scrive come $P=\lambda A+\mu B=[\lambda v+\mu v]$, dove $v$ è un vettore che rappresenta $A$, ovvero $A=[v]$ e idem per $B=[w]$ con $v,w\in\kamp^3$ e $(\lambda\colon\mu)\in\proj[1]{\ }$. Pertanto $C\cap r$ è dato da $F(\lambda v+\mu w)=0$ che è uguale all'esplicitamzione delle coordinate quindi è pari a $F(\lambda v_0+\mu w_0,\ \lambda v_1+\mu w_1,\ \lambda v_2+\mu w_2)$ e qui pensiamo che $A$ e $B$ sono dati mentre $\lambda$ e $\mu$ sono delle variabili, ottenendo un polinomio $G$ in $\lambda$ e $\mu$ quale $G(\lambda,\mu)\in\kamp[\lambda,\mu]$ che sarà omogeneo di grado $d$ o identicamente nullo se la retta è contenuta nella curva, ovvero $r\subset C$.

%LEZ 34
\begin{example}
	In $\proj[2]{\realset}$ sia $C\colon x_0^2+x_1^2-x_2^2=0$, $r_1\colon x_1=x_2$ e $r_2\colon x_0+x_1=0$, vogliamo calcolare le intersezioni $r_i\cap C$:
		\begin{gather*}
			r_1\colon x_1=x_2 \rightarrow x_0^2=0 \text{ e } r_1\cap C=\{ (0\colon 1 \colon 1) \} \text{ molteplicità 2}\\
			r_2 \colon x_1=-x_0 \rightarrow 2x_0^2=x_2^2 \rightarrow x_2=\pm \sqrt{2}x_0 \ \ x_0=1\implies x_1=-1,\ x_2=\pm \sqrt{2}\\ \implies \text{ due punti di intersezione } (1\colon -1\colon \sqrt{2}) \text{ e } (1\colon -1\colon -\sqrt{2})
		\end{gather*}
\end{example}

%combinazione lineare dei punti e dei vettori corrispondenti e poi F(x_0  )=0 equazione di C, sostituiamo nell'equazione la parametrizzazione di r in F si ottine n polinomio in lambda e mu G()\coloneqq	che per definizione è ottenuto sostituend i vetori
%Abbiamo due possibilità
%o la retta è contenuta nella conica: ogni pt della retta soddisfa l'eq, dunque il polinomio è identicamente nullo
%se la retta non è contenuta nella conica, allora G è un polinoimo in lamba e mu siccome F era omo di grado d e dento F sostituisco forme lineari, allora G  un polinomio  omogeneo di grado d in lambda e mu

%DEF
%SE UNA COPPIA è UNA RADICE DI g DI MOLTELICIT M
%(massimo esponente della fomra lineare che fdivide il polinomio G=
%la curva C e la retta r hanno molteplicità di intersezione m nel punto P che corrisponde all'intersezione in P2, sostituendolo nella parametrizzazione della retta
%CONTO MOLTEPLICITà DELL'INTERSEZIONE
%
%poniamo m=0 se P non sta nell'intersezione e m=\infrty se la retta è contenuta nella curva e P è in r
%
%RECAP OSS
%1 MOLTEPLICITà INTERSEZIONE	se r non è contnuta in C allora l'intersezione è finita /#finito di punti/. Sia mi la molteplicità di intersezione in P_i, allora il numero di questi punti di intersezione /G(\lambda, \mu)=0 dà i punti di intersezione della curvacon la retta. Tale equazione può avere al più d soluzioni, ovvero tante quandte la curva, questo perché G è omogeneo di grado d. N deduciamo che la cardinalità dell'intersezione è al più in grado di C. Anche contati con moltplicità è al più il grado di C. Questo perché G()=0 ha al più d soluzioni con moltplicità /dall'analisi dei plinomi omogenei in due variabili di ieri
%	Se il campo è quello complesso allora possiamo dire che la somma delle moltlpicità è esattamente d. In particolare, la retta e la curva si intersecano sempre: generalizza che nel pinao proj si intersecano sempre
%	Se il campo è quello reale e d è dispari allora possimamo ancora concludere che la rettaaa e la curva si intersecano sempre: deve annullarsi almeno in un punto reale
%
%
%nel caso della conica il grado è due, quindi non si hanno molte possibilità
%ESEMPIO 
%Se C in P2C è una conica ed r è una retta non contenuta in C, allora r\cap C sono due punti con molt 1 o 1 punto con molteplicità 2
%Se la conica  in P2R ed r è una retta non contenuta in c, allora c'è anche la possibilità che l'intersezione sia vuota e
%	C\colon	r_3
%	
%Se una conica C contiene tre punti allineati, allora è riducibile, questo perché
%riducibile vuol dire che il rango è minore o uguale di 2
%TIPS 14:50 da riasocltare
%se la retta e lacurva si intersecano troppo lo vedo dal grado e dalla molteplicità ottengo che una è contenuta
%OSS si può dimostrare che la molteplicità di intersezione fra C e r in P non dipende dalla parametrizzazione scelta per r		cambiamento variabili invertibile nel poinomio
%la molteplicità di intersezione è invariante per proiettività
%
%con l'inversa della proiettività ottengo un nuovo pol omogeneo
%dunque le priìoiettività portano curve algebriche in curve algebriche
%
%
%stessa costruzione nel caso affine
%
%INTERSEZINE RETTA CURVA NE CASO AFFINE
%Sia C una curva in k\amp^2 di equazione f(x,y)=0 e sia r una retta affine
%Scegliamo una parametrizzazione per r
%per intersecare C ed r sostituiamo la parametrizzazine di r nell'equazione di C e otteniamo un polinomio nell'unico parametro t
%le radici di t corrispondono ai punti di intersezione
%definiamo la moltplicità di intersezinoe di C e r in un punto P che corrispone ad un t_0 del parametro che è uno 0 di G che corrisponde alla molteplicità di t_0 come radice fi g(t)
%
%FATTI
%1/2	la moltplicità di int non dipende dalla scelta di paramaterizzazione della retta ed è invariante per afifnità
%3	è la stessa cosa calcolata nel pinao affine o nella chiusura proiettiva. Sia p nell'intersezione e la chiusura proiettiva di C in P2 che contiene il piano affine ed r segnato la chiusura proiettiva di r in P2, partiamo da una curva nel piano affine e una retta e il punto di intersezione
%il punto satarà ancora nelle chiusure proiettive, allora la molteplicità di intersezione fra c e r in P è uguale alla molteplicità di intersezione fra le chiusure proiettive in P
%
%DEF RETTA TANGENTE AD UNA CURVA IN UN PUNTO
%Sia C una curva piana (affine o proj) e r una retta (aff o proj). Diciamo che r è TANGENTE a C in un punto P se la molteplicità di intersezione fra C ed r in P è maggiore di 1
%per esempio, C in P2R di equazione con retta di equazione, l'intersezione era solo un punto, allora r_1 è tangente a C in P. è proprio la tangente geoemtrica. La conica in P2R 
%deomogeneizziamo rispetto alla variabile non nulla x=/ y=/ e duneue C_2 ha equazione	,ovvero è una circonferenza con P=(0,1) allora la tangente in questp caso è chiaramente la retta y=1, tornando in coo proj diventa x1/x_2=1 \implies x_1=x_2
%
%esempio con una cubica in R2
%Sia C in R^2 la crva di equazione y^2=x^2+x^3, è una cubica perché ha grado 3
%voglio calcolare quali sono le rette tangenti nei punti P=(-1,0)\in C	prendo le rette che passano per P, le interseco con la retta e vedo quali sono tangente: fascio e per quali la molteplicità è maggiore di 1
%tego la direzione come parametro
%dalla retta parametrizzazione sosttuisco nell'equazione 
%
%g(t) porto tutto al secondo membro e viene 
%
%analizziamo cosa abbiamo trovato t=0 è sempre una soluzione: per costruione abbiamo preso la retta che passava per p, dunque è sempre soluzione, per qualsiasi direazione
%la molteplicità di intersezione fra C e r in P è la massima potenza di t che divide g, o meglio è m se  t^m è la massima potenza di t che divide g. Quand'è che la molteplicità di intersezione è maggiore di 1 in questo caso con una cubica? Nell'equazione che abbiamo scritto deve succedere che t^2 divide g, ovvero v_1=0 per poter raccogliere una copia di t
%questo determina univocamente la retta
%quindi r è la retta verticale che assa per P
%abbiamo dunque determinato che esiste ed è unica tangente in P
%
%ESEMPIO DI RETTE TANG NON UNICHE
%riscriviamo l'eq delle curva, questa volta consideriamo l'origine
%scriviamo il frascio di rette per Q
%troviamo che t^2 si può sempre raccogliere
%significa in questo caso che la molt di intersezione fra le rette e Q è sempre almeno 2, dunque ogni retta per Q ha intersezione maggiore di 2, dunque è tangente
%nel punto Q la curva si autointerseca, moralment ogniiretta per l'origine interseca la curva almeno due vole, quindi è tangente
%nel conto ci sono due dir speciali per ui la molt è 3, quando w_1^2-w_2^2=0\implies w_1=w_2 (bis 1 quadrante) oppure w_1=-w_2	tangenti ai rami: più tangenti perché la molt di intersezione sale
%
%nel caso generale si fa un conto analogo: nel caso affine
%C\colon f()=0
%OSS possiamo sempre scrivere il polinomio come polinomio centrato in x_0,y_0, ovvero come polinomio in x_0-x_0 e	 invece che come polinomio in x e y
%(somma finita senza specificare il grado)
%uso la formula del binomio di Newton
%Allora f()==f(P) e in particolare in questa scrittura si ha il termine noto,quello lineare e i termini di grado superiore
%dipende da tali numeri, che si possoo esprimere in termini di derivate parziali
%quando ho polinomio posso sempre definire in maniera formale la derivazione parziale
%
%ESERCIZIO
%verificare che \alpha=\frac{\partial{f}}{\partial{x}}(x_0,y_0) e \beta=\frac{\partial{f}}{\partial{y}}(x_0,y_0)
%
























%
%%LEZ 35
%Scriviamo $f$ centrato in $p$: $f=\sum_{i,j\geq} 
%
%definsco derivate formale, che sono pol in coeff x e y, applicando tali regoe alla srittura in x_0 e y_0 si vede che la derivata si può scrivere come
%Allo stesso modo $\frac{}{}=\beta$
%indicheremo anche il gradiente ed il gradiente valutato in P
%
%adesso vogliamo intersecare con l retta genereica per P
%Sia r la retta per P con direzione v=(v_1,v_2)
%descrizione parametrica x=x_0+tv_1 
%per cui x-x_0=
%dnque scrivendo g(t)=f()siamo facilitati dall'averlo scritto centrato /scritta in rosso/
%sostituendo siccome non c'è il termine noto viene 	i monomi con gado almeno 2 in -x_0 almeno grado almeno 2 in t
%raccogliendo la t viene (\alpha v_1+\beta v_2)t
%quello che fa la differenza è il coeff nel rettangolo giallo
%Si hanno dunque due possiblità:
%	1	\alpha=\beta=0, ovvero grad =0:\il ceoff è0 infipendentemente dalla retta \implies \forall r retta per p t^2 divide g(t)\implies la moltplicità di intersezione è \geq 2 \implies ogni retta per P è tangente a C in P
%	2	\neq 0 	l'eq gialla determina in maniera univoca la direzione della retta: retta ortogonale a \alpha e \beta: \implies \exists ! la retta tangente a C in P ed è quela di direzione (-\beta,\alpha) con equazione	\alpha(x-x_0)+\beta(y-y_0)=0, ovvero in temrinin di polinomi			 \frac{}{}(P)(x-x_0)+\frac{}{}
%=0
%abbiamo ritrovato la casistica della cubica con pnti eplicit: ogni retta è tangente oppure c'è una sola tangente alla curvanel punto
%ESERCIZIOE nel caso della cruva dello scorso esempio: calcolare il gradiente di f in (-1,0) e in (0,0) e per (-1,0) scrivere la retta tangente e confrontare con i conti dello scorso esempio
%
%questo ci porta a dare una definizione su punto della curva se il gradiente si annulla o no
%DEF
%Sia $C$ una curva affine in $\kamp^2$ di equazione $f(x,y)=$, allora un punto $P\in C$ è detto \textbf{non singolare} o \textbf{liscio} se \neq 0. Altrimenti $p$ è detto \textbf{punto singolare}
%Una cruva $C$ è detta $\textbf{singolare} se ha almeno un punto singolare, altrimenti è detta curva non singolare o liscia
%
%Abbiamo visto prima che se $P$ è non singolare esiste ed è unic la tangente a $C$ in $P$ ed ha equazione		essendo non sing almeno uno dei due coeff non è nullo
%Se invece $P$ è singolare allora ogni retta per $P$ è tangente a $C$ in $P$.
%
%vogliamo vedere la stessa cosa nel caso proiettivo
%per passare da punto singolare o tangente serve prima proprietà dei polinomi omogenei, detta relazione di Eulero sui polinomi omogenei (in un qualsiasi numero di variabili e  coeff in un campo qualsiasi)
%Sia $F\in\kamp[]$ relazione fra $F$ e le sue derivate parziali, che sono dei polinomi data la loro definizione formale, e sono polinomio omogenei di grado $m-1$
%Si ha che la somma 	è un polinomio è pari a mF con m grado di F.
%Siccome la der parz omogeneo m-1, molt per x
%
%PROOF
%siccome la somma è la somma, allora basta mostrarlo per un monomio G=\lambda 	con j_0+\dots
%scrivendo la deer rispetto ad una variabile
%quando moltiplico per x_i metto apposto l'esponente i-esimo
%
%il monomio è sempre lo stesso perché si moltiplica per x_i
%monomio j e somma degli esponenti è esattamente di grado, dunque =mG
%
%sing e non sing rette tang per piane pro
%PROP
%Sia ora $$ in P2 una curva di equazione $F()=0$ con $F$ omogeneo di grado $d$. Sia $P\in C$, allora, $P$ è non singolare $\iff$ almeno una delle der parz di F non è nulla in $P$, ovvero $\exists i\in\{0,1,2\}\colon \frac{}{}(P)\neq 0$
%allo stesso mod del caso affine con le der in p
%In tal caso eisste ed è unica la retta tangente a $C$ in $P$ ed ha equazione coeff dati dalle der parziali di $F$ in $P$:
%\frac{}{}(P)x_0+ \frac{}{}(P)x_1+\frac{}{}(P)x_2=0
%ATTENZIONE che le derivate sono dei numeri!
%PROOF
%dobbiamo verificare che la crva aff di cui C è chiusura proj, deomogeneizzando rispetto a x_0 si ritrovano le stesse definiion di prima
%A meno di proiettività possiamo supporre che $P=(1\colon a\colon b)$, ovvero che stia nella carta affine $U_0$, ovvero P corrisponde a quando identificao U_0 a K^2
%Poniamo $f(x,y)\coloneqq F(1,x,y)$ e sia $C_0$ la curva in K^2 di equazione $f8x,y=0$ per cui $C$ è la chiusura proiettiva di $C_0$
%vogliamo mettere in relazionie le der parz di f e di F a partire dalla relazione nel rettangolo giallo, che ci dice che facendo la der parz di f rispetto a x è la sessa di 	valutata in	come polinomio, idem y, ed è una relazione fra polinomi
%valutandola nel punto si ottiene l'eq \frac{}{}(a,b)=\frac{}{}(1,a,b) idem y
%
%usiamo la relazione di Euleeero: riusciamo a mettere in rel le der parz solo rispetto alle var x_2,y_2, nulla con x_0
%Relazione di Euleero: 	relazione fra polinomi, valutiamo in (1,a,b) siccome x_0= otteniamo
%\frac{}{}(1,a,b)+a\fracP{}{}(1,a,b)+b\frac{}{}(1,a,b)=dF(1,a,b), ma F(1,a,b)=0 perché il punto sta nella curva
%riusciamo così a esprimere la terza derivata parziale in funzione delle altre due \frac=-a\frac -b\frac
%Quindi abbiamo che 	=0\iff F(1,a,b)=(0,0,0)
%Verifichiamo la doppia implicazione: se il grad f si annulla in P allora si annullano le derivate parziali di x_1,x_2 di F, allora per la relazione di Eulero anche la terza derivata parziale si annulla
%Viceversa, se il grad fi F si annulla bastano le relazioni per avere che anche il grad di f si annulla
%
%il pnto P è non singolare quando il grad fdi F non è identicamente nullo nel punto
%manca che la retta tangente diventi proprio quell'equazione
%Supponendo $P$ non singolare, ovvero $grad F\neq 0$, allora la ret tangente affine a $C_0$ in $P$ ha equazione
%ne facciamo la chiusura proiettiva che ne dà la retta tangente proiettiva a $C$ in $P$ ed ha equazione	bisgona omogeneizzare rispetto a $x_0$
%
%sostituisco ed omgeneizzo rispetto a x_0
%sostituendo le der parzi di f sostituisco le relazioni asterisco verde chiaro, ottenendo
%\frac{}{}()()+\frac{}{}()()=0
%raccogliendo i termini in x_0,x_1,x_2, ottenendo 
%-a\frac{}{}()-b\frac{}{}()
%si usa ora la secona relazione ottenuta da Eulero	coeff di x_0 proprio
%END PROOF
%
%OSS
%Se $C$ è una curva affine di equazione 	per trovare i punti singolare di $C$ bisogna risolvere un sistema con l'eq della curva e le der parz di f	serve l'eq della cruva perché potrei avere punti che il grad si annulla ma non appartengono alla curva!
%Invece se $C$ è proiettiva di eqazunoe	 per trovare i punti singoari di $C$ bisogna risolvere il sistema 
%e non serve mettere anche l'eq della curva perché c'è la relazione di Eulero:
%Infatti se P annulla grad F, allora dalla relazione di Eulero 
%F(P)=\frac{1}{d}		e se sono tute nulle viene 0 /applicazione di Eulero/
%
%ESEMPI
%Esempi di due cubiche: una vecchia
%
%$C$ è la chiusura proiettiva di $C_0$ ed ha equazione $F=x_0x_1^2+x_1^3-x_0x_2^2$ con derivate parziali
%se le poniamo uguali a zero
%
%siccome l'ultima è un prodotto otttengo che una deve essere nulla, da cui viene una condizione impossibile perché le coordinate omogenee non possono essere tutte nulle
%
%P corrisponde all'origin in K^2		la curva affine con tale equazione l'abbiamo già studiata, e sappiam già che l'origine deve venire singolare
%in più abbiamo verificato che P è l'unico punto singolare
%avevamo studiato anche il punto (-1,0), vediamolo anche nel caso proiettivo
%Scriviamo $T_Q C$
%	\frac{}{}()=1,\ \frac{}{}(Q)=(2x_0x_1+3x_1^2)(Q)=1
%dunque l'equazione proiettiva della retta tangente proiettiva è
%per ottenere la retta affine di cui è chiusura proiettiva basta porre x_0=1, per cui x+1=0, ed è coerente con l'analisi fatta la scorsa lezione
%avevamo visto che nel punto singolare P=(), tutte le rette per P hanno molteplicità di intersezione 2 con la curva $C$ in $P$ tranne due rette speciali, quelle di direzione (1\pm 1) in cui la moltplicità di intersezione è 3	/comportamento locale nel punto singolare/
%	P si dice un nodo con questo tipo di punto singolare
%FINE ESEMPIO
%ESEMPIO
%nuova cubica
%parto da curva affine e poi ne consideriamo la chiusura proiettiva $C$ di equazione $F(x_0,x_1,x_2)=x_0x_2^2-x_1^3$
%\implies unico punto singolare di C
%
%vediamo qual è la moltplicità dell'intersezione per confrontarlo con il caso precedente
%retta r per l'origine in K^2 	con v direazione di r
%interechiamo con C_0
%sostituendo si ottiene g(t)
%t^2()=0
%veidmamo dunque che la molteplicità di intersezione della retta con la curva è 2 in generale e 3 se v_2=0, quindi vediamo che è simile ma diverso: quasi tutte le rette hanno moolt 2 e qui c'è soo un'unica retta con moltplicità 3 e non 2
%
%se la disegnamo in R2 è circa così:
%nel punto singolare c'è una cuspide
%intorno al punto non singolare è liscia
%
%questi erano esempi di cubiche, vediamo cosa succede per le coniche
%OSS punti singolari delle coiche
%Sia $C$ una conica proiettiva, allora il numero di punti singolari dipende solo dal rango, ovvero
%	\rk=3\implies C non ha punti singolari
%	\rk C=2 \implies C ha un punti singolare
%	\rk C=1 \implies C è una retta doppia e ogni punto di C è singolare
%	
%Infatti sia $A$ la matrice simmetrica associata a $C$, allora l'equazione associata a $C$ è $F=x^tAX=\sum_{i,j=0}^2 a_{ij}x_ix_j
%scriviamo la derivata parziale: 0 se i,j\neq h
%
%u punt P rappresentato dal vettore v è singolare per C se le derivate parziali si annullano, cioé \sum_{i=0}^2 a_{hi}v_i=0\forall =0,1,1
%se si pensa al prodotto righe per colonne si ha che ho l'indice di riga di a fissato in h mentre faccio variare l'indice di colonna
%
%sela riga h deve essere nulla allora il vettore deve essere nullo, ovvero v\in\ker A
%riassumendo, i punti singolari di $C$ son dati dai vettori che stanno nel nucleo dellamatrice $A$, che dipende dal rango di $A$
%	\rk a=3\implies \ker A=\{0 \} \implies nessun punto singolare
%	\rk A=2\implies
%			quadrato di una forma lineare, retta dopppia, allora ogni punto di C è singolare	è esattamente la retta proiettiva associata al nucleo di A
%data la classificazione proiettiva reale e complessa
%posto \rk C=2, nel caso complesso C=	distinte e il punto singolare è il punto di intersezione delle due rette
%mentre nel caso reale a meno di proiettività di hanno 2 casi in base alla segnatura		ancora intersezione delle due rette
%mentre nell'altro caso la forma quadratica si fattorizza su C e non su R e C ha sostegno un unico punto P, che è proprio il punto singolare
%
%OSS sulle cubiche nel caso complesso
%nel piano proiettivo complesso consideriamo $C$ una cubica di equazione $F=0$, qunidi $\deg F=3$. Se la curva p riducibile, allora il polinomio $F$ p riducibile, per definizione, ma siccomei lgrado è basso allora è prodotto di un polinomio di grado 1 per un altro polinomio di grdo 2, pertanto il prodott	luogo zeri F è unione luogo zeri G e H
%dunque $C$ è unione di una retta ed una conica
%mi riconduco così a gradi più bassi
%Supponiamo che $C$ invece sia irriducibile: allora $C$ non può contenere una retta, altrimenti l'eq della retta dividerebbe il polinomio $F$. Allora $C$ ha al più un punto singolare 
%Infatti, se per assurdo ne avesse almeno 2 quali $P$ e $Q$ potremmo considerare la retta r che passa per P e Q, pertanto l'intersezione fra la retta e la cubica	la interseca in almeno	C\cap r\subseteq \{P,q\} e sappiamo che la molteplicità di intersezione in questi due punti, siccome sono due punti singolari allora la molteplicità è almeno 2, ma non è possibile perché dallo studio delle intersezioni fra una retta e una curva sappiamo che dobbiamo contare con molteplicità fino al grado della curva: qui sono 2 punti con molt 2, ma C ha grado 3, dunque la retta dovrebbe essere contenuta nella curva, ma è una contraddizione
%
%ESEMPIO
%per liscie
%se $F=x_0^3	$ dà una curva senza punti singolari perché le der parziali sono multpli delle coordinate dunque non possono mai essere tutti nulli
%FINE PNTI SINGOLARI DELLE CUBICHE
%
%--------------------------------------------------------------------
%FASCI DI CONICHE PROIETTIVE
%
%prendo 2 coniche e considero le coniche le cui eq si ottengono come cl delle due equazioni
%Siano $C_1$ e $C_2$ due coniche distinte nel piano proiettivo di equazionie $F_1$ e $F_2$, siccome le coniche sono distinte allor $F_1$ e $F_2$ non sono proporzionali. 
%Il fascio di coniche generato da $C_1$ e da $C_2$ è dato da tutte le coniche di equazione $\lambda F_1+\mu F_2=0$ con $(\lambda\colon \mu)\in $
%posso scrivere \mathcal{F} come fascio e $C_{\lambda,\mu} com conica specifica ottenuta dall'equazione, che è sempre unnac onica
%se moltiplico lambda e mu per lo stesso scalare tutta l'eq viene moltplicata ed ottengo la stessa conica di prima, dunque vanno presi in P1 e non solo in K
%
%ESEMPIO
%C_1\colon x_0x_1=0
%C_2\colon (x_0-x_1)x_2=0
%entrambe coppie di rette, allorail fascio da loro generato è	
%riscritto raggruppando i monomi si ottiene
%
%ESEMPIO
%si cambia C_2	una delle due rette fa parte della prima: x_0=0 appartiene ad entrambe
%posso raccogliere x_0
%
%dato un fascio di coniche ci si chiede qual è il rango delle coniche del fascio
%DEF
%una conica in P2 si dice DEGENERE quando non ha rango massimo , ovvero se \rk C< 3, ovvero quando la matrice non è invertibile
%
%STUDIO DELLE CONICHE DEGNERI IN UN FASCIO
%dato un fascio vogliamo vedere quante e quali sono le coniche degenerei del fascio
%
%Supponiamo che C_1 abbia matrice associata la matrice simmetrica $A_1$ e
%allora è chiaro che la conica del fascio generata da C_1,c_2 sarà la combinazione lineare sulle matrici: ci interessa il determinante della combinazione lineare
%si hanno due possibilità:
%lambda A_1+\mu A_2 è una matrice 3\times 3 i cui elementi sono nulli oppure delle forme lineari in \lmbda e \mu /cl di numeri/
%dunque facendo il determinante si ottiene un polinomio omogeneo in \lambda e \mu e sarà nullo oppure avrà grado 3
%dunque si avranno 2 possibilità
%	o D(\lambda,\mu)=0\implies in termini del fasciotutte le coniche del fascio sono degeneri
%	o D(\lambda,\mu) è omogeneo di grado 3 \implies si possono avere nel fascio 	coniche degeneri è come se stessimo guardando gli zeri del polinomio du P1 e ne può avere al più 3, pertanto ci sono al più 3 coniche degeneri
%	
%deduciamo dunque che o sono tutte degeneri o sono massimo 3, quindi se in un fascio ne trovo 4 degenerei allora tutte lo sono!
%
%nel caso complesso gli zeri sono pari al grado contato con moltplicità: ho sempre almeno una conica degenere
%anche nel caso reale ssendo nel caso dispari 
%		dunque c'è sempre una conica degenere
%		
%Se \kamp=\complexset o \kamp=\realset, allora D ha sempre almeno una radice in P1, dunque il fascio ha sempre una conica degenere
%pertanto ogni fascio ha sempre una conica degenere
%
%riscriviamo gli esempi precedenti
%\ESEMPIO 1
%
%
%ci sono solo 2 eri perché uno è doppio
%questi valori dei parametri soo sempre i valori che c restituisconoi polinomi di partenza, corrispondono dunque a C_1 e C_2, che sapevamo già esseredegeneri perché sono coppie di rett
%abbiamo dunque scoperto che C_1 e C_2 sono le uniche coniche degeneri del fascio
%
%ESEMPIO 2
%in questo caso il deterinante viene identicamente nullo perché sono riducibili essendo coppie di rette
%in questo fasco tutte le coniche del fascio hanno una retta in comune
%
%FIN ESEMPIO
%
%ci interessa sapere anche il punto che passa per tutte le coniche (che ne sono di più)
%DEF
%I \textbf{punti base} base di un fascio di coniche sono i punti che appartengono a tutte le coniche del fascio, ovvero 
%
%OSS punti base
%i pnti base sono dati dall'interseoine delle due coniche che generano il fascio, infatti essendo nel fascio la loro intersezione
%viceversa se 		duque comunque faccia la combinazione lineare viene sempre nulla
%
%
%vediamo i punti base degli esempi
%ESEMPIO 1
%punti base
%
%intersecando due rette non coincidenti posso ottenere al più 4 punti 1+1+1+1	ne ottengo meno se qualcuno di questi punti va a coincidere
%
%si guardano diversi casi		3 punti base
%
%ESEMPIO 2
%retta di punti base perché  una retta comune a tutte le coniche del fascio, ed il punto base del fascio di rette che dà la seconda retta della conica di equazione \lambda x_1+\mu x_2=0		la seconda retta varia fra tutte le rette che contengono P











%%LEZ 36
%PARAMETRIZZZIONE DELLE CONICHE IN p2
%Data l'equazione di una conica $F=a_{00}x_0^2+2a_{01}x_0x_1		$ possiamo associare a $C$ il punto $(a_{00}\colon a_{01}\colon )$, essendoci 6 coordinate allora è un punto di P5, che determina univocamente la conica: non nulla e ameno di multipli sia l'equazione sia i lpunto di P5
%In questo modo otteniamo una corrispondenza biunivoca fra le coice in P2 e P5
%Cosa vuol dire considerare un fascio di coniche?
%Date C_1 e C_2 coniche, consideriamo il fascio \mathcal{F} da loro generato. C_1 ha equazione con coefficienti a_{ij} e corrisponde ad un punto A=()\in P5
%Mentre C_2 ha equazione 		punto di P5 a coefficienti b_{ij}
%La conica C_{\lambda,\mu} del fascio è la cl di F e G, dunque i coefficienti sono la cl dei coefficienti dell'eq si C_1 e C_2, dunque il punto corrispondente P_{\lambda,\mu}=() che facendo variare lambda e mu in P5 descrive una retta generata dai punti a e b
%in questa corrisp biunvoca fra coniche e punti, i fasci di coniche corrispondono esattamente alle rette in P5
%Ogni fascio di coniche corisponde ad una retta in P5
%dunque la retta è individuata da due qualsiasi 2 punti, allo stesso modo il fascio è descritto da qualsiasi sue 2 coniche
%scelta coniche dà parametrizzazione del fascio
%La retta in P5 è determinata da 2 suoi punti qualsiasi distinti \implies il fascio \mathcal{F} è determinato da 2 qualsiasi 2 coniche distinte (la scelta di C_1 e C_2 dà diverse descrizioni parametriche del fascio)
%questo ci permette di dare più informazioni sui punti base
%OSS
%Dato un fascio di coniche, i punti base del fascio sono dti dall'intersezione di due qualsiasi coniche del fascio purché siano distinte, ovvero da $C\cap\widetilde{C}$ dove $C$ e $\widetilde{C}$  coniche distinte del fascio
%	tips?
%così è molto più facile intersecare coppie di rette
%
%OSS
%Sia \mathcal{F} un fascio di coniche. Esiste sempre una conica degenere in \mathcal{F} /possiamo usarla per calcolare i punti base/ \implies usiamo C per calcolare i punti base
%C è l'uniione di due rette. Scegliamo una qualsiasi altra conica del fascio \implies i punti base del fascio sono dati da C\cap\widetilde{D}=()\cup ()
%deduciamo che il numero di punti base di un fascio di coniche, se sono finiti
%ciascuna delle due rette interseca tilde C al più in 2 punti
%
%COROLL
%Se due coniche C_1 e C_2 non hanno una retta in comune allora #()\leq 4
%PROOF
%C_1\cap C_2 sono i punti base del fascio generato da C_1 e C_2, dunque segue dall'osservazione precedente
%
%TRUCCO PER CALCOLARE INTERESEZIONE DELLE CONICHE
%coniche irriducibili di cui devo calc intersezione, ovvero il sistema delle due coniche
%fascio coniche
%mat e determinate
%trovo conica rid del fascio
%interseco C_1 o C_2 con le rette della conica riducibile
%Questo dà anche un metodo per calcolare C_1\cap C_2 nel fascio \mathcal{F* scirviamo D(\lambda,\mu), troviamo una onica degenere widetilde{C} e poi intersechiamo con C_1\cap\widetilde{C}}
%
%
%fasci coniche rappresentazione geometrica, ce ne sono di molti tipi, vediamo quello comune
%PROP
%Siano $A,B,C,D$ 4 punti in posizione generale in P2. Allora la famiglia delle coniche passanti per i 4 punti è un fascio \mathcal{F} avente come punti base esattamente i 4 punti
%/stimao dicendo che fisso 4 punti in po gen e considero le coniche che contengono tutti e 4 punti
%famiglia fascio F: se la consider ocome punti di P5 descrivono esataente una retta: fissate due coniche le altre sono date da cl delle altre 2
%essere un fascio: in P5 è una retta: se guardo le eq tutte e sole che si ottengono come cl di due eq fissate/
%Inoltre \mathcal{F} non contiene rette doppie e contiene esattamente 3 coniche degeneri
%/coniche degeneri che sono coppie di rette che passano per questi 4 punti/
%/il disegno è fuorviante perché le rette si intersecano da qualche parte nel piano proiettivo/
%\overline{AB}\cup\overline{CD} e
%/è un fascio semplice perché il comportamento è quello che uno si aspetta/
%PROF
%/scelta coo: siccome sono in pos gen posso scegliere in modo tale che i primi 3 sono i punti fondamentali e l'ultimo il punto unità/
%A,
%scriviamo letterlamnte la famiglia partendo da eq conica generica, impoiamo che pass per A,\dots D e vediamo che conidzioni vengon sui coefficienti
%Conica generale: a_{00}x_0^2+2a_{01}x_0x_1+a_{11}x_1^2+2a_{02}
%
%imponiamo il passaggio per A, ovvero sostituire A e metterlo uguale a 0, ottenendo la condizione a_{00}=0
%condizioni semplici perché abbiamo scelto unti semplici
%
%nel passaggio per D tego conto delle condizioni precedenti
%
%andiamo a scrivere l'equazione che abbiamo ottenut: a_{01}x_0x_1+a_{02}x_0x_2-(a_01+a_02)x_1x_2=0
%sono le eq di tutte e sole coniche che passano per A,B,C,D
%siccome a_{01} e a_{02} sono gli unici parametri rimasti adesso le voglio  riscrivere evidenziandoli
%a_{01}()+a_{02}()=0
%
%abbiamo così trovato esattamente un fascio di coniche ed  enerato dalle due coniche che sono entrambe degeneri x_1(x_0-x_2)=0
%abbiamo così dimostrato la prima affermazione
%per la seoncda esaminiamo cosa sono queste coppie di rette
%la retta x_!=0 è la retta \overline{AC} mentre quella			guardo quale coppia di punti ha quella coordinata nulla
%
%ci dice anche che i punti base sono solo A,D perché si intersecano solo lì le rette degeneri
%C_1\cap C_2
%
%dunque i punti base del fascio sono questi 4 punti: devono essere i punti base del fascio e siccome sono finiti allora non ossono essercene altri
%
%affermazione sulle coniche degeneri: scirviamo la matrice della conica, usiamo l'equazione della conica del fascio per scrivere la matrice
%Per calcolare le coniche degeneri sciviamo la matrice divisa per due perché tanto è determinata a meno di multipli
%0 & a_{01} & a_{02} \\
%a_{01} & 0 & -a_{01}-a_{02}\\
%a_{02} & -a_{01}-a{02} & 0
%
%D=\det M=-a_{01}(a_{01}+a_{02}) + a_{02}a_{01}(-a_{01}-a_{02}=
%pol omogeneo in a_o1 e 02 già fattorizzato in fattori lilneari, pertanto si hanno esattemente 3 oniche degeneri)
%a_{01}=0 dà C_2, mentre a_{02}=0 dà C_1, mentre la terza si ottiene sostituendo nell'euazione del fascio a_{02}=-a_{01}, ottenendo a_{01}x_0x_1-a_		dunque x_0(x_1-x_2)=0, a cui corrispondono 
%Tutte e tre le coniche degeneri hanno rango 2 e quindi non ci sono rette doppie nel fascio
%	end proof
%
%TIPS
%se devo scrivere fascio coniche per 4 punti non lo facco come nella dim
%OSS
%Supponiamo di aver dati 4 punti in posizione generale e di voler scrivere il fascio \mathcal{F} delle coniche che passano per questi 4 punti
%/scirvo 2 delle coniche riducibili perché faccio molto prima/
%Scriviamo 2 delle coniche riducibili: l_1 eq della retta \overline{AB} etc
%pertanto l'eq del fascio è
%fare come nella dimostrazione è più complicato
%END TIPS
%
%OSS sui fasci
%PROP Sia \mathcal{F} un fascio di coniche e sia P\in P2 / se il punto è base sta in tutte le coniche del fascio, ma se non è un pnto base in quante coniche sta?
%Se P non è un punto base di \mathcal{F}, allora esiste ed è unica la conica del fascio che contiene P
%PROOF
%Supponiamo di avere 2 coniche che generano il fascio con	 pertanto il fascio avrà eq
%il punto P apparitene a \iff l'eq della conica è soddisfatta nel punto, ovvero
%va vista come un'equazione in \lambda e \mu
%siccome il punto P non è un punto base, allora non appartiene all'intersezione, allora non è ossibile che entrambe le equazioni si annullino in P, ovvero
%è equivalente pt base ed eq nulla
%pertanto l'equazione ha un'unica soluzione in P1 che sarà proprio (), pertanto si ottiene un'unica conica del fascio che contiene P
%
%sostituisco i valori di lamba e mu per trovare la soluzione /esempio in giallo
%
%
%PROP
%5 punti determinano una conica
%Dati 5 punti distinti in P2 a 4 a 4 non allineati / più deboe che siano in pos generael, perché pottrebbero essercene 3 allineati ma non 4/, esiste ed è unica la conica C che li contiene
%PROOF
%Possiamo scegliere 4 di questi punti che sono in posizione generale, infatti consideriamo i ptimi 4: se sono in pos gen ok, else ce ne sono 3 allineati, per esempio A,B,C. siccome per i potesi i 4 pt non sono allineati allora D\notin r e ancheora per ipotesi neanche E appartiene a E. buttiamo C e consideriamo A,B,D,E: di nuovo, se son in pos gen ok, else 3 sono allineati, però abbiamo già che D ed E non sono in r, dunque abbiamo 3 punti allineati che possono essere A,D,E oppure B,D,E. Supponiamo A,D,E, allora B.C.D,E son in pos generale (scarto A)
%
%--
%Troviamo quindi 4 punti fra	in pos generale, dunque possiamo applicare la posizione precendente, dunque sia \mathcal{F} il fascio delle coniche passanti per A,D. Ma E non è un punto base per F perchè i punti base sono i 4 punti, dunque esiste ed è unica la conica C del fascio che passa per E, e dunque C è l'unica conica che contiene i 5 punti
%
%dati 5 punti esiste ed è unica la conica che passa per i 5 punti
%
%UTILE PER ESERCIZI
%questa dim dà anche il metodo che passa per tali 5 punti
%
%TIPS
%il metodo più semplice è scrivere il fascio come nel tip per prima e poi imporre il passaggio per il 5° punto
%oppure parto dalla conica generale e impongo il passaggio per 5 punti, ma è più lungo
%il passaggio per un unto dà eq lin omo sui coeff della conica e possiamo pensarlo come ipermiano nel P5, è ragionevole aspettarsi che con 5 punti ho 5 iperpiani che in pos gen si intersecano in solo punto
%l'ipotesi sui punti serve a garantire che le condizioni lineari siano indipendenti, così si ttiene un punto
% OSS
% La dimstrazione dà anche il metodo per trovare la conica $C$ che passa per 5 punti dati, nescelgo 4 in posizione generale, scrivo 4 rette e come prima scrivo il fascio delle coniche per, impongo al fascio il passaggio per E, ottenendo i valori di lambda e mu giusti, così trovo C
% 
%ES
%Se abbiamo 5 punti di cui 4 allineati, allora per ogni retta s che passa per P la conica r\cup s contiene i 5 punti, qunidi ce ne cono \infty avendo infinite rette s
%
%%PAUSA
%
%PROP
%invece di prendere 4 pt in pos gen, consideriamo
%Siano 3 punti non allineati, e sia una retta r che passi per A ma non per B e C. La famiglia delle coniche che passano per A,B,C e sono tangenti a r in A è un fascio F. I punti base del fascio sono solo A,B,C e il fascio F non contiene rette doppie e contiene 2 coniche degeneri che sono esattamente
%/due coppie di rette che soddsfano le condizioni/
%\overline{AB}\cup\overline{AC} : si intersecano in A: la molt di intersezione è 2, conta 1 per ciascuna retta, pertanto la retta è tangente, dal punto di vist dei pt sing: la retta è singolare, ogni retta per A è tangente
%r\cup	passa per a,b,c e contiene r, duneuq siccome quando è contenuta è tangente (moltplicità infinita)
%PROOF
%parto dalla conica generale e impongo condizioni, ottenog fascio e vedo che valgono le 
%Sia P\in r un punto diverso da A e P\notin\overline{BC} \implies A,B,C,P sono n posizione generale (a tre a tre non allineati)
%Scegliamo le coordinate proiettive tali che A,B,C siano i punti coordinati mentre P il punto unità. Allora la retta r che è AP ha equazione x_1-x_2=0
%Si consideri la conica generale 
%sappiamo già che il passaggio per i punti coordinati annulla la diagonale
%
%vogliamo scrivere le der parz perché vogliamo imporre che la retta r sia tangente in A
%Dobbiamo imporre che la retta r sia tangente alla conica in A: due modi istruttivi
%	1	intersechiamo semplicemente con r	sostituendo in Fx_1=x_2 otteniamo a_{01}x_0x_+a_{12}x_1^2
%	raccogliamo x_1 e rimane
%	il primo x_1 corrisponde al fatto che a\in 	r e C passano per A, voglimao che r sia tangente alla conica in A, pertanto bisogna imporre che xx_1=0 è l'unica soluzione, dunque il coefficiente di x_0 deve essere nullo, ovvero a_{01}+a_{02}=0
%	sostituendo nell'equazione si ottiene
%	raccogliamo
%	sono tutte e sole le coniche per A,B,C e tangenti a r in A
%	in questo modo abbiamo verificato che è un fascio: cl di coniche fissae ciascuna con coeff
%	
%	vediamo quali sono le coniche che generano: C:1\xoln x_0	 e C_2
%	intersecando C_1 e C_2 otteniamo i punti base		verifico così aff dìsui punti base
%	
%	sriviamo la matrice per verificare che non si sono altri puti base (?)
%	D=\det M=
%	pol omo 3 grado si ha radice doppia, duque le uniche coniche deg sono 2
%	parametri nulli danon le coniche che generano
%	
%	è uno dei de esempi dei fasci dati ieri
%
%OSS
%Un fascio di questo tipo è l'esempio 1 della scorsa lezione: 
%vediamo come sono posizionate le rette
%la retta x_0-x_1=0 passa per il punto di intersezione delle prme 2 rette, quindi qui siamo nella situa precedene: A il punto i intersezione, B e B i punti di intersezione di con
%dunque C_2 diventa r\cup BC, mentre C_1 è AB\cup AC
%ieri abbiamo già verificato che i punti base sono solo 3 e che C_1 e C_2 sono le uniche soniche degenerei di F. non avevamo visto che la retta r è tangente a tutte le coniche del fascio
%ESEMPIO ESERCIZIO 4.3 FFP
%Nel piao proiettivo reale P2R considerimao i punti A=(0\colon 1 \colon 2) e B=(0\colon 0\colon 1)
%Determinare, se esiste l'equazione di una conica passante per A,B,C,D e tangente in C alla retta r di equazione x_0-x_2=0 /che passa per C/
%SOLUZIONE DIVERSA
%SOL
%Verifichiamo se i 4 punti sono in posizione generale verificando che sono a 3 a 3 non allineati tramite i determinanti
%dunque c'è un fascio di coniche per questi 4 punti, che si scrive come 
%scrivo l'eq delle 4 rette con il determinante formale delle cordinate
%passa per i 2 punti, dunque la conica delfascio è
%scrivo le altre 2 retta
%idem seoncda conica
%dunque il fascio F è dato da
%queste sono tute e eosle le coniche che passano per A,D
%Vogliamo la conica del fascio che è tangente alla retta r\colo 	in C
%intersechiamo la conicha con la retta sostituenzo x_2=x_0 nell'equazione
%
%interpretiamo quando trovato: x_1=x_0 stiamo parametrixxando la retta r come x_0\colon x_1\colon x_0
%le coordinate d c perché C corrisponde al punto, ovvero a x_0=2x_1, ovvero x_0-2x_1=0, dunque il primo fattore corrisponde alla soluzione C
%tutte le conche passano per C e r passa per C allora
%vogliamo che anche l'altra soluzione sia il punto C, quindi imponimìamo che lambda e mu dinao la stessa sol, ovvero che le forme lineari siano proporzionali, ovvero imponiamo che \det =0, ovvero che i coeff dell'eq sono multipli, ovvero \mu=-4\lambda
%poniamo \kambda=1 e \mu=-4
%
%
%seabbiamo tempo controlliamo se la conica fa quello che deve fare: passa per i punti per cui deve passare e che sia tangente
%scriviamo direttamente la tangente














